<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>jasonpbecker</title><link href="http://blog.jsonbecker.com/" rel="alternate"></link><link href="http://blog.jsonbecker.com/feeds/jason-p-becker.atom.xml" rel="self"></link><id>http://blog.jsonbecker.com/</id><updated>2014-11-02T14:29:58-05:00</updated><entry><title>NaNo(Blo)WriMo</title><link href="http://blog.jsonbecker.com/2014/11/nanoblowrimo.html" rel="alternate"></link><updated>2014-11-02T14:29:58-05:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2014-11-02:2014/11/nanoblowrimo.html</id><summary type="html">&lt;p&gt;November marks the start of National Novel Writing Month (NaNoWriMo). The quick version is folks band together and support each other to write 50,000 words in&amp;nbsp;November.&lt;/p&gt;
&lt;p&gt;I would love to write a novel one day. I am not sure I could do it well, but I am pretty sure I could hit 50,000-80,000 words if I dedicated time to tell a&amp;nbsp;story.&lt;/p&gt;
&lt;p&gt;I don&amp;#8217;t have a story to&amp;nbsp;tell.&lt;/p&gt;
&lt;p&gt;So this year, I have decided to not feel guilty about skipping out on another NaNoWriMo (&lt;em&gt;always the reader, never the author&lt;/em&gt;), and instead I am modifying it to meet my needs. With no story to tell and no experience tackling a single project the size of a novel, I am going to tackle a smaller problem&amp;#8212; this&amp;nbsp;blog.&lt;/p&gt;
&lt;p&gt;Instead of 50,000 words in 30 days, I am going to try and write 1000 words a day for the next four weeks. I will not hold myself to a topic. I will not even hold myself to non-fiction. I will not hold myself to a number of posts or the size of the posts I write. I will not even hold myself to true daily count, instead reviewing where I stand at the end of each&amp;nbsp;week.&lt;/p&gt;
&lt;p&gt;I am hoping that the practice of simply writing will grease my knuckles and start the avalanche that leads to writing more. A small confession&amp;#8212; I write two or three blog posts every week that never leave my drafts. I find myself unable to hit publish because the ideas tend to be far larger or far smaller than I anticipate when I set out to write and share my frustrations. I also get nervous, particularly when writing about things I do professionally, about not writing the perfect post that&amp;#8217;s clear, heavily researched, and expresses my views definitively and completely. This month, I say goodbye to that anxiety and start simply hitting&amp;nbsp;publish.&lt;/p&gt;
&lt;p&gt;I will leave you with several&amp;nbsp;warnings.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Things might get topically wacky. I might suddenly become a food blogger, or write about more personal issues, or write a short story and suddenly whiplash to talking about programming, education policy, or the upcoming election. If high volume, random topics aren&amp;#8217;t your thing, you should probably unsubscribe from my &lt;span class="caps"&gt;RSS&lt;/span&gt; feed and check back in a&amp;nbsp;month.&lt;/li&gt;
&lt;li&gt;I might write terrible arguments that are poorly supported and ultimately don&amp;#8217;t reflect my views. This month, I will not accept my most common excuses for not publishing, which boil down to fear I will be held to the views I write and my first-draft thinking. I am going to make mistakes this month in public and print the dialog I am having with myself. You may be shocked and offended by voices I allow room to speak as I struggled with values, beliefs, and opinions. This month, this blog is my internal dialog. Please read it as a struggle, however definitive the&amp;nbsp;tone.&lt;/li&gt;
&lt;li&gt;I am often disappointed that the only things I publish are smaller ideas written hastily with poor editing. Again, this month I embrace the reality that almost everything I ended up publishing is written in 20 minutes of furious typing with no looking back, rather than trying to be a strong writer with a strong view point and strong&amp;nbsp;support.&lt;/li&gt;
&lt;/ol&gt;</summary><category term="novblog"></category><category term="meta"></category></entry><entry><title>Growing Up in the Internet Hate Machine</title><link href="http://blog.jsonbecker.com/2014/10/growing-up-in-the-internet-hate-machine.html" rel="alternate"></link><updated>2014-10-06T07:03:59-04:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2014-10-06:2014/10/growing-up-in-the-internet-hate-machine.html</id><summary type="html">&lt;p&gt;A terrible thing is happening this year. Women all across the internet are finding themselves the target of violence, simply for existing. Women are being harassed for talking about video games, women are being harassed for talking about the technology industry, women are being harassed for talking, women are being&amp;nbsp;harassed.&lt;/p&gt;
&lt;p&gt;A terrible thing is happening. Women are finding themselves the target of&amp;nbsp;violence.&lt;/p&gt;
&lt;p&gt;A terrible thing has always&amp;nbsp;happened.&lt;/p&gt;
&lt;p&gt;&lt;hr&gt;&lt;/hr&gt;&lt;/p&gt;
&lt;p&gt;I remember being a 16 year old posting frequently on internet forums. One in particular focused on guitar equipment. I loved playing in a band, and I loved the technology of making guitar sounds. Many people on the forum were between 16 and 24, although it was frequented by quite a few &amp;#8220;adults&amp;#8221; in their 30s, 40s, and 50s. It was a wonderful opportunity to interact as an adult, with&amp;nbsp;adults.&lt;/p&gt;
&lt;p&gt;Every week members created a new thread where they posted hundreds of photos of women. Most of them were professional photographs taken at various night clubs as patrons entered. Some were magazine clippings or fashion modeling. I remember taking part, both in gazing and supplying the occasional photograph from the internet. We were far from the early days of the world wide web, this being around 2003, but this was also before social media matured and online identity was well understood by the general&amp;nbsp;public.&lt;/p&gt;
&lt;p&gt;This thread became controversial. A change from private to corporate ownership of this forum led to increased moderation, and the weekly post with photos of women was one of the&amp;nbsp;targets.&lt;/p&gt;
&lt;p&gt;I did not&amp;nbsp;understand.&lt;/p&gt;
&lt;p&gt;In the debates about the appropriateness of the content and its place within our online community, I took the side of those who wanted the post to remain alive. I was not its most ardent supporter, nor was I moved to some of the extremes in language and entitlement that typically surround these conversations. However, my views were clear and easy. These were public photographs, largely taken with permission (often for compensation). And, of course, none of the pictures were &lt;em&gt;pornographic&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Appropriateness for me at 16 was defined by &lt;em&gt;pornography&lt;/em&gt;. I did not&amp;nbsp;understand.&lt;/p&gt;
&lt;p&gt;&lt;hr&gt;&lt;/hr&gt;&lt;/p&gt;
&lt;p&gt;My parents did not raise me to be misogynist. One of the most influential moments in my life came on a car ride to the dentist. I was also around 16 or 17. I think it was on my way to get my wisdom teeth removed. I had been dating the same girl for a while, and it was time for my father to give me &lt;em&gt;the talk&lt;/em&gt;. All he said to me was, &amp;#8220;Women deserve your&amp;nbsp;respect.&amp;#8221; &lt;/p&gt;
&lt;p&gt;That was&amp;nbsp;it.&lt;/p&gt;
&lt;p&gt;&lt;hr&gt;&lt;/hr&gt;&lt;/p&gt;
&lt;p&gt;We were in college, and my friends and I were all &lt;em&gt;internet natives&lt;/em&gt;. We had used the web for over ten years. We grew up in &lt;span class="caps"&gt;AOL&lt;/span&gt; chatrooms and forums. The backwaters of the internet at this time shifted from Something Awful to 4Chan. This was the height of some of the most prolific and hilarious memes: lolcats, &lt;a href="http://knowyourmeme.com/memes/xzibit-yo-dawg"&gt;Xzibit&lt;/a&gt;, &lt;a href="http://knowyourmeme.com/memes/advice-dog"&gt;advice dogs&lt;/a&gt; (a favorite was &lt;a href="http://knowyourmeme.com/memes/foul-bachelor-frog"&gt;bachelor frog&lt;/a&gt;, which seemed to understand our worst impulses expressed in only modest&amp;nbsp;exaggeration). &lt;/p&gt;
&lt;p&gt;There was also&amp;nbsp;violence.&lt;/p&gt;
&lt;p&gt;It was not uncommon to see names, phone numbers, and addresses that 4chan was supposed to harass because someone said so. Various subcultures seemed to be alternatively mocked and harassed endlessly in the very place that had first embraced, supported, and connected people under the guise of radical anonymity. The most famous of the &amp;#8220;&lt;a href="http://knowyourmeme.com/memes/rules-of-the-internet"&gt;Rules of the Internet&lt;/a&gt;&amp;#8221; was Rule 34 &amp;#8212; if you can think of it, there is a porn of it&amp;#8212; and its follow up, Rule 35 &amp;#8212; if you can not find porn of it, you should make it. 4chan seemed determined to make this a reality. But really the most troublesome thing was the attitude toward women. Nothing was as unacceptable to 4chan as suggesting that women are anything but objects for male gaze. In a place sometimes filled with radically liberal (if more left-libertarian than left-progressive) politics that would spawn groups like &lt;a href="http://knowyourmeme.com/memes/subcultures/anonymous"&gt;Anonymous&lt;/a&gt;, nothing brought out as much criticism as suggesting our culture has a problem with&amp;nbsp;women.&lt;/p&gt;
&lt;p&gt;My response was largely to fade from this part of the internet. I had only reached the point of being &lt;em&gt;uncomfortable&lt;/em&gt; with this behavior. It would take more time for me to understand. It still felt like this was a problem of ignorant&amp;nbsp;people.&lt;/p&gt;
&lt;p&gt;&lt;hr&gt;&lt;/hr&gt;&lt;/p&gt;
&lt;p&gt;I am rarely jealous of intelligence. I am rarely jealous of wealth. I am rarely jealous of experiences. What I am most often jealous of is what seems to me to be a preternatural maturity of others, particularly around issues of ethics and human&amp;nbsp;rights.&lt;/p&gt;
&lt;p&gt;Fully grappling with privilege is not something that happens over a moment, it is a sensitivity to be developed over a lifetime. We are confronted with media that builds and reinforces a culture that is fundamentally intolerant and conservative. There are countless microaggressions that are modeled everywhere for our acceptance as normal. It has taken me a decade of maturation, hard conversations, and self-examination to only begin to grow from fully complicit and participating in objectification of women to what I would now consider to be the most basic level of human&amp;nbsp;decency.&lt;/p&gt;
&lt;p&gt;The internet has gone from enabling my own aggression toward women to exposing me to a level of misogyny and violence that deeply disturbs and disgusts me, shattering any notion that my past offenses were harmless or victimless. The ugly underside of our culture is constantly on display, making it all the more obvious how what felt like isolated events on the &amp;#8220;ok&amp;#8221; side of the line were actaully creating a space that supported and nurtured the worst compulsions of&amp;nbsp;men.&lt;/p&gt;
&lt;p&gt;&lt;hr&gt; &lt;/hr&gt;&lt;/p&gt;
&lt;p&gt;I often think about my own journey when I see disgusting behavior on the internet. I wonder whether I am facing a deeply, ugly person or myself at 16. I try to parse the difference between naïvety, ignorance, and hate and to understand if they require a unique&amp;nbsp;response. &lt;/p&gt;
&lt;p&gt;Mostly, I struggle with what would happen if Jason Today spoke to Jason&amp;nbsp;16. &lt;/p&gt;
&lt;p&gt;Jason 16 could not skip over a decade of growth simply for having met Jason Today. It took me conversations with various folks playing the role of Jason Today over and over again, year after year. I wish I believed there was another way to reach the Jason 16s out there. I wish I knew how to help them become preternaturally aware of their actions. All I know how to do is try to be compassionate to those who hate while firmly correcting, try to meet the heightened expectations I place on myself, try to apologize when I need to, and try to support those that seem more equipped to push the conversation&amp;nbsp;forward.&lt;/p&gt;
&lt;p&gt;Along this path, I never lept to agreement so much as paused. Each time I heard a convincing point, I paused and considered. Growth came in a series of all too brief&amp;nbsp;pauses.&lt;/p&gt;
&lt;p&gt;Pauses are often private and quiet, its discoveries never on direct&amp;nbsp;display.&lt;/p&gt;
&lt;p&gt;If pauses are the best anyone can expect, then working to change our culture of violence toward women will rarely feel like much more than shouting at the&amp;nbsp;void.&lt;/p&gt;</summary><category term="feminism"></category><category term="internet"></category></entry><entry><title>When We Legislate and Ajudicate Our World View</title><link href="http://blog.jsonbecker.com/2014/06/when-we-legislate-and-ajudicate-our-world-view.html" rel="alternate"></link><updated>2014-06-13T14:00:00-04:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2014-06-13:2014/06/when-we-legislate-and-ajudicate-our-world-view.html</id><summary type="html">&lt;p&gt;The &lt;em&gt;Vergara v. California&lt;/em&gt; case has everyone in education talking. Key teacher tenure provisions in California are on the ropes, presumably because of the disparate impact on teacher, annd therefore education, quality for students who are less&amp;nbsp;fortunate.&lt;/p&gt;
&lt;p&gt;I have fairly loosely held views about the practice of tenure itself and the hiring and firing of teachers. However, I have strongly held views that unions made mistake with their efforts to move a lot of rules about the teaching labor market into state laws across the country. Deep rules and restrictions are better left to contracts, even from a union perpsective. At worst, these things should be a part of regulation, which can be more easily adapted and&amp;nbsp;waived.&lt;/p&gt;
&lt;p&gt;That said, here are a collection of interesting thoughts on tenure post-&lt;em&gt;Vergara&lt;/em&gt;:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a href="http://takingnote.learningmatters.tv/?p=7032"&gt;John Merrow, reacting to &lt;em&gt;Vergara&lt;/em&gt;&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Tenure and due process are essential, in my view, but excessive protectionism (70+ steps to remove a teacher?) alienates the general public and the majority of effective teachers, particularly young teachers who are still full of idealism and resent seeing their union spend so much money defending teachers who probably should have been counseled out of the profession years&amp;nbsp;ago.&lt;/p&gt;
&lt;p&gt;With the modal ‘years of experience’ of teachers dropping dramatically, from 15 years in 1987 to 1 or 2 years today, young teachers are a force to be reckoned with. If a significant number of them abandon the familiar &lt;span class="caps"&gt;NEA&lt;/span&gt;/&lt;span class="caps"&gt;AFT&lt;/span&gt; model, or if they develop and adopt a new form of teacher unionism, public education and the teaching profession will be forever&amp;nbsp;changed.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;&lt;a href="http://www.mercurynews.com/education/ci_25724972/longer-pre-tenure-probationary-period-san-jose-teachers"&gt;San Jose Mercury News reporting on the state thwarting a locally negotiated change to tenure&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;With little discussion, the board rejected the request, 7 to 2. The California Teachers Association, one of the most powerful lobbies in Sacramento, had opposed granting a two-year waiver from the state Education Code &amp;#8212; even though one of the &lt;span class="caps"&gt;CTA&lt;/span&gt;&amp;#8217;s locals had sought the exemption&amp;#8230;
&amp;#8230;San Jose Teachers Association President Jennifer Thomas, whose union had tediously negotiated with the district an agreement to improve teacher evaluations and teaching quality, called the vote frustrating&amp;#8230;
San Jose Unified and the local teachers association sought flexibility to grant teachers tenure after one year or to keep a teacher on probation for three&amp;nbsp;years.&lt;/p&gt;
&lt;p&gt;The district argued that 18 months &amp;#8212; the point in a teacher&amp;#8217;s career at which districts must make a tenure decision &amp;#8212; sometimes doesn&amp;#8217;t allow time to fairly evaluate a candidate for what can be a lifetime&amp;nbsp;job.&lt;/p&gt;
&lt;p&gt;Now, Thomas said, when faced with uncertainty over tenure candidates, administrators will err on the side of releasing them, which then leaves a stain on their&amp;nbsp;records.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;&lt;a href=""&gt;Kevin Welner summarzing some of the legal implications of &lt;em&gt;Vergara&lt;/em&gt;&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Although I can’t help but feel troubled by the attack on teachers and their hard-won rights, and although I think the court’s opinion is quite weak, legally as well as logically, my intent here is not to disagree with that decision. In fact, as I explain below, the decision gives real teeth to the state’s Constitution, and that could be a very good thing. It’s those teeth that I find fascinating, since an approach like that used by the Vergara judge could put California courts in a very different role —as a guarantor of educational equality—than we have thus far seen in the United States&amp;#8230;
&amp;#8230;To see why this is important, consider an area of education policy that I have researched a great deal over the years: tracking (aka “ability grouping”). There are likely hundreds of thousands of children in California who are enrolled in low-track classes, where the expectations, curricula and instruction are all watered down. These children are denied equal educational opportunities; the research regarding the harms of these low-track classes is much stronger and deeper than the research about teachers Judge Treu found persuasive in the Vergara case. That is, plaintiffs’ attorneys would easily be able to show a “real and appreciable impact” on students’ fundamental right to equality of education. Further, the harm from enrollment in low-track classes falls disproportionately on lower-income students and students of color. (I’ll include some citations to tracking research from myself and others at the end of this&amp;nbsp;post.)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Welner also repeats a common refrain from the education-left that tenure and insulating teachers from evaluations is critical for attracting quality people into the teaching profession. This is an argument that the &lt;em&gt;general equilibrium&lt;/em&gt; impact on the broader labor market is both larger in magnitude and in the opposite direction of any assumed positive impacts from easier dismissal of poor performing&amp;nbsp;teachers:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This more holistic view is important because the statutes are central to the larger system of teacher employment. That is, one would expect that a &lt;span class="caps"&gt;LIFO&lt;/span&gt; statute or a due process statute or tenure statute would shape who decides to become a teacher and to stay in the profession. These laws, in short, influence the nature of teaching as a profession. The judge here omits any discussion of the value of stability and experience in teaching that tenure laws, however imperfectly, were designed to promote in order to attract and retain good teachers. By declining to consider the complexity of the system, the judge has started to pave a path that looks more narrowly at defined, selected, and immediate impact—which could potentially be of great benefit to future education rights&amp;nbsp;plaintiffs.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;em&gt;&lt;a href="http://www.forbes.com/sites/modeledbehavior/2014/06/13/should-everyone-have-tenure/"&gt;Adam Ozimek of Modeled Behavior&lt;/a&gt;&lt;/em&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I can certainly imagine it is possible in some school districts they will find it optimal to fire very few teachers. But why isn’t it enough for administrators to simply rarely fire people, and for districts to cultivate reputations as places of stable employment? One could argue that administrators can’t be trusted to actually do this, but such distrust of administrators brings back a fundamental problem with this model of public education: if your administrators are too incompetent to cultivate a reputation that is optimal for student outcomes then banning tenure is hardly the problem, and imposing tenure is hardly a solution. This is closely related to a point I made yesterday: are we supposed to believe administrators fire sub-optimally but hire&amp;nbsp;optimally&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;His piece from today (and &lt;a href="http://www.forbes.com/sites/modeledbehavior/2014/06/12/putting-teacher-tenure-in-context/"&gt;this one from yesterday&lt;/a&gt;) argues that Welner&amp;#8217;s take could be applied to just about any profession, and furthermore, requires accepting a far deeper, more fundamental structural problem in education that should be unacceptable. If administrators would broadly act so foolishly as to decimate the market for quality teaching talent and be wholly unable to successfully staff their schools, we have far bigger problems. And, says Ozimek, there is no reason to believe that tenure is at all a response to this&amp;nbsp;issue.&lt;/p&gt;
&lt;p&gt;Dana Goldstein would likely take a more &lt;a href="http://www.amazon.com/dp/038553695X/?tag=jasonpbeckerc-20"&gt;historical view&lt;/a&gt; on the usefulness of tenure against adminstrator&amp;nbsp;abuse. &lt;/p&gt;
&lt;p&gt;&lt;em&gt;&lt;a href="http://www.theatlantic.com/education/archive/2014/06/california-rules-teacher-tenure-laws-unconstitutional/372536/"&gt;But, writing for The Atlantic&lt;/a&gt;&lt;/em&gt;, she focuses instead on tenure as a red&amp;nbsp;herring:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The lesson here is that California’s tenure policies may be insensible, but they aren’t the only, or even the primary, driver of the teacher-quality gap between the state’s middle-class and low-income schools. The larger problem is that too few of the best teachers are willing to work long-term in the country’s most racially isolated and poorest neighborhoods. There are lots of reasons why, ranging from plain old racism and classism to the higher principal turnover that turns poor schools into chaotic workplaces that mature teachers avoid. The schools with the most poverty are also more likely to focus on standardized test prep, which teachers dislike. Plus, teachers tend to live in middle-class neighborhoods and may not want a long&amp;nbsp;commute.&lt;/p&gt;
&lt;/blockquote&gt;</summary><category term="tenure"></category><category term="education"></category></entry><entry><title>They really don't make them like they used to...</title><link href="http://blog.jsonbecker.com/2014/05/they-really-dont-make-them-like-they-used-to.html" rel="alternate"></link><updated>2014-05-20T11:17:41-04:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2014-05-20:2014/05/they-really-dont-make-them-like-they-used-to.html</id><summary type="html">&lt;p&gt;I have never found dictionaries or even a thesaurus particularly useful as part of the writing process. I like to blame this on my lack of &lt;del&gt;creative&lt;/del&gt; careful&amp;nbsp;writing.&lt;/p&gt;
&lt;p&gt;But just maybe, I have simply been using the wrong dictionaries. It is hard not to be seduced by the seeming superiority of Webster&amp;#8217;s original style. A dictionary that is one-part explanatory and one-part &lt;em&gt;exploratory&lt;/em&gt; provides a much richer experience of English as an enabler of ideas that transend meager&amp;nbsp;vocabulary.&lt;/p&gt;</summary><category term="dictionary"></category><category term="writing"></category><category term="Webster"></category></entry><entry><title>Pindown: Failed Dreams</title><link href="http://blog.jsonbecker.com/2014/05/pindown-failed-dreams.html" rel="alternate"></link><updated>2014-05-13T21:52:00-04:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2014-05-13:2014/05/pindown-failed-dreams.html</id><summary type="html">&lt;p&gt;I had never thought of a use for &lt;a href="http://www.brettterpstra.com"&gt;Brett Terpstra&amp;#8217;s&lt;/a&gt; &lt;a href="http://heckyesmarkdown.com"&gt;Marky the Markdownifier&lt;/a&gt; before listening today&amp;#8217;s &lt;a href="http://5by5.tv/systematic/96"&gt;Systematic&lt;/a&gt;. Why would I want to turn a webpage into&amp;nbsp;Markdown?&lt;/p&gt;
&lt;p&gt;When I heard that Marky has an &lt;span class="caps"&gt;API&lt;/span&gt;, I was inspired. &lt;a href="http://pinboard.in"&gt;Pinboard&lt;/a&gt; has a &amp;#8220;description&amp;#8221; field that allows up to 65,000 characters. I never know what to put in this box. Wouldn&amp;#8217;t it be great to put the full content of the page in Markdown into this&amp;nbsp;field?&lt;/p&gt;
&lt;p&gt;I set out to write a quick Python script&amp;nbsp;to:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Grab recent Pinboard&amp;nbsp;links.&lt;/li&gt;
&lt;li&gt;Check to see if the URLs still&amp;nbsp;resolve.&lt;/li&gt;
&lt;li&gt;Send the link to Marky and collect a Markdown version of the&amp;nbsp;content.&lt;/li&gt;
&lt;li&gt;Post an updated link to Pinboard with the Markdown in the description&amp;nbsp;field.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If all went well, I would release this script on Github as &lt;strong&gt;Pindown&lt;/strong&gt;, a great way to put Markdown page content into your Pinboard&amp;nbsp;links.&lt;/p&gt;
&lt;p&gt;The script below is far from well-constructed. I would have spent more time cleaning it up with things like better error handling and a more complete &lt;span class="caps"&gt;CLI&lt;/span&gt; to give more granular control over which links receive Markdown&amp;nbsp;content. &lt;/p&gt;
&lt;p&gt;Unfortunately, I found that Pinboard consistently returns a &lt;a href="http://www.checkupdown.com/status/E414.html"&gt;414 error code&lt;/a&gt; because the URLs are too long. Why is this a problem? Pinboard, in an attempt to &lt;a href="https://pinboard.in/api/"&gt;maintain compatibility&lt;/a&gt; with the &lt;a href="http://del.ico.us"&gt;del.ico.us&lt;/a&gt; &lt;span class="caps"&gt;API&lt;/span&gt; uses only &lt;span class="caps"&gt;GET&lt;/span&gt; requests, whereas this kind of request would typically use a &lt;span class="caps"&gt;POST&lt;/span&gt; end point. As a result, I cannot send along a data&amp;nbsp;payload.&lt;/p&gt;
&lt;p&gt;So I&amp;#8217;m sharing this just for folks who are interested in playing with Python, RESTful APIs, and Pinboard. I&amp;#8217;m also posting for my own posterity since a &lt;a href="https://groups.google.com/d/msg/pinboard-dev/Od6sCzREeBU/L-WKgX6vUDoJ"&gt;non-Del.ico.us compatible version 2 of the Pinboard &lt;span class="caps"&gt;API&lt;/span&gt; is coming&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;requests&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;json&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;yaml&lt;/span&gt;


&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;getDataSet&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;call&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;https://api.pinboard.in/v1/posts/recent&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;call&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;data_set&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;json&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;loads&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_content&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;data_set&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;checkURL&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;newurl&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;newurl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;status_code&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="mi"&gt;200&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;newurl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;
  &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="k"&gt;raise&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;your message&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;newurl&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;status_code&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;markyCall&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;http://heckyesmarkdown.com/go/?u=&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;_content&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;process_site&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;call&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;data_set&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;getDataSet&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;call&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;processed_site&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
  &lt;span class="n"&gt;errors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;site&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;data_set&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;posts&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;
    &lt;span class="k"&gt;try&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;checkURL&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;site&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;href&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="k"&gt;except&lt;/span&gt; &lt;span class="ne"&gt;ValueError&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
      &lt;span class="n"&gt;errors&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;site&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;href&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;description&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;markyCall&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;site&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;extended&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;description&lt;/span&gt;
    &lt;span class="n"&gt;processed_site&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;site&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;errors&lt;/span&gt;
  &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="n"&gt;processed_site&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;write_pinboard&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;site&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;auth_token&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
  &lt;span class="n"&gt;stem&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;https://api.pinboard.in/v1/posts/add?format=json&amp;amp;auth_token=&amp;#39;&lt;/span&gt;
  &lt;span class="n"&gt;payload&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;{}&lt;/span&gt;
  &lt;span class="n"&gt;payload&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;url&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;site&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;href&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;payload&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;description&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;site&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;description&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;payload&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;extended&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;site&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;extended&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;payload&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;tags&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;site&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;tags&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;payload&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;shared&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;site&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;extended&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;no&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;payload&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;toread&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;site&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;toread&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;no&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;           
  &lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;stem&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;auth_token&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;params&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;payload&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;print&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;site&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;href&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\t\t&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;status_code&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;main&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
  &lt;span class="n"&gt;settings&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;file&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;AUTH.yaml&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;rw&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;identity&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;yaml&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;load&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;AUTH&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;yaml&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="n"&gt;auth_token&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;identity&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;user_name&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;:&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;identity&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;token&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="n"&gt;valid_sites&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;process_site&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;?format=json&amp;amp;auth_token=&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="n"&gt;auth_token&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;site&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;valid_sites&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;write_pinboard&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;site&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;auth_token&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;main&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="pinboard"></category><category term="markdown"></category><category term="python"></category><category term="code"></category></entry><entry><title>Symlinking Your Data</title><link href="http://blog.jsonbecker.com/2014/04/symlinking-your-data.html" rel="alternate"></link><updated>2014-04-02T15:50:00-04:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2014-04-02:2014/04/symlinking-your-data.html</id><summary type="html">&lt;p&gt;I frequently work with private data. Sometimes, it lives on my personal machine rather than on a database server. Sometimes, even if it lives on a remote database server, it is better that I use locally cached data than query the database each time I want to do analysis on the data set. I have always dealt with this by &lt;a href="http://support.apple.com/kb/HT1578?viewlocale=en_US&amp;amp;locale=en_US"&gt;creating encrypted disk images&lt;/a&gt; with secure passwords (stored in &lt;a href="https://agilebits.com"&gt;1Password&lt;/a&gt;). This is a nice extra layer of protection for private data served on a laptop, and it adds little complication to my workflow. I just have to remember to mount and unmount the disk&amp;nbsp;images.&lt;/p&gt;
&lt;p&gt;However, it can be inconvenient from a project perspective to refer to data in a distant location like &lt;code&gt;/Volumes/ClientData/Entity/facttable.csv&lt;/code&gt;. In most cases, I would prefer the data &amp;#8220;reside&amp;#8221; in &lt;code&gt;data/&lt;/code&gt; or &lt;code&gt;cache/&lt;/code&gt; &lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;inside&amp;#8221; of my project&amp;nbsp;directory.&lt;/p&gt;
&lt;p&gt;Luckily, there is a great way that allows me to point to &lt;code&gt;data/facttable.csv&lt;/code&gt; in my R code without actually having &lt;code&gt;facttable.csv&lt;/code&gt; reside there:&amp;nbsp;symlinking.&lt;/p&gt;
&lt;p&gt;A &lt;a href="http://en.wikipedia.org/wiki/Symbolic_link"&gt;symlink&lt;/a&gt; is a &lt;strong&gt;symbolic link&lt;/strong&gt; file that sits in the preferred location and references the file path to the actual file. This way, when I refer to &lt;code&gt;data/facttable.csv&lt;/code&gt; the file system knows to direct all of that activity to the actual file in &lt;code&gt;/Volumes/ClientData/Entity/facttable.csv&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;From the command line, a symlink can be generated with a simple&amp;nbsp;command:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;ln -s target_path link_path
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;R offers a function that does the same&amp;nbsp;thing:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;file.symlink&lt;span class="p"&gt;(&lt;/span&gt;target_path&lt;span class="p"&gt;,&lt;/span&gt; link_path&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;where &lt;code&gt;target_path&lt;/code&gt; and &lt;code&gt;link_path&lt;/code&gt; are both strings surrounded by quotation&amp;nbsp;marks.&lt;/p&gt;
&lt;p&gt;One of the first things I do when setting up a new analysis is add common data storage file extensions like &lt;code&gt;.csv&lt;/code&gt; and &lt;code&gt;.xls&lt;/code&gt; to my &lt;code&gt;.gitignore&lt;/code&gt; file so that I do not mistakenly put any data in a remote repository. The second thing I do is set up symlinks to the mount location of the encrypted&amp;nbsp;data.&lt;/p&gt;</summary><category term="rstats"></category><category term="symlink"></category><category term="data"></category><category term="encryption"></category><category term="privacy"></category></entry><entry><title>Expressiveness Counts</title><link href="http://blog.jsonbecker.com/2014/03/expressiveness-counts.html" rel="alternate"></link><updated>2014-03-10T19:30:00-04:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2014-03-10:2014/03/expressiveness-counts.html</id><summary type="html">&lt;p&gt;Education data often come in annual snapshots. Each year, students are able to identify anew, and while student identification numbers may stay the same, names, race, and gender can often change. Sometimes, even data that probably should not change, like a date of birth, is altered at some point. While I could spend all day talking about data collection processes and automated validation that should assist with maintaining clean data, most researchers face multiple characteristics per student, unsure of which one is&amp;nbsp;accurate.&lt;/p&gt;
&lt;p&gt;While it is true that identity is fluid, and sex/gender or race identifications are not inherently stable overtime, it is often necessary to &amp;#8220;choose&amp;#8221; a single value for each student when presenting data. The &lt;a href="http://www.strategicdataproject.com"&gt;Strategic Data Project&lt;/a&gt; does a great job of defining the business rules for these cases in its &lt;a href="http://www.gse.harvard.edu/sdp/resources/toolkit.php"&gt;diagnostic toolkits&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If more than one [attribute value is] observed, report the modal [attribute value]. If multiple modes are observed, report the most recent [attribute value]&amp;nbsp;recorded.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is their rule for all attributes considered &lt;em&gt;time-invariant&lt;/em&gt; for analysis purposes. I think it is a pretty good&amp;nbsp;one.&lt;/p&gt;
&lt;p&gt;Implementing this rule turned out to be more complex than it appeared using R, especially with performant code. In fact, it was this business rule that led me to learn how to use the &lt;code&gt;data.table&lt;/code&gt; package.&lt;/p&gt;
&lt;p&gt;First, I developed a small test set of data to help me make sure my code accurately reflected the expected results based on the business&amp;nbsp;rule:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c1"&gt;# Generate test data for modal_attribute().&lt;/span&gt;
modal_test &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; data.frame&lt;span class="p"&gt;(&lt;/span&gt;sid &lt;span class="o"&gt;=&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;1000&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;1001&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;1000&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;1000&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;1005&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                 &lt;span class="s"&gt;&amp;#39;1005&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; rep&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;1006&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;
                         race &lt;span class="o"&gt;=&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Black&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;White&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Black&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Hispanic&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                  &lt;span class="s"&gt;&amp;#39;White&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;White&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; rep&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Black&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; 
                                  rep&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Hispanic&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;
                         year &lt;span class="o"&gt;=&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;2006&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;2006&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;2007&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;2008&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                  &lt;span class="m"&gt;2010&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;2011&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;2007&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;2008&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                  &lt;span class="m"&gt;2010&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;2011&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The test data generated by that code looks like&amp;nbsp;this:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;sasid&lt;/th&gt;
&lt;th&gt;race&lt;/th&gt;
&lt;th&gt;year&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1000&lt;/td&gt;
&lt;td&gt;Black&lt;/td&gt;
&lt;td&gt;2006&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1001&lt;/td&gt;
&lt;td&gt;White&lt;/td&gt;
&lt;td&gt;2006&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1000&lt;/td&gt;
&lt;td&gt;Black&lt;/td&gt;
&lt;td&gt;2007&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1000&lt;/td&gt;
&lt;td&gt;Hispanic&lt;/td&gt;
&lt;td&gt;2008&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1005&lt;/td&gt;
&lt;td&gt;White&lt;/td&gt;
&lt;td&gt;2010&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1005&lt;/td&gt;
&lt;td&gt;White&lt;/td&gt;
&lt;td&gt;2011&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1006&lt;/td&gt;
&lt;td&gt;Black&lt;/td&gt;
&lt;td&gt;2007&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1006&lt;/td&gt;
&lt;td&gt;Black&lt;/td&gt;
&lt;td&gt;2008&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1006&lt;/td&gt;
&lt;td&gt;Hispanic&lt;/td&gt;
&lt;td&gt;2010&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1006&lt;/td&gt;
&lt;td&gt;Hispanic&lt;/td&gt;
&lt;td&gt;2011&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;And the results should&amp;nbsp;be:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;sasid&lt;/th&gt;
&lt;th&gt;race&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1000&lt;/td&gt;
&lt;td&gt;Black&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1001&lt;/td&gt;
&lt;td&gt;White&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1005&lt;/td&gt;
&lt;td&gt;White&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1006&lt;/td&gt;
&lt;td&gt;Hispanic&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;My first attempts at solving this problem using &lt;code&gt;data.table&lt;/code&gt; resulted in a pretty complex set of&amp;nbsp;code.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c1"&gt;# Calculate the modal attribute using data.table&lt;/span&gt;
modal_person_attribute_dt &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;df&lt;span class="p"&gt;,&lt;/span&gt; attribute&lt;span class="p"&gt;){&lt;/span&gt;
  &lt;span class="c1"&gt;# df: rbind of all person tables from all years&lt;/span&gt;
  &lt;span class="c1"&gt;# attribute: vector name to calculate the modal value&lt;/span&gt;
  &lt;span class="c1"&gt;# Calculate the number of instances an attributed is associated with an id&lt;/span&gt;
  dt &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; data.table&lt;span class="p"&gt;(&lt;/span&gt;df&lt;span class="p"&gt;,&lt;/span&gt; key&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;sasid&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  mode &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; dt&lt;span class="p"&gt;[,&lt;/span&gt; rle&lt;span class="p"&gt;(&lt;/span&gt;as.character&lt;span class="p"&gt;(&lt;/span&gt;.SD&lt;span class="p"&gt;[[&lt;/span&gt;attribute&lt;span class="p"&gt;]])),&lt;/span&gt; by&lt;span class="o"&gt;=&lt;/span&gt;sasid&lt;span class="p"&gt;]&lt;/span&gt;
  setnames&lt;span class="p"&gt;(&lt;/span&gt;mode&lt;span class="p"&gt;,&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;sasid&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;counts&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; as.character&lt;span class="p"&gt;(&lt;/span&gt;attribute&lt;span class="p"&gt;)))&lt;/span&gt;
  setkeyv&lt;span class="p"&gt;(&lt;/span&gt;mode&lt;span class="p"&gt;,&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;sasid&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;counts&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="c1"&gt;# Only include attributes with the maximum values. This is equivalent to the&lt;/span&gt;
  &lt;span class="c1"&gt;# mode with two records when there is a tie.&lt;/span&gt;
  mode &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; mode&lt;span class="p"&gt;[,&lt;/span&gt;subset&lt;span class="p"&gt;(&lt;/span&gt;.SD&lt;span class="p"&gt;,&lt;/span&gt; counts&lt;span class="o"&gt;==&lt;/span&gt;max&lt;span class="p"&gt;(&lt;/span&gt;counts&lt;span class="p"&gt;)),&lt;/span&gt; by&lt;span class="o"&gt;=&lt;/span&gt;sasid&lt;span class="p"&gt;]&lt;/span&gt;
  mode&lt;span class="p"&gt;[,&lt;/span&gt;counts&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="kc"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  setnames&lt;span class="p"&gt;(&lt;/span&gt;mode&lt;span class="p"&gt;,&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;sasid&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; attribute&lt;span class="p"&gt;))&lt;/span&gt;
  setkeyv&lt;span class="p"&gt;(&lt;/span&gt;mode&lt;span class="p"&gt;,&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;sasid&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;attribute&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="c1"&gt;# Produce the maximum year value associated with each ID-attribute &lt;/span&gt;
  &lt;span class="c1"&gt;# pairing    &lt;/span&gt;
  setkeyv&lt;span class="p"&gt;(&lt;/span&gt;dt&lt;span class="p"&gt;,&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;sasid&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;attribute&lt;span class="p"&gt;))&lt;/span&gt;
  mode &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; dt&lt;span class="p"&gt;[,&lt;/span&gt;list&lt;span class="p"&gt;(&lt;/span&gt;schoolyear&lt;span class="o"&gt;=&lt;/span&gt;max&lt;span class="p"&gt;(&lt;/span&gt;schoolyear&lt;span class="p"&gt;)),&lt;/span&gt; by&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;sasid&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; attribute&lt;span class="p"&gt;)][&lt;/span&gt;mode&lt;span class="p"&gt;]&lt;/span&gt;
  setkeyv&lt;span class="p"&gt;(&lt;/span&gt;mode&lt;span class="p"&gt;,&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;sasid&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;schoolyear&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="c1"&gt;# Select the last observation for each ID, which is equivalent to the highest&lt;/span&gt;
  &lt;span class="c1"&gt;# schoolyear value associated with the most frequent attribute.&lt;/span&gt;
  result &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; mode&lt;span class="p"&gt;[,&lt;/span&gt;lapply&lt;span class="p"&gt;(&lt;/span&gt;.SD&lt;span class="p"&gt;,&lt;/span&gt; tail&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; by&lt;span class="o"&gt;=&lt;/span&gt;sasid&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="c1"&gt;# Remove the schoolyear to clean up the result&lt;/span&gt;
  result &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; result&lt;span class="p"&gt;[,&lt;/span&gt;schoolyear&lt;span class="o"&gt;:=&lt;/span&gt;&lt;span class="kc"&gt;NULL&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="kr"&gt;return&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;as.data.frame&lt;span class="p"&gt;(&lt;/span&gt;result&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This approached seemed &amp;#8220;natural&amp;#8221; in &lt;code&gt;data.table&lt;/code&gt;, although it took me a while to refine and debug since it was my first time using the package &lt;sup id="fnref:2012"&gt;&lt;a class="footnote-ref" href="#fn:2012" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;. Essentially, I use &lt;code&gt;rle&lt;/code&gt;, a nifty function I used in the past for my &lt;a href="http://blog.jsonbecker.com/2012/07/ranked-likert-scale-visualization.html"&gt;Net-Stacked Likert&lt;/a&gt; code to count the number of instances of an attribute each student had in their record. I then subset the data to only the max count value for each student and merge these values back to the original data set. Then I order the data by student id and year in order to select only the last observation per&amp;nbsp;student.&lt;/p&gt;
&lt;p&gt;I get a quick, accurate answer when I run the test data through this function. Unfortunately, when I ran the same code on approximately 57,000 unique student IDs and 211,000 total records, the results were less inspiring. My Macbook Air&amp;#8217;s fans spin up to full speed and timings are&amp;nbsp;terrible:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; system.time&lt;span class="p"&gt;(&lt;/span&gt;modal_person_attribute&lt;span class="p"&gt;(&lt;/span&gt;all_years&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;sex&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
 user  system elapsed 
 &lt;span class="m"&gt;40.452&lt;/span&gt;   &lt;span class="m"&gt;0.246&lt;/span&gt;  &lt;span class="m"&gt;41.346&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Data cleaning tasks like this one are often only run a few times. Once I have the attributes I need for my analysis, I can save them to a new table in a database, &lt;span class="caps"&gt;CSV&lt;/span&gt;, or similar and never run it again. But ideally, I would like to be able to build a document presenting my data completely from the raw delivered data, including all cleaning steps, accurately. So while I may use a cached, clean data set for some the more sophisticated analysis while I am building up a report, in the final stages I begin running the entire analyses process, including data cleaning, each time I produce the&amp;nbsp;report.&lt;/p&gt;
&lt;p&gt;With the release of &lt;code&gt;dplyr&lt;/code&gt;, I wanted to reexamine this particular function because it is one of the slowest steps in my analysis. I thought with fresh eyes and a new way of expressing R code, I may be able to improve on the original function. Even if its performance ended up being fairly similar, I hoped the &lt;code&gt;dplyr&lt;/code&gt; code would be easier to maintain since I frequently use &lt;code&gt;dplyr&lt;/code&gt; and only turn to &lt;code&gt;data.table&lt;/code&gt; in specific, sticky situations where performance&amp;nbsp;matters.&lt;/p&gt;
&lt;p&gt;In about a tenth the time it took to develop the original code, I came up with this new&amp;nbsp;function:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;modal_person_attribute &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;,&lt;/span&gt; sid&lt;span class="p"&gt;,&lt;/span&gt; attribute&lt;span class="p"&gt;,&lt;/span&gt; year&lt;span class="p"&gt;){&lt;/span&gt;
  grouping &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; lapply&lt;span class="p"&gt;(&lt;/span&gt;list&lt;span class="p"&gt;(&lt;/span&gt;sid&lt;span class="p"&gt;,&lt;/span&gt; attribute&lt;span class="p"&gt;),&lt;/span&gt; as.symbol&lt;span class="p"&gt;)&lt;/span&gt;
  original &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; x
  max_attributes &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; x &lt;span class="o"&gt;%.%&lt;/span&gt; 
                    regroup&lt;span class="p"&gt;(&lt;/span&gt;grouping&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%.%&lt;/span&gt;
                    summarize&lt;span class="p"&gt;(&lt;/span&gt;count &lt;span class="o"&gt;=&lt;/span&gt; n&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="o"&gt;%.%&lt;/span&gt;
                    filter&lt;span class="p"&gt;(&lt;/span&gt;count &lt;span class="o"&gt;==&lt;/span&gt; max&lt;span class="p"&gt;(&lt;/span&gt;count&lt;span class="p"&gt;))&lt;/span&gt;
  recent_max &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; left_join&lt;span class="p"&gt;(&lt;/span&gt;original&lt;span class="p"&gt;,&lt;/span&gt; max_attributes&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%.%&lt;/span&gt;
                regroup&lt;span class="p"&gt;(&lt;/span&gt;list&lt;span class="p"&gt;(&lt;/span&gt;grouping&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]]))&lt;/span&gt; &lt;span class="o"&gt;%.%&lt;/span&gt;
                filter&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;is.na&lt;span class="p"&gt;(&lt;/span&gt;count&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; count &lt;span class="o"&gt;==&lt;/span&gt; max&lt;span class="p"&gt;(&lt;/span&gt;count&lt;span class="p"&gt;))&lt;/span&gt;
  results &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; recent_max &lt;span class="o"&gt;%.%&lt;/span&gt; 
             regroup&lt;span class="p"&gt;(&lt;/span&gt;list&lt;span class="p"&gt;(&lt;/span&gt;grouping&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]]))&lt;/span&gt; &lt;span class="o"&gt;%.%&lt;/span&gt;
             filter&lt;span class="p"&gt;(&lt;/span&gt;year &lt;span class="o"&gt;==&lt;/span&gt; max&lt;span class="p"&gt;(&lt;/span&gt;year&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="kr"&gt;return&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;results&lt;span class="p"&gt;[,&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;sid&lt;span class="p"&gt;,&lt;/span&gt; attribute&lt;span class="p"&gt;)])&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;At least to my eyes, this code is far more expressive and elegant. First, I generate a &lt;code&gt;data.frame&lt;/code&gt; with only the rows that have the most common attribute per student by grouping on student and attribute, counting the size of those groups, and filtering to most common group per student. Then, I do join on the original data and remove any records without a count from the previous step, finding the maximum count per student &lt;span class="caps"&gt;ID&lt;/span&gt;. This recovers the year value for each of the students so that in the next step I can just choose the rows with the highest&amp;nbsp;year.&lt;/p&gt;
&lt;p&gt;There are a few funky things (note the use of regroup and grouping, which are related to &lt;code&gt;dplyr&lt;/code&gt;&lt;span class="quo"&gt;&amp;#8216;&lt;/span&gt;s poor handling of strings as arguments), but for the most part I have shorter, clearer code that closely resembles the plain-English stated business&amp;nbsp;rule.&lt;/p&gt;
&lt;p&gt;But was this code more performant? Imagine my glee when this&amp;nbsp;happened:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; system.time&lt;span class="p"&gt;(&lt;/span&gt;modal_person_attribute_dplyr&lt;span class="p"&gt;(&lt;/span&gt;all_years&lt;span class="p"&gt;,&lt;/span&gt; sid&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;sasid&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
&lt;span class="o"&gt;&amp;gt;&lt;/span&gt; attribute&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;sex&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; year&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;schoolyear&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
Joining by&lt;span class="o"&gt;:&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;sasid&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;sex&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
   user  system elapsed 
  &lt;span class="m"&gt;1.657&lt;/span&gt;   &lt;span class="m"&gt;0.087&lt;/span&gt;   &lt;span class="m"&gt;1.852&lt;/span&gt; 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That is a remarkable increase in&amp;nbsp;performance!&lt;/p&gt;
&lt;p&gt;Now, I realize that I may have cheated. My &lt;code&gt;data.table&lt;/code&gt; code isn&amp;#8217;t very good and could probably follow a pattern closer to what I did in &lt;code&gt;dplyr&lt;/code&gt;. The results might be much closer in the hands of a more adept developer. But the take home message for me was that &lt;code&gt;dplyr&lt;/code&gt; enabled me to write the more performant code naturally because of its expressiveness. Not only is my code faster and easier to understand, it is also simpler and took far less time to&amp;nbsp;write.&lt;/p&gt;
&lt;p&gt;It is not every day that a tool provides powerful &lt;strong&gt;expressiveness&lt;/strong&gt; and yields greater &lt;strong&gt;performance&lt;/strong&gt;.&lt;/p&gt;
&lt;h3&gt;Update&lt;/h3&gt;
&lt;p&gt;I have made some improvements to this function to simplify things. I will be maintaining this code in my &lt;a href="https://github.com/jasonpbecker/PPSDCollegeReadiness/blob/master/R/modal_person_attribute.R"&gt;PPSDCollegeReadiness repository&lt;/a&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;modal_person_attribute &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;,&lt;/span&gt; sid&lt;span class="p"&gt;,&lt;/span&gt; attribute&lt;span class="p"&gt;,&lt;/span&gt; year&lt;span class="p"&gt;){&lt;/span&gt;
  &lt;span class="c1"&gt;# Select only the important columns&lt;/span&gt;
  x &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; x&lt;span class="p"&gt;[,&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;sid&lt;span class="p"&gt;,&lt;/span&gt; attribute&lt;span class="p"&gt;,&lt;/span&gt; year&lt;span class="p"&gt;)]&lt;/span&gt;
  names&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;sid&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;attribute&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="c1"&gt;# Clean up years&lt;/span&gt;
  &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kc"&gt;TRUE&lt;/span&gt; &lt;span class="o"&gt;%in%&lt;/span&gt; grepl&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;_&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; x&lt;span class="o"&gt;$&lt;/span&gt;year&lt;span class="p"&gt;)){&lt;/span&gt;
    x&lt;span class="o"&gt;$&lt;/span&gt;year &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; gsub&lt;span class="p"&gt;(&lt;/span&gt;pattern&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;[0-9]{4}_([0-9]{4})&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;\\1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; x&lt;span class="o"&gt;$&lt;/span&gt;year&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;  
  &lt;span class="c1"&gt;# Calculate the count for each person-attribute combo and select max&lt;/span&gt;
  max_attributes &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; x &lt;span class="o"&gt;%.%&lt;/span&gt; 
                    group_by&lt;span class="p"&gt;(&lt;/span&gt;sid&lt;span class="p"&gt;,&lt;/span&gt; attribute&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%.%&lt;/span&gt;
                    summarize&lt;span class="p"&gt;(&lt;/span&gt;count &lt;span class="o"&gt;=&lt;/span&gt; n&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="o"&gt;%.%&lt;/span&gt;
                    filter&lt;span class="p"&gt;(&lt;/span&gt;count &lt;span class="o"&gt;==&lt;/span&gt; max&lt;span class="p"&gt;(&lt;/span&gt;count&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;%.%&lt;/span&gt;
                    select&lt;span class="p"&gt;(&lt;/span&gt;sid&lt;span class="p"&gt;,&lt;/span&gt; attribute&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="c1"&gt;# Find the max year for each person-attribute combo&lt;/span&gt;
  results &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; max_attributes &lt;span class="o"&gt;%.%&lt;/span&gt; 
             left_join&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%.%&lt;/span&gt;
             group_by&lt;span class="p"&gt;(&lt;/span&gt;sid&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%.%&lt;/span&gt;
             filter&lt;span class="p"&gt;(&lt;/span&gt;year &lt;span class="o"&gt;==&lt;/span&gt; max&lt;span class="p"&gt;(&lt;/span&gt;year&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;%.%&lt;/span&gt;
             select&lt;span class="p"&gt;(&lt;/span&gt;sid&lt;span class="p"&gt;,&lt;/span&gt; attribute&lt;span class="p"&gt;)&lt;/span&gt;
  names&lt;span class="p"&gt;(&lt;/span&gt;results&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;sid&lt;span class="p"&gt;,&lt;/span&gt; attribute&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="kr"&gt;return&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;results&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:2012"&gt;
&lt;p&gt;It was over a year ago that I first wrote this code.&amp;#160;&lt;a class="footnote-backref" href="#fnref:2012" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="rstats"></category><category term="dplyr"></category><category term="data.table"></category><category term="algorithms"></category></entry><entry><title>Latinos in Rhode Island Face Housing Burden</title><link href="http://blog.jsonbecker.com/2014/02/latinos-in-rhode-island-face-housing-burden.html" rel="alternate"></link><updated>2014-02-27T14:30:00-05:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2014-02-27:2014/02/latinos-in-rhode-island-face-housing-burden.html</id><summary type="html">&lt;p&gt;We burden Latinos (and other traditionally underserved communities) with expensive housing because of the widespread practice of using &lt;a href="https://www.providenceri.com/efile/3620"&gt;homestead exemptions&lt;/a&gt; in Rhode Island. By lowering the real estate tax rate, typically by 50%, for owner occupied housing, we dramatically inflate the tax rate paid by Rhode Islanders who are&amp;nbsp;renting. &lt;/p&gt;
&lt;p&gt;Echoing a newly filed lawsuit in New York City over &lt;a href="http://www.bkreader.com/2014/02/class-action-law-suit-charges-black-and-hispanic-renters-pay-more-in-property-taxes-than-some-owners/"&gt;discriminatory real estate tax regimes&lt;/a&gt;, this new report emphasizes the racist incentives built into our property&amp;nbsp;tax. &lt;/p&gt;
&lt;p&gt;Homestead exemptions are built on the belief that renters are non-permanent residents of communities, care less for the properties they occupy and neighborhoods they live in, and are worse additions than homeowners. Frankly, it is an anti-White flight measure meant to assure people that only those with the means to purchase and the intent to stay will join their neighborhoods. Wealthy, largely White, property owners see homestead exemptions as fighting an influx of &amp;#8220;slum lords&amp;#8221;, which is basically the perception of anyone who purchases a home or builds apartments and rents them&amp;nbsp;out.&lt;/p&gt;
&lt;p&gt;Rather than encouraging denser communities with higher land utilization and more housing to reduce the cost of living in dignity, we subsidize low value (per acre) construction that maintain inflated housing&amp;nbsp;costs.&lt;/p&gt;
&lt;p&gt;Full disclosure: I own a condo in Providence and receive a 50% discount on my taxes. In fact, living in a condo Downcity, my home value is depressed because of the limited ways that I can use it. I could rent my current condo at market rate and lose money because of the doubling in taxes that I would endure versus turning a small monthly profit at the same rent with higher taxes. The flexibility to use my property as my own residence or as a rental unit more than pays for higher&amp;nbsp;taxes.&lt;/p&gt;
&lt;p&gt;So while I do have personal reasons to support removing the homestead exemption, even if I lived in a single family home on the East Side that was not attractive as a rental property, I would still think this situation is absurd. Homeowners&amp;#8217; taxes should easily be 20% higher to tax renters 30% less. Maybe some of our hulking, vacant infrastructure could be more viably converted into housing stock and lower the cost for all residents. Maybe we could even see denser development because there will actually be a market for renters at the monthly rates that would need to be charged to recuperate expenses. At least the rent wouldn&amp;#8217;t be so damn high for too many people of color and people living in or near&amp;nbsp;poverty.&lt;/p&gt;</summary><category term="tax"></category><category term="development"></category><category term="homestead"></category><category term="latinos"></category><category term="property tax"></category><category term="real estate"></category></entry><entry><title>Appreciating the Beauty of dplyr</title><link href="http://blog.jsonbecker.com/2014/02/appreciating-the-beauty-of-dplyr.html" rel="alternate"></link><updated>2014-02-18T15:39:00-05:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2014-02-18:2014/02/appreciating-the-beauty-of-dplyr.html</id><summary type="html">&lt;p&gt;&lt;a href="http://had.co.nz"&gt;Hadley Wickham&lt;/a&gt; has &lt;a href="https://github.com/hadley"&gt;once again&lt;/a&gt;&lt;sup id="fnref:seriously"&gt;&lt;a class="footnote-ref" href="#fn:seriously" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; made R ridiculously better. Not only is &lt;code&gt;dplyr&lt;/code&gt; incredibly fast, but the new syntax allows for some really complex operations to be expressed in a ridiculously beautiful&amp;nbsp;way.&lt;/p&gt;
&lt;p&gt;Consider a data set, &lt;code&gt;course&lt;/code&gt;, with a student identifier, &lt;code&gt;sid&lt;/code&gt;, a course identifier, &lt;code&gt;courseno&lt;/code&gt;, a quarter, &lt;code&gt;quarter&lt;/code&gt;, and a grade on a scale of 0 to 4, &lt;code&gt;gpa&lt;/code&gt;. What if I wanted to know the number of a courses a student has failed over the entire year, as defined by having an overall grade of less than a&amp;nbsp;1.0?&lt;/p&gt;
&lt;p&gt;In&amp;nbsp;dplyr:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;course &lt;span class="o"&gt;%.%&lt;/span&gt; 
group_by&lt;span class="p"&gt;(&lt;/span&gt;sid&lt;span class="p"&gt;,&lt;/span&gt; courseno&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%.%&lt;/span&gt;
summarise&lt;span class="p"&gt;(&lt;/span&gt;gpa &lt;span class="o"&gt;=&lt;/span&gt; mean&lt;span class="p"&gt;(&lt;/span&gt;gpa&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;%.%&lt;/span&gt;
filter&lt;span class="p"&gt;(&lt;/span&gt;gpa &lt;span class="o"&gt;&amp;lt;=&lt;/span&gt; &lt;span class="m"&gt;1.0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%.%&lt;/span&gt;
summarise&lt;span class="p"&gt;(&lt;/span&gt;fails &lt;span class="o"&gt;=&lt;/span&gt; n&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I refuse to even sully this post with the way I would have solved this problem in the&amp;nbsp;past.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:seriously"&gt;
&lt;p&gt;Seriously, how many of the packages he has managed/written are indispensable to using R today? It is no exaggeration to say that the world would have many more Stata, &lt;span class="caps"&gt;SPSS&lt;/span&gt;, and &lt;span class="caps"&gt;SAS&lt;/span&gt; users if not for Hadleyverse.&amp;#160;&lt;a class="footnote-backref" href="#fnref:seriously" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="rstats"></category><category term="dplyr"></category><category term="hadleyverse"></category></entry><entry><title>Freedom Should Be Reserved for the Wealthy</title><link href="http://blog.jsonbecker.com/2014/02/freedom-should-be-reserved-for-the-wealthy.html" rel="alternate"></link><updated>2014-02-10T14:51:00-05:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2014-02-10:2014/02/freedom-should-be-reserved-for-the-wealthy.html</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;These quotes are absolutely striking, in that they give a clear glimpse into the ideological commitments of the Republican Party. From Sen. Blunt and Rep. Cole, we get the revelation that— for conservatives— the only “work” worth acknowledging is wage labor. To myself, and many others, someone who retires early to volunteer— or leaves a job to care for their children— is still working, they&amp;#8217;re just outside the formal labor market. And indeed, their labor is still valuable— it just isn&amp;#8217;t compensated with&amp;nbsp;cash.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;One of the greatest benefits of wealth is that it can liberate people to pursue happiness. When we tie a basic need for living complete lives of dignity to full time employment, people will find themselves willing to make many sacrifices to ensure this need. In our nation of great wealth with liberty and freedom as core values, it is hard to believe that the &lt;span class="caps"&gt;GOP&lt;/span&gt; would decry the liberating effect of ending the contingency of health care on&amp;nbsp;work.&lt;/p&gt;
&lt;p&gt;There is no work rule, regulation, or union that empowers workers more in their relationship with their employers than removing the threat of losing health care from the table. An increasingly libertarian right should be celebrating this as a key victory, rather than celebrate the existing coercive impact that health care has in our&amp;nbsp;lives.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Republicans aren&amp;#8217;t as worried as the idle rich, who— I suppose— have earned the right to avoid a life of endless toil. Otherwise— if Republicans really wanted everyone to work as much as possible— they&amp;#8217;d support confiscatory tax rates. After all, nothing will drive an investment banker back to the office like the threat of losing 70 percent of her income to Uncle&amp;nbsp;Sam.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Oh yeah, I forgot. For all their claims to loving liberty and freedom, what the &lt;span class="caps"&gt;GOP&lt;/span&gt; really stands for is protecting liberty and freedom for the existing &amp;#8220;deserving&amp;#8221; wealthy. They will fight tooth and nail to remove estate taxes because inheritance is a legitimate source of liberty. Removing the fear of entering a hospital uninsured after being unable to access preventive care is what deprives folks of&amp;nbsp;&amp;#8220;dignity&amp;#8221;.&lt;/p&gt;</summary><category term="healthcare"></category><category term="aca"></category><category term="obamacare"></category><category term="politics"></category><category term="cbo"></category><category term="employment"></category></entry><entry><title>Dreamschooling</title><link href="http://blog.jsonbecker.com/2014/02/dreamschooling.html" rel="alternate"></link><updated>2014-02-06T14:19:00-05:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2014-02-06:2014/02/dreamschooling.html</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;My Democracy Prep colleague Lindsay Malanga and I often say we should start an organization called the Coalition of Pretty Good Schools.  We&amp;#8217;d start with the following&amp;nbsp;principles.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Every child must have a safe, warm, disruption-free classroom as a non-negotiable, fundamental&amp;nbsp;right.&lt;/li&gt;
&lt;li&gt;All children should be taught to read using phonics-based&amp;nbsp;instruction.&lt;/li&gt;
&lt;li&gt;All children must master basic computational skills with automaticity before moving on to higher&amp;nbsp;mathematics.&lt;/li&gt;
&lt;li&gt;Every child must be given a well-rounded education that includes science, civics, history, geography, music, the arts, and physical&amp;nbsp;education.&lt;/li&gt;
&lt;li&gt;Accountability is an important safeguard of public funds, but must not drive or dominate a child&amp;#8217;s education. Class time must not be used for standardized test&amp;nbsp;preparation.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;We have no end of people ready to tell you about their paradigmatic shift that will fix education overnight. There has been plenty of philosophizing about the goals, purpose, and means of education. Everyone is ready to pull out tropes about the &amp;#8220;factory model&amp;#8221; of education our system is built&amp;nbsp;on.&lt;/p&gt;
&lt;p&gt;The reality is that the education system too often fails at very basic delivery, period. I would love to see more folks draw a line in the sand of their minimum basic requirements, and not in an outrageous, political winky-wink where they are wrapping thier ideal in the language of the minimum. Lets have a deep discussion right now about the minimum basic requirements and lets get relentless about making that happen without the distraction of the dream. Frankly, whatever your dream is, so long as it involves kids going somewhere to learn &lt;sup id="fnref:yeahyeah"&gt;&lt;a class="footnote-ref" href="#fn:yeahyeah" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;, if we can&amp;#8217;t deliver on the basics it will be dead on&amp;nbsp;arrival.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:yeahyeah"&gt;
&lt;p&gt;Of course, for a group of folks who are engaged in Dreamschooling, we cannot take for granted that schools will be places or that children will be students in any traditional sense of the word. However, I believe that if we have a frank conversation about the minimum expectations for education I suspect this will not be a particularly widely held sentiment. If our technofuturism does complete its mindmeld with the anarcho-____ movements on the left and right to lead to a dramatically different conceptualization of childhood in the developed world in my lifetime&amp;#8230;&amp;#160;&lt;a class="footnote-backref" href="#fnref:yeahyeah" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="education"></category><category term="schools"></category></entry><entry><title>Garrahy Complex: Rules for Public Investment in Parking</title><link href="http://blog.jsonbecker.com/2014/01/garrahy-complex-rules-for-public-investment-in-parking.html" rel="alternate"></link><updated>2014-01-07T23:00:00-05:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2014-01-07:2014/01/garrahy-complex-rules-for-public-investment-in-parking.html</id><summary type="html">&lt;p&gt;James over at &lt;a href="http://www.transportprovidence.blogspot.com"&gt;TransportPVD&lt;/a&gt; has a great &lt;a href="http://www.transportprovidence.blogspot.com/2014/01/how-do-you-prevent-surface-parking-lot.html"&gt;post today&lt;/a&gt; talking about a Salt Lake City ordinance that makes property owners responsible for providing a bond that funds the landscaping and maintenance of vacant lots left after demolition. I love this as much as he does and would probably add several other provisions (like forfeiting any tax breaks on that property or any other property in the city and potentially forfeiture of the property itself if a demolition was approved based on site plans that are not adhered to within a given time frame). Ultimately, I do think the best solution to surface parking where it doesn&amp;#8217;t belong, of either the temporary or permanent (and isn&amp;#8217;t it all actually permanent?) kind, is a &lt;a href="http://streetsblog.net/2012/12/10/want-to-end-the-scourge-of-surface-parking-tax-land-not-buildings/"&gt;land value tax&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;James goes one step further and suggests that we should adopt some similar rules around &lt;span class="caps"&gt;ALL&lt;/span&gt; parking developments and proposes a few. His hopes were that a mayoral candidate would chime in. For now, he will have to do with&amp;nbsp;me.&lt;/p&gt;
&lt;p&gt;His recommendations are built somewhat specific to the commission looking at building a state-funded parking garage in front of the &lt;a href="http://www.gcpvd.org/2013/10/24/projo-commission-meets-to-discuss-possible-garrahy-complex-parking-garage/"&gt;Garrahy Complex&lt;/a&gt; in Downcity, about which many urbanists and transit advocates have expressed reservations or outright rejection. They&amp;nbsp;are:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;The garage is parking neutral. As many spots need to be removed from the downtown as are&amp;nbsp;added. &lt;/li&gt;
&lt;li&gt;An added bonus would be if some of the spots removed were on-street ones, to create protected bike lanes or transit lanes with greenery separating them from car&amp;nbsp;traffic.&lt;/li&gt;
&lt;li&gt;The garage has the proposed bus&amp;nbsp;hub.&lt;/li&gt;
&lt;li&gt;There are ground-level&amp;nbsp;shops.&lt;/li&gt;
&lt;li&gt;The garage is left open 24-hours so that it can limit the need for other lots (this happens when a garage is used only during the day, or only at night, instead of letting it serve both&amp;nbsp;markets).&lt;/li&gt;
&lt;li&gt;Cars pay full market price to&amp;nbsp;park.&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;(Note: I&amp;#8217;ve numbered rather than kept the bullets of the original to make responding&amp;nbsp;easier.)&lt;/p&gt;
&lt;p&gt;I disagree with the first and second point, which are really one and the same. We are in a district that has tremendously underutilized land. We want that space to be developed and as a result of that development we expect their to be much increased need for transit capacity. The goal should be &lt;em&gt;both&lt;/em&gt; to increase accessibility &lt;em&gt;and&lt;/em&gt; increase the share of transit capacity offered by walking, biking, or riding a bus or light rail. This does not require that we demand a spot-for-spot when building a public garage. I agree with the sentiment but disagree with the degree. Part of building rules and policies like this is to ensure comprehensive consideration of the transit context when developing parking. I see no reason to a priori assume that garages should only be permitted if they eliminate the same number of spaces they&amp;nbsp;create.&lt;/p&gt;
&lt;p&gt;The reason I combine these two points is because the city does not have the ability to remove off-street parking that is not publicly owned. Investing in smaller garages by footprint that have to be built taller and provide no change in capacity probably make no sense at all. If we&amp;#8217;re going to build any kind of public garage at all, it should be with the goal of consolidating parking into infrastructure with reasonable land utilization. We would rather 3 or 4 large garages properly located than all of the current lots. Limiting their size because of the flexibility available due to reducing on-street parking or the footprint on existing lots doesn&amp;#8217;t achieve that and doesn&amp;#8217;t factor in orders-of-magnitude changes in capacity we should need for all transit modes in the next 20&amp;nbsp;years.&lt;/p&gt;
&lt;p&gt;On point three, I am skeptical. I like the idea of improving bus infrastructure when building parking infrastructure in general. In fact, I voted against the \&lt;mathjax&gt;$40M Providence road paving bond even though that was much needed maintenance. My rationale was purely ideological-- we should not use debt to pay for car maintenance without also investing in ways to reduce future maintenance costs through better utilization of those roads. However, I have a hard time believing that the Garrahy location is any good as a bus hub. If RIPTA did a great job identifying the need for an additional bus hub that the Garrahy location met the criteria for, I think it's a reasonable idea. Short of that, it feels like throwing the transit community a wasteful&amp;nbsp;bone.&lt;/p&gt;
&lt;p&gt;I mostly agree on point four, but I doubt at the scale James would like to see. I think an appropriate level is probably not that different from the recently erected Johnson and Wales garage. The reality is that street-level retail is the right form, but there isn't sufficient foot traffic to support it right now and won't be for some time. There has to be street-level activation of any garage built in this area, but the square footage is likely fairly&amp;nbsp;timid.&lt;/p&gt;
&lt;p&gt;I absolutely agree with point five, without qualification. Not a dime should be spent on a public parking spot that is closed at any point in time, anywhere in the city. I would actually ditto this for surface parking lots on commercial properties of any kind after business hours. Not only should they have to be open, they should have to provide signs indicating the hours of commercial activity when parking is restricted and the hours when parking is available to the public. These hours of operations should require board approval. Owners could choose to charge during these off hours, but cars must be able to access the&amp;nbsp;lot.&lt;/p&gt;
&lt;p&gt;And point six should be a given for any public&amp;nbsp;parking.&lt;/p&gt;
&lt;p&gt;The real problem with Garrahy, in my opinion, is the cost is absurd, likely to be at least \$&lt;/mathjax&gt;35,000 per space. There is plenty of existing parking, suggesting the demand right now is illusory and market rate for those spots right now means the investment is unlikely to ever be recovered. In a world with limited capacity for government spending on transit as a public good, I would rather subsidize transit infrastructure that benefits the poor and directly impacts the share of non-car transit as it increases capacity. Spending limited funds on parking infrastructure is ludicrous when demand isn&amp;#8217;t sufficient to recover the investment. We already more than sufficiently subsidize parking in the area. And of course, the &amp;#8220;study commission&amp;#8221; is not really a study&amp;#8212; it&amp;#8217;s a meeting convened by those who want the project to happen putting the required usual suspects in the room to tepidly rubber stamp it. At least that&amp;#8217;s my cynical&amp;nbsp;take.&lt;/p&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</summary><category term="providence"></category><category term="urban"></category><category term="transit"></category><category term="parking"></category><category term="downcity"></category></entry><entry><title>Did public schools build economies, or did economies build public schools?</title><link href="http://blog.jsonbecker.com/2013/12/did-public-schools-build-economies-or-did-economies-build-public-schools.html" rel="alternate"></link><updated>2013-12-10T23:00:00-05:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-12-10:2013/12/did-public-schools-build-economies-or-did-economies-build-public-schools.html</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;We find that public schools offered practically zero return education on the margin, yet they did enjoy significant political and financial support from local political elites, if they taught in the “right” language of&amp;nbsp;instruction.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;One thing that both progressives and libertarians agree upon are that social goals of education are woefully underappreciated and considered in the current school reform discussion. Both school choice and local, democratic control of schools are reactions to centralization resulting in &amp;#8220;elites&amp;#8230; [selecting] the &amp;#8216;right&amp;#8217; language of&amp;nbsp;instruction.&amp;#8221;&lt;/p&gt;
&lt;p&gt;I am inclined to agree with&amp;nbsp;neither.&lt;/p&gt;</summary><category term="education"></category><category term="economics"></category><category term="research"></category><category term="public goods"></category><category term="nber"></category></entry><entry><title>Calculating Age with Precision in R</title><link href="http://blog.jsonbecker.com/2013/12/calculating-age-with-precision-in-r.html" rel="alternate"></link><updated>2013-12-04T17:00:00-05:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-12-04:2013/12/calculating-age-with-precision-in-r.html</id><summary type="html">&lt;p&gt;&lt;strong&gt;Update&lt;/strong&gt;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Turns out the original code below was pretty messed up. All kinds of little errors I didn&amp;#8217;t catch. I&amp;#8217;ve updated it below. There are a lot of options to refactor this further that I&amp;#8217;m currently considering. Sometimes it is really hard to know just how flexible something this big really should be. I think I am going to wait until I start developing tests to see where I land. I have a feeling moving toward a more test-driven work flow is going to force me toward a different&amp;nbsp;structure.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I recently updated the function I &lt;a href="http://blog.jsonbecker.com/2013/06/calculating-age-in-r.html"&gt;posted&lt;/a&gt; about back in June that calculates the difference between two dates in days, months, or years in R. It is still surprising to me that &lt;code&gt;difftime&lt;/code&gt; can only return units from seconds up until weeks. I suspect this has to do with the challenge of properly defining a &amp;#8220;month&amp;#8221; or &amp;#8220;year&amp;#8221; as a unit of time, since these are&amp;nbsp;variable.&lt;/p&gt;
&lt;p&gt;While there was nothing wrong with the original function, it did irk me that it always returned an integer. In other words, function returned only complete months or years. If the start date was on &lt;code&gt;2012-12-13&lt;/code&gt; and the end date was on &lt;code&gt;2013-12-03&lt;/code&gt;, the function would return &lt;code&gt;0&lt;/code&gt; years. Most of the time, this is the behavior I expect when calcuating age. But it is completely reasonable to want to include partial years or months, e.g. in the aforementioned example returning &lt;code&gt;0.9724605&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;So after several failed attempts because of silly errors in my algorithm, here is the final code. It will be released as part of &lt;a href="https://github.com/jknowles/eeptools/"&gt;eeptools 0.3&lt;/a&gt; which should be avialable on &lt;span class="caps"&gt;CRAN&lt;/span&gt; soon &lt;sup id="fnref:moves"&gt;&lt;a class="footnote-ref" href="#fn:moves" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;age_calc &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;dob&lt;span class="p"&gt;,&lt;/span&gt; enddate&lt;span class="o"&gt;=&lt;/span&gt;Sys.Date&lt;span class="p"&gt;(),&lt;/span&gt; units&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;months&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; precise&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
  &lt;span class="kr"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;inherits&lt;span class="p"&gt;(&lt;/span&gt;dob&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Date&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="o"&gt;!&lt;/span&gt;inherits&lt;span class="p"&gt;(&lt;/span&gt;enddate&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Date&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)){&lt;/span&gt;
    stop&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Both dob and enddate must be Date class objects&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  start &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; as.POSIXlt&lt;span class="p"&gt;(&lt;/span&gt;dob&lt;span class="p"&gt;)&lt;/span&gt;
  end &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; as.POSIXlt&lt;span class="p"&gt;(&lt;/span&gt;enddate&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;precise&lt;span class="p"&gt;){&lt;/span&gt;
    start_is_leap &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; ifelse&lt;span class="p"&gt;(&lt;/span&gt;start&lt;span class="o"&gt;$&lt;/span&gt;year &lt;span class="o"&gt;%%&lt;/span&gt; &lt;span class="m"&gt;400&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                        ifelse&lt;span class="p"&gt;(&lt;/span&gt;start&lt;span class="o"&gt;$&lt;/span&gt;year &lt;span class="o"&gt;%%&lt;/span&gt; &lt;span class="m"&gt;100&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;FALSE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                               ifelse&lt;span class="p"&gt;(&lt;/span&gt;start&lt;span class="o"&gt;$&lt;/span&gt;year &lt;span class="o"&gt;%%&lt;/span&gt; &lt;span class="m"&gt;4&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;FALSE&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
    end_is_leap &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; ifelse&lt;span class="p"&gt;(&lt;/span&gt;end&lt;span class="o"&gt;$&lt;/span&gt;year &lt;span class="o"&gt;%%&lt;/span&gt; &lt;span class="m"&gt;400&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                        ifelse&lt;span class="p"&gt;(&lt;/span&gt;end&lt;span class="o"&gt;$&lt;/span&gt;year &lt;span class="o"&gt;%%&lt;/span&gt; &lt;span class="m"&gt;100&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;FALSE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                               ifelse&lt;span class="p"&gt;(&lt;/span&gt;end&lt;span class="o"&gt;$&lt;/span&gt;year &lt;span class="o"&gt;%%&lt;/span&gt; &lt;span class="m"&gt;4&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="kc"&gt;FALSE&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;units&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;days&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    result &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; difftime&lt;span class="p"&gt;(&lt;/span&gt;end&lt;span class="p"&gt;,&lt;/span&gt; start&lt;span class="p"&gt;,&lt;/span&gt; units&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;days&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="kr"&gt;else&lt;/span&gt; &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;units&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;months&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    months &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; sapply&lt;span class="p"&gt;(&lt;/span&gt;mapply&lt;span class="p"&gt;(&lt;/span&gt;seq&lt;span class="p"&gt;,&lt;/span&gt; as.POSIXct&lt;span class="p"&gt;(&lt;/span&gt;start&lt;span class="p"&gt;),&lt;/span&gt; as.POSIXct&lt;span class="p"&gt;(&lt;/span&gt;end&lt;span class="p"&gt;),&lt;/span&gt; 
                            by&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;months&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; SIMPLIFY&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;FALSE&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; 
                     length&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;
    &lt;span class="c1"&gt;# length(seq(start, end, by=&amp;#39;month&amp;#39;)) - 1&lt;/span&gt;
    &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;precise&lt;span class="p"&gt;){&lt;/span&gt;
      month_length_end &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; ifelse&lt;span class="p"&gt;(&lt;/span&gt;end&lt;span class="o"&gt;$&lt;/span&gt;mon&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                 ifelse&lt;span class="p"&gt;(&lt;/span&gt;end&lt;span class="o"&gt;$&lt;/span&gt;mon&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; end_is_leap&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;29&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                        ifelse&lt;span class="p"&gt;(&lt;/span&gt;end&lt;span class="o"&gt;$&lt;/span&gt;mon &lt;span class="o"&gt;%in%&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;10&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; 
                                               &lt;span class="m"&gt;30&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;31&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
      month_length_prior &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; ifelse&lt;span class="p"&gt;((&lt;/span&gt;end&lt;span class="o"&gt;$&lt;/span&gt;mon&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                     ifelse&lt;span class="p"&gt;((&lt;/span&gt;end&lt;span class="o"&gt;$&lt;/span&gt;mon&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; start_is_leap&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;29&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                            ifelse&lt;span class="p"&gt;((&lt;/span&gt;end&lt;span class="o"&gt;$&lt;/span&gt;mon&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%in%&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                                                      &lt;span class="m"&gt;10&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; 
                                                   &lt;span class="m"&gt;30&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;31&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
      month_frac &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; ifelse&lt;span class="p"&gt;(&lt;/span&gt;end&lt;span class="o"&gt;$&lt;/span&gt;mday &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; start&lt;span class="o"&gt;$&lt;/span&gt;mday&lt;span class="p"&gt;,&lt;/span&gt;
                           &lt;span class="p"&gt;(&lt;/span&gt;end&lt;span class="o"&gt;$&lt;/span&gt;mday&lt;span class="o"&gt;-&lt;/span&gt;start&lt;span class="o"&gt;$&lt;/span&gt;mday&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;month_length_end&lt;span class="p"&gt;,&lt;/span&gt;
                           ifelse&lt;span class="p"&gt;(&lt;/span&gt;end&lt;span class="o"&gt;$&lt;/span&gt;mday &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; start&lt;span class="o"&gt;$&lt;/span&gt;mday&lt;span class="p"&gt;,&lt;/span&gt; 
                            &lt;span class="p"&gt;(&lt;/span&gt;month_length_prior &lt;span class="o"&gt;-&lt;/span&gt; start&lt;span class="o"&gt;$&lt;/span&gt;mday&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; 
                                month_length_prior &lt;span class="o"&gt;+&lt;/span&gt; 
                                end&lt;span class="o"&gt;$&lt;/span&gt;mday&lt;span class="o"&gt;/&lt;/span&gt;month_length_end&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
      result &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; months &lt;span class="o"&gt;+&lt;/span&gt; month_frac
    &lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="kr"&gt;else&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
      result &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; months
    &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="kr"&gt;else&lt;/span&gt; &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;units&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;years&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    years &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; sapply&lt;span class="p"&gt;(&lt;/span&gt;mapply&lt;span class="p"&gt;(&lt;/span&gt;seq&lt;span class="p"&gt;,&lt;/span&gt; as.POSIXct&lt;span class="p"&gt;(&lt;/span&gt;start&lt;span class="p"&gt;),&lt;/span&gt; as.POSIXct&lt;span class="p"&gt;(&lt;/span&gt;end&lt;span class="p"&gt;),&lt;/span&gt; 
                            by&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;years&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; SIMPLIFY&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;FALSE&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; 
                     length&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;
    &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;precise&lt;span class="p"&gt;){&lt;/span&gt;
      start_length &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; ifelse&lt;span class="p"&gt;(&lt;/span&gt;start_is_leap&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;366&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;365&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      end_length &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; ifelse&lt;span class="p"&gt;(&lt;/span&gt;end_is_leap&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;366&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;365&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
      year_frac &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; ifelse&lt;span class="p"&gt;(&lt;/span&gt;start&lt;span class="o"&gt;$&lt;/span&gt;yday &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; end&lt;span class="o"&gt;$&lt;/span&gt;yday&lt;span class="p"&gt;,&lt;/span&gt;
                          &lt;span class="p"&gt;(&lt;/span&gt;end&lt;span class="o"&gt;$&lt;/span&gt;yday &lt;span class="o"&gt;-&lt;/span&gt; start&lt;span class="o"&gt;$&lt;/span&gt;yday&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;end_length&lt;span class="p"&gt;,&lt;/span&gt;
                          ifelse&lt;span class="p"&gt;(&lt;/span&gt;start&lt;span class="o"&gt;$&lt;/span&gt;yday &lt;span class="o"&gt;&amp;gt;&lt;/span&gt; end&lt;span class="o"&gt;$&lt;/span&gt;yday&lt;span class="p"&gt;,&lt;/span&gt; 
                                 &lt;span class="p"&gt;(&lt;/span&gt;start_length&lt;span class="o"&gt;-&lt;/span&gt;start&lt;span class="o"&gt;$&lt;/span&gt;yday&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; start_length &lt;span class="o"&gt;+&lt;/span&gt;
                                end&lt;span class="o"&gt;$&lt;/span&gt;yday &lt;span class="o"&gt;/&lt;/span&gt; end_length&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
      result &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; years &lt;span class="o"&gt;+&lt;/span&gt; year_frac
    &lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="kr"&gt;else&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
      result &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; years
    &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="kr"&gt;else&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
    stop&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Unrecognized units. Please choose years, months, or days.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="kr"&gt;return&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;result&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:moves"&gt;
&lt;p&gt;I should note that my mobility function will also be included in eeptools 0.3. I know I still owe a post on the actual code, but it is such a complex function I have been having a terrible time trying to write clearly about it.&amp;#160;&lt;a class="footnote-backref" href="#fnref:moves" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="r"></category><category term="rstats"></category><category term="age_calc"></category><category term="eeptools"></category><category term="code"></category></entry><entry><title>A Different Angle on PISA</title><link href="http://blog.jsonbecker.com/2013/12/a-different-angle-on-pisa.html" rel="alternate"></link><updated>2013-12-03T10:33:00-05:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-12-03:2013/12/a-different-angle-on-pisa.html</id><summary type="html">&lt;p&gt;&lt;img alt="PISA Results" src="http://blog.jsonbecker.com/images/pisaengagement.png" title="PISA Student Engagement US" /&gt;&lt;/p&gt;
&lt;p&gt;I wanted to call attention to these interesting &lt;span class="caps"&gt;PISA&lt;/span&gt; results. &lt;a href="http://blog.jsonbecker.com/images/turnsout.mp3"&gt;Turns out&lt;/a&gt; that student anxiety in the United States is lower than the &lt;span class="caps"&gt;OECD&lt;/span&gt; average and belief in ability is higher &lt;sup id="fnref:definitions"&gt;&lt;a class="footnote-ref" href="#fn:definitions" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;. I thought that all of the moves in education since the start of standard&amp;#8217;s based reform were supposed to be generating tremendous anxiety and failing to produce students who had high sense of&amp;nbsp;self-efficacy?&lt;/p&gt;
&lt;p&gt;It is also worth noting that students in the United States were more likely to skip out on school dand this had a higher than typical impact on student performance. One interpretation of this could be that students are less engaged, but also that schooling activities do have a large impact on students rather than schools being of lesser importance than student&amp;nbsp;inputs.&lt;/p&gt;
&lt;p&gt;I have always had a hard time reconciling the calls for higher teacher pay and better work conditions and evidence that missing even just 10% of schooling has a huge impact on student outcomes with the belief that addressing other social inequities is the key way to achieve better outcomes for&amp;nbsp;kids.&lt;/p&gt;
&lt;p&gt;This is all an exercise in nonsense. It is incredibly difficult to transfer findings from surveys across dramatical cultural differences. It is also hard to imagine what can be learned about the delivery of education in the dramatically different contexts that exists. The whole international comparison game seems like one big Rorschach test where the price of admission is leaving any understanding of culture, context, and external validity at the&amp;nbsp;door.&lt;/p&gt;
&lt;p&gt;P.S.: The use of color in this visualization is awful. There is a sense that they are trying to be &amp;#8220;value neutral&amp;#8221; with data that is ordinal in nature (above, same, or below), and in doing so chose two colors that are very difficult to distinguish between.&amp;nbsp;Yuck.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:definitions"&gt;
&lt;p&gt;The site describes prevalence of anxiety as, &amp;#8220;proportion of students who feel helpless when faced with math problems&amp;#8221; and belief in ability as, &amp;#8220;proportion of students who feel confident in their math abilitites&amp;#8221;. Note, based on these defitions, one might also think that either curricula were not so misaligned with international benchmarks or that we are already seeing the fruits of partial transition to Common Core. Not knowing the trend for this data, or some of the specifics about the collection instrument, makes that difficult to assess.&amp;#160;&lt;a class="footnote-backref" href="#fnref:definitions" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="education"></category><category term="pisa"></category><category term="non-cognitive."></category></entry><entry><title>A Good Long Read on Assessment and Accountability</title><link href="http://blog.jsonbecker.com/2013/11/a-good-long-read-on-assessment-and-accountability.html" rel="alternate"></link><updated>2013-11-23T00:00:00-05:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-11-23:2013/11/a-good-long-read-on-assessment-and-accountability.html</id><summary type="html">&lt;p&gt;Although it clocks in at 40+ pages, this is a worthwhile and relatively fast read for anyone in education policy on the future of assessment if we&amp;#8217;re serious about college and career readiness. There is a ton to unpack, with a fair amount it agree with and a lot I am quite a bit less sure&amp;nbsp;on.&lt;/p&gt;
&lt;p&gt;I think this paper is meant for national and state level policy-makers, and so my major quibble is I think this is much more valuable for a district-level audience. I am less bullish on the state&amp;#8217;s role in building comprehensive assessment systems. That&amp;#8217;s just my initial&amp;nbsp;reaction.&lt;/p&gt;
&lt;p&gt;The accountability section is both less rich and less convincing than the assessment portion. I have long heard cries for so-called reciprocal accountability, but it is still entirely unclear to me what this means and looks like and the implications for current&amp;nbsp;systems.&lt;/p&gt;</summary><category term="education"></category><category term="assessment"></category><category term="edpolicy"></category></entry><entry><title>Bilingual Education at Providence Public Schools</title><link href="http://blog.jsonbecker.com/2013/11/bilingual-education-at-providence-public-schools.html" rel="alternate"></link><updated>2013-11-21T00:00:00-05:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-11-21:2013/11/bilingual-education-at-providence-public-schools.html</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;“We are trying to work towards late-exit &lt;span class="caps"&gt;ELL&lt;/span&gt; programs so (students) can learn the concepts in (their) native language,” Lusi said. Administrative goals have recently shifted to a focus on proficiency in both languages because bilingual education is preferred, she&amp;nbsp;added.&lt;/p&gt;
&lt;p&gt;But instituting district-wide bilingual education would require funding to hire teachers certified in both languages and to buy dual-language materials, she&amp;nbsp;said.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I am pretty sure this is new. I am surprised there has not been a stronger effort to pass a legislative package in Rhode Island that provides both the policy framework and funding necessary to achieve universal bilinguage education for English language learners in &lt;span class="caps"&gt;RI&lt;/span&gt;&amp;nbsp;schools.&lt;/p&gt;
&lt;p&gt;One of the great advantages of transitioning to common standards&lt;sup id="fnref:CCSS"&gt;&lt;a class="footnote-ref" href="#fn:CCSS" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; is there should be greater availability of curricular materials in languages other than English. I suspect most of what is needed for bilingual education is start up money for materials, curriculum supports and developments, and assessment materials. There are a few policy things that need to be in place, possibly around state exams, but also rules around flexible teacher assignment, hiring, and dismissal staffing needs dramatically&amp;nbsp;change.&lt;/p&gt;
&lt;p&gt;Someone should be putting this package together. I suspect there would be broad&amp;nbsp;support.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:CCSS"&gt;
&lt;p&gt;Note, this is not necessarily a feature of the Common Core State Standards, just having standards in common with many other states.&amp;#160;&lt;a class="footnote-backref" href="#fnref:CCSS" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="education"></category><category term="pvd"></category><category term="ppsd"></category><category term="bilingual"></category><category term="ell"></category></entry><entry><title>DeBlasio: Weak on Implementation</title><link href="http://blog.jsonbecker.com/2013/11/deblasio-weak-on-implementation.html" rel="alternate"></link><updated>2013-11-20T00:00:00-05:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-11-20:2013/11/deblasio-weak-on-implementation.html</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;De Blasio and his advisers are still figuring out how much rent to charge well-funded charter schools, his transition team told me. “It would depend on the resources of the charter school or charter network,” he told &lt;span class="caps"&gt;WNYC&lt;/span&gt;, in early October. “Some are clearly very, very well resourced and have incredible wealthy backers. Others don’t. So my simple point was that programs that can afford to pay rent should be paying rent.” (In an October debate with the Republican candidate Joseph Lhota, he put it more bluntly: “I simply wouldn’t favor charters the way Mayor Bloomberg did because, in the end, our city rises or falls on our traditional public&amp;nbsp;schools.”)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;My impression of DeBlasio was that he went around collecting every plausible complaint from every interest group that was mad at Bloomberg and promised whatever they wanted. There didn&amp;#8217;t really seem to be a coherent theory or any depth whatsoever to his policy&amp;nbsp;prescriptions.&lt;/p&gt;
&lt;p&gt;Already working hard to confirm this&amp;nbsp;impression.&lt;/p&gt;</summary><category term="deblasio"></category><category term="nyc"></category><category term="education"></category><category term="charters"></category></entry><entry><title>More evidence for "mere facts"</title><link href="http://blog.jsonbecker.com/2013/11/more-evidence-for-mere-facts.html" rel="alternate"></link><updated>2013-11-19T00:00:00-05:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-11-19:2013/11/more-evidence-for-mere-facts.html</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;To recap, the first study discussed above established that children from disadvantaged backgrounds know less about a topic (i.e., birds) than their middle-class peers. Next, in study two, the researchers showed that differences in domain knowledge influenced children’s ability to understand words out of context, and to comprehend a story. Moreover, poor kids — who also had more limited knowledge — perform worse on these tasks than did their middle class peers. But could additional knowledge be used to level the playing field for children from less affluent backgrounds? &lt;br&gt;&lt;br&gt;
In study three, the researchers held the children’s prior knowledge constant by introducing a fictitious topic — i.e., a topic that was sure to be unknown to both groups. When the two groups of children were assessed on word learning and comprehension related to this new domain, the researchers found no significant differences in how poor and middle-class children learned words, comprehended a story or made&amp;nbsp;inferences.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;One of the &amp;#8220;old&amp;#8221; divides in education, from before the current crop of &amp;#8220;edreform&amp;#8221;, is whether or not content matters. Broadly, there are two camps, let&amp;#8217;s call them the &amp;#8220;Facts&amp;#8221; and &amp;#8220;Skills&amp;#8221;, with the &amp;#8220;Skills&amp;#8221; camp clearly ahead in terms of mind&amp;nbsp;share.&lt;/p&gt;
&lt;p&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Skills&amp;#8221; is based on a fundamentally intuitive insight&amp;#8212; students need to know how to do things not about the things themselves. In many ways it is built on our common experience of forgetting facts over time. We need &lt;em&gt;21st century skills&lt;/em&gt;, not an accumulation of specific, privileged knowledge that fades over time. Whatever the latest technology, from encyclopedias to calculators through to Google, each generation decides that the tools that adults use end the necessity of knowing &lt;em&gt;about&lt;/em&gt; things rather than knowing how to &lt;em&gt;find&lt;/em&gt;&amp;nbsp;things.&lt;/p&gt;
&lt;p&gt;This is very attractive. It seems to match our adult experiences accumulating knowledge and using it in our work. It seems to address students&amp;#8217; boredom with learning &lt;em&gt;irrelevant&lt;/em&gt; information. It leaves space for groups to advocate for teaching whatever content they want since everyone can argue that content is fundamentally limited in&amp;nbsp;value.&lt;/p&gt;
&lt;p&gt;In classic &lt;strong&gt;&lt;a href="http://blog.jsonbecker.com/images/turnsout.mp3"&gt;turns out&lt;/a&gt;&lt;/strong&gt; sense, however, the evidence keeps mounting that one must teach from the &amp;#8220;Facts&amp;#8221; approach to achieve the goals of the &amp;#8220;Skills&amp;#8221;&amp;nbsp;position.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Turns out:&lt;/strong&gt; skills and knowledge do not transfer well across domains. There is little evidence that learning how to read literary fiction translates to reading technical manuals with comprehension. In other words, critical thinking is not really an independent ability free of domain context &lt;sup id="fnref:critthinking"&gt;&lt;a class="footnote-ref" href="#fn:critthinking" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;. In fact, experts are able to learn more quickly, but only in their domain and only when they have prior knowledge to use as scaffolding &lt;sup id="fnref:scaffold"&gt;&lt;a class="footnote-ref" href="#fn:scaffold" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Turns out:&lt;/strong&gt; reading comprehension is strongly connected to whether or not students have prior knowledge (&amp;#8220;Facts&amp;#8221;) about the topic of the passage &lt;sup id="fnref:priorknowledge"&gt;&lt;a class="footnote-ref" href="#fn:priorknowledge" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;. Reading techniques only provide modest assistance for&amp;nbsp;comprehension.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Turns out:&lt;/strong&gt; privileging skills over content may have a serious differential impact on disadvantaged children. A well-intentioned goal of achieving equity through equality has led many to advocate that we do a disservice to children of color and children in poverty because their schools have not as completely embraced a &amp;#8220;Skills&amp;#8221; world and are too focused on &amp;#8220;Facts&amp;#8221;. The problem is that deep disparities we see when these students enter schooling point to having less prior knowledge than their peers &lt;sup id="fnref:culturalliteracy"&gt;&lt;a class="footnote-ref" href="#fn:culturalliteracy" rel="footnote"&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;What is remarkable, and tragic, is that the &amp;#8220;Skills&amp;#8221; camp has maintained its dominance through the demonization of &amp;#8220;Facts&amp;#8221;, with dramatic misinterpretations&amp;nbsp;like:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The &amp;#8220;Facts&amp;#8221; folks are just White colonialists seeking to maintain existing power structures through teaching the information of&amp;nbsp;privilege.&lt;/li&gt;
&lt;li&gt;The &amp;#8220;Facts&amp;#8221; folks privilege memorization, rote learning, and recall-based assessment over other pedagogy that is more engaging and&amp;nbsp;authentic.&lt;/li&gt;
&lt;li&gt;The &amp;#8220;Facts&amp;#8221; folks can only ever teach what was important yesterday; &amp;#8220;Skills&amp;#8221; camp can teach what matters to become a lifelong learner for tomorrow&amp;#8217;s&amp;nbsp;world.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;None of these are&amp;nbsp;true.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This post is largely brought to you by: &lt;span class="caps"&gt;E.D.&lt;/span&gt; Hirsch, Dan T. Willingham, and Malcolm Gladwell via Merlin&amp;nbsp;Mann.&lt;/em&gt;&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:critthinking"&gt;
&lt;p&gt;&lt;a href=""&gt;http://www.aft.org/pdfs/americaneducator/summer2007/Crit_Thinking.pdf&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:critthinking" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:scaffold"&gt;
&lt;p&gt;&lt;a href=""&gt;http://www.ncbi.nlm.nih.gov/pubmed/11550744&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:scaffold" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:priorknowledge"&gt;
&lt;p&gt;&lt;a href=""&gt;http://www.aft.org/newspubs/periodicals/ae/spring2006/willingham.cfm&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:priorknowledge" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:comptech"&gt;
&lt;p&gt;http://www.aft.org/pdfs/americaneducator/winter0607/CogSci.pdf&amp;#160;&lt;a class="footnote-backref" href="#fnref:comptech" rev="footnote" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:culturalliteracy"&gt;
&lt;p&gt;This has pretty much been the thrust behind &lt;span class="caps"&gt;E.D.&lt;/span&gt; Hirsch&amp;#8217;s work, who has been accused of being on the far right in education, despite his consistent belief that education equity is one of the most important goals to achieve. His firm belief, and I am mostly convinced, is that explicit factual content is the key tool for how teaching can dramatically improve educational equity.&amp;#160;&lt;a class="footnote-backref" href="#fnref:culturalliteracy" rev="footnote" title="Jump back to footnote 5 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="education"></category><category term="core knowledge"></category><category term="pedagogy"></category><category term="curriculum"></category></entry><entry><title>The four ways to really fix education</title><link href="http://blog.jsonbecker.com/2013/11/the-four-ways-to-really-fix-education.html" rel="alternate"></link><updated>2013-11-19T00:00:00-05:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-11-19:2013/11/the-four-ways-to-really-fix-education.html</id><summary type="html">&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;More schooling, reoriented&amp;nbsp;calendar&lt;/li&gt;
&lt;li&gt;Wider range of higher&amp;nbsp;education&lt;/li&gt;
&lt;li&gt;Cheaper four-year&amp;nbsp;degrees&lt;/li&gt;
&lt;li&gt;Eliminate property tax-based public&amp;nbsp;education&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is an interesting list. I don&amp;#8217;t agree with number four. There are several benefits to using property taxes not the least of which is their stability and lagged response during traditional economic downturns. However, there are many things we should do to reform our revenue system for education. I am keen on &lt;em&gt;more&lt;/em&gt; taxes on &amp;#8220;property&amp;#8221;, using land value taxes that are levvied either statewide or regionally to address some of the inequities traditional, highly localized property taxes can lead&amp;nbsp;to.&lt;/p&gt;</summary><category term="education"></category><category term="qz"></category></entry><entry><title>It's Poverty Stupid... or is it?</title><link href="http://blog.jsonbecker.com/2013/11/its-poverty-stupid-or-is-it.html" rel="alternate"></link><updated>2013-11-18T00:00:00-05:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-11-18:2013/11/its-poverty-stupid-or-is-it.html</id><summary type="html">&lt;p&gt;If I had to point to the key fissure in the education policy and research community it would be around poverty. Some seem to view it as an inexorable obstacle, deeply believing that the key improvement strategy is to decrease inequity of inputs. Some seem to view it as an obstacle that can be overcome by systems functioning at peak efficacy, deeply believing the great challenge is achieving that efficacy sustainably at scale. Both positions seem to grossly simplify causes and suggest policy structures and outcomes that are&amp;nbsp;unachievable.&lt;/p&gt;
&lt;p&gt;Paraphrasing &lt;a href="http://www.kungfugrippe.com"&gt;Merlin Mann&lt;/a&gt;, &lt;em&gt;always be skeptical of &amp;#8220;turns out&amp;#8221; research&lt;/em&gt;. In this case, are the results really that surprising? If they are, I might suggest that you have been focusing too much on the partial equilibrium impact of poverty and ignoring the bigger&amp;nbsp;picture.&lt;/p&gt;
&lt;p&gt;Not that I think integration is likely, easy, quick, or magically fixes&amp;nbsp;things.&lt;/p&gt;</summary><category term="education"></category><category term="poverty"></category><category term="research"></category></entry><entry><title>A New Calculation for Student Mobility</title><link href="http://blog.jsonbecker.com/2013/09/a-new-calculation-for-student-mobility.html" rel="alternate"></link><updated>2013-09-17T00:00:00-04:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-09-17:2013/09/a-new-calculation-for-student-mobility.html</id><summary type="html">&lt;p&gt;How do we calculate student mobility? I am currently soliciting responses from other data professionals across the country. But when I needed to produce mobility numbers for some of my work a couple of months ago, I decided to develop a set of business rules without any exposure to how the federal government, states, or other existing systems define mobility. &lt;sup id="fnref:ignorance"&gt;&lt;a class="footnote-ref" href="#fn:ignorance" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;I am fairly proud of my work on mobility. This post will review how I defined student mobility. I am hopeful that it matches or bests current techniques for calculating the number of schools a student has attended. In my next post, I will share the first two major versions of my implementation of these mobility business rules in &lt;code&gt;R&lt;/code&gt;. &lt;sup id="fnref:learningexperience"&gt;&lt;a class="footnote-ref" href="#fn:learningexperience" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt; Together, these posts will represent the work I referred to in my previous post on the &lt;a href="http://blog.jsonbecker.com/2013/09/documentation-of-business-rules-and-analysis.html"&gt;importance of documenting business rules and sharing code&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;The&amp;nbsp;Rules&lt;/h2&gt;
&lt;p&gt;Working with district data presents a woefully incomplete picture of the education mobile students receive. Particularly in a state like Rhode Island, where our districts are only a few miles wide, there is substantial interdistrict mobility. When a student moves across district lines, their enrollment is not recorded in local district data. However, even with state level data, highly mobile students cross state lines and present incomplete data. A key consideration for calculating how many schools a student has attended in a particular year is capturing &amp;#8220;missing&amp;#8221; data&amp;nbsp;sensibly.&lt;/p&gt;
&lt;p&gt;The typical structure of enrollment records looks something like&amp;nbsp;this:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Unique Student &lt;span class="caps"&gt;ID&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;School Code&lt;/th&gt;
&lt;th&gt;Enrollment Date&lt;/th&gt;
&lt;th&gt;Exit Date&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;10101&lt;/td&gt;
&lt;td&gt;2012-09-01&lt;/td&gt;
&lt;td&gt;2012-11-15&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;10103&lt;/td&gt;
&lt;td&gt;2012-11-16&lt;/td&gt;
&lt;td&gt;2013-06-15&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;A compound key for this data consists of the Unique Student &lt;span class="caps"&gt;ID&lt;/span&gt;, School Code, and Enrollment Date, meaning that each row must be a unique combination of these three factors. The data above shows a simple case of a student enrolling at the start of the school year, switching schools once with no gap in enrollment, and continuing at the new school until the end of the school year. For the purposes of mobility, I would define the above as having moved one&amp;nbsp;time.&lt;/p&gt;
&lt;p&gt;But it is easy to see how some very complex scenarios could quickly arise. What if student &lt;code&gt;1000000&lt;/code&gt;&lt;span class="quo"&gt;&amp;#8216;&lt;/span&gt;s record looked like&amp;nbsp;this?&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Unique Student &lt;span class="caps"&gt;ID&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;School Code&lt;/th&gt;
&lt;th&gt;Enrollment Date&lt;/th&gt;
&lt;th&gt;Exit Date&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;10101&lt;/td&gt;
&lt;td&gt;2012-10-15&lt;/td&gt;
&lt;td&gt;2012-11-15&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;10103&lt;/td&gt;
&lt;td&gt;2013-01-03&lt;/td&gt;
&lt;td&gt;2013-03-13&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;10103&lt;/td&gt;
&lt;td&gt;2013-03-20&lt;/td&gt;
&lt;td&gt;2013-05-13&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;There are several features that make it challenging to assign a number of &amp;#8220;moves&amp;#8221; to this student. First, the student does not enroll in school until October 15, 2012. This is nearly six weeks into the typical school year in the Northeastern United States. Should we assume that this student has enrolled in no school at all prior to October 15th or should we assume that the student was enrolled in a school that was outside of this district and therefore missing in the data? Next, we notice the enrollment gap between November 15, 2012 and January 3, 2013. Is it right to assume that the student has moved only once in this period of time with a gap of enrollment of over a month and a half? Then we notice that the student exited school &lt;code&gt;10103&lt;/code&gt; on March 13, 2013 but was re-enrolled in the same school a week later on March 20, 2013. Has the student truly &amp;#8220;moved&amp;#8221; in this period? Lastly, the student exits the district on May 13, 2013 for the final time. This is nearly a month before the end of school. Has this student moved to a different&amp;nbsp;school?&lt;/p&gt;
&lt;p&gt;There is an element missing that most enrollment data has which can enrich our understanding of this student&amp;#8217;s record. All district collect an exit type, which explains if a student is leaving to enroll in another school within the district, another school in a different district in the same state, another school in a different state, a private school, etc. It also defines whether a student is dropping out, graduating, or has entered the juvenile justice system, for example. However, it has been my experience that this data is reported inconsistently and unreliably. Frequently a student will be reported as changing schools within the district without a subsequent enrollment record, or reported as leaving the district but enroll within the same district a few days later. Therefore, I think that we should try and infer the number of schools that a student has attended using soley the enrollment date, exit date, and school code for each student record. This data is far more reliable for a host of reasons, and, ultimately, provides us with all the information we need to make intelligent&amp;nbsp;decisions.&lt;/p&gt;
&lt;p&gt;My proposed set of business rules examines &lt;code&gt;school code&lt;/code&gt;, &lt;code&gt;enrollment date&lt;/code&gt;, and &lt;code&gt;exit date&lt;/code&gt; against three parameters: &lt;code&gt;enrollment by&lt;/code&gt;, &lt;code&gt;exit by&lt;/code&gt;, and &lt;code&gt;gap&lt;/code&gt;. 
Each students minimum enrollment date is compared to &lt;code&gt;enrollment by&lt;/code&gt;. If that student entered the data set for the first time before the &lt;code&gt;enrollment by&lt;/code&gt;, the assumption is that this record represents the first time the student enrolls in any school for that year, and therefore the student has 0 &lt;code&gt;moves&lt;/code&gt;. If the student enrolls for the first time after &lt;code&gt;enrollment by&lt;/code&gt;, then the record is considered the second school a student has attended and their &lt;code&gt;moves&lt;/code&gt; attribute is incremented by &lt;code&gt;1&lt;/code&gt;. Similarly, if a student&amp;#8217;s maximium &lt;code&gt;exit date&lt;/code&gt; is after &lt;code&gt;exit by&lt;/code&gt;, then this considered to be the student&amp;#8217;s last school enrolled in for the year and they are credited with &lt;code&gt;0&lt;/code&gt; &lt;code&gt;moves&lt;/code&gt;, but if &lt;code&gt;exit date&lt;/code&gt; is prior to &lt;code&gt;exit by&lt;/code&gt;, then that student&amp;#8217;s &lt;code&gt;moves&lt;/code&gt; is incremented by &lt;code&gt;1&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;That takes care of the &amp;#8220;ends&amp;#8221;, but what happens as students switch schools in the &amp;#8220;middle&amp;#8221;? I proposed that each &lt;code&gt;exit date&lt;/code&gt; is compared to the subsequent &lt;code&gt;enrollment date&lt;/code&gt;. If &lt;code&gt;enrollment date&lt;/code&gt; occurs within &lt;code&gt;gap&lt;/code&gt; days of the previous &lt;code&gt;exit date&lt;/code&gt;, and the &lt;code&gt;school code&lt;/code&gt; of enrollment is not the same as the &lt;code&gt;school code&lt;/code&gt; of exit, then a student&amp;#8217;s &lt;code&gt;moves&lt;/code&gt; are incremented by &lt;code&gt;1&lt;/code&gt;. If the &lt;code&gt;school codes&lt;/code&gt; are identical and the difference between dates is less than &lt;code&gt;gap&lt;/code&gt;, then the student is said to have not moved at all. If the difference between the &lt;code&gt;enrollment date&lt;/code&gt; and the previous &lt;code&gt;exit date&lt;/code&gt; is greater than &lt;code&gt;gap&lt;/code&gt;, then the student&amp;#8217;s &lt;code&gt;moves&lt;/code&gt; is incremented by &lt;code&gt;2&lt;/code&gt;, the assumption being that the student likely attended a different school between the two observations in the&amp;nbsp;data.&lt;/p&gt;
&lt;p&gt;Whereas calculating student mobility may have seemed a simple matter of counting the number of records in the enrollment file, clearly there is a level of complexity this would fail to&amp;nbsp;capture.&lt;/p&gt;
&lt;p&gt;Check back in a few days to see my next post where I will share my initial implementation of these business rules and how I achieved an 10x speed up with a massive code&amp;nbsp;refactor.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:ignorance"&gt;
&lt;p&gt;My ignorance was intentional. It is good to stretch those brain muscles that think through sticky problems like developing business rules for a key statistic. I can&amp;#8217;t be sure that I have developed the most considered and complete set of rules for mobility, which is why I&amp;#8217;m now soliciting other&amp;#8217;s views, but I am hopeful my solution is at least as good.&amp;#160;&lt;a class="footnote-backref" href="#fnref:ignorance" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:learningexperience"&gt;
&lt;p&gt;I think showing my first two implementation of these business rules is an excellent opportunity to review several key design considerations when programming in &lt;code&gt;R&lt;/code&gt;. From version 1 to version 2 I achieved a 10x speedup due to a complete refactor that avoided &lt;code&gt;for&lt;/code&gt; loops, used &lt;code&gt;data.table&lt;/code&gt;, and included some clever use of recursion.&amp;#160;&lt;a class="footnote-backref" href="#fnref:learningexperience" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="education"></category><category term="data"></category><category term="rstats"></category></entry><entry><title>Documentation of Business Rules and Analysis</title><link href="http://blog.jsonbecker.com/2013/09/documentation-of-business-rules-and-analysis.html" rel="alternate"></link><updated>2013-09-13T00:00:00-04:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-09-13:2013/09/documentation-of-business-rules-and-analysis.html</id><summary type="html">&lt;p&gt;One of the most challenging aspects of being a data analyst is translating programmatic terms like &amp;#8220;student mobility&amp;#8221; into precise business rules. Almost any simple statistic involves a series of decisions that are often opaque to the ultimate users of that&amp;nbsp;statistic.&lt;/p&gt;
&lt;p&gt;Documentation of business rules is a critical aspect of a data analysts job that, in my experience, is often regrettably overlooked. If you have ever tried to reproduce someone else&amp;#8217;s analysis, asked different people for the same statistic, or tried to compare data from multiple years, you have probably encountered difficulties getting a consistent answer on standard statistics, e.g. how many students were proficient in math, how many students graduated in four years, what proportion of students were chronically absent? All too often documentation of business rules is poor or non-existent. The result is that two analysts with the same data will produce inconsistent statistics. This is not because of something inherent in the quality of the data or an indictment of the analyst’s skills. In most cases, the undocumented business rules are essentially trivial, in that the results of any decision has a small impact on the final result and any of the decisions made by the analysts are equally&amp;nbsp;defensible.&lt;/p&gt;
&lt;p&gt;This major problem of lax or non-existent documentation is one of the main reasons I feel that analysts, and in particular analysts working in the public sector, should extensively use tools for code sharing and version control like &lt;a href="http://www.github.com/"&gt;Github&lt;/a&gt;, use free tools whenever possible, and generally adhere to best practices in reproducible&amp;nbsp;research.&lt;/p&gt;
&lt;p&gt;I am trying to put as much of my code on Github as I can these days. Much of what I write is still very disorganized and, frankly, embarrassing. A lot of what is in my Github repositories is old, abandoned code written as I was learning my craft. A lot of it is written to work with very specific, private data. Most of it is poorly documented because I am the only one who has ever had to use it, I don&amp;#8217;t interact with anyone through practices like code reviews, and frankly I am lazy when pressed with a deadline. But that&amp;#8217;s not really the point, is it? The worst documented code is code that is hidden away on a personal hard drive, written for an expensive proprietary environment most people and organizations cannot use, or worse, is not code at all but rather a series of destructive data edits and manipulations. &lt;sup id="fnref:fuckexcel"&gt;&lt;a class="footnote-ref" href="#fn:fuckexcel" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;One way that I have been trying to improve the quality and utility of the code I write is by contributing to an open source R package, &lt;code&gt;eeptools&lt;/code&gt;. This is a package written and maintained by Jared Knowles, an employee of the Wisconsin Department of Public Instruction, whom I met at a &lt;a href="http://www.gse.harvard.edu/sdp/"&gt;Strategic Data Project&lt;/a&gt; convening. &lt;code&gt;eeptools&lt;/code&gt; is consolidating several functions in R for common tasks education data analysts are faced with. Because this package is available on &lt;a href="http://cran.us.r-project.org/"&gt;&lt;span class="caps"&gt;CRAN&lt;/span&gt;&lt;/a&gt;, the primary repository for R packages, any education analyst can have access to its functions in one&amp;nbsp;line: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;install.packages&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;eeptools&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; require&lt;span class="p"&gt;(&lt;/span&gt;eeptools&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Submitting code to a &lt;span class="caps"&gt;CRAN&lt;/span&gt; package reinforces several habits. First, I get to practice writing R documentation,  explaining how to use a function, and therefore, articulating the assumptions and business rules I am applying. Second, I have to write my code with a wider tolerance for input data. One of the easy pitfalls of a beginning analyst is writing code that is too specific to the dataset in front of you. Most of the errors I have found in analyses during quality control stem from assumptions embedded in code that were perfectly reasonable with a single data set that lead to serious errors when using different data. One way to avoid this issue is through &lt;a href="http://en.wikipedia.org/wiki/Test-driven_development"&gt;test-driven development&lt;/a&gt;, writing a good testing suite that tests a wide range of unexpected inputs. I am not quite there yet, personally, but thinking about how my code would have to work with arbitrary inputs and ensuring it fails gracefully &lt;sup id="fnref:fallingwithstyle"&gt;&lt;a class="footnote-ref" href="#fn:fallingwithstyle" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt; is an excellent side benefit of preparing a pull request &lt;sup id="fnref:gitterms"&gt;&lt;a class="footnote-ref" href="#fn:gitterms" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt; . Third, it is an opportunity to write code for someone other than myself. Because I am often the sole analyst with my skillset working on a project, it is easy to not consider things like style, optimizations, clarity, etc. This can lead to large build-ups of &lt;a href="http://en.wikipedia.org/wiki/Technical_debt"&gt;technical debt&lt;/a&gt;, complacency toward learning new techniques, and general sloppiness. Submitting a pull request feels like publishing. The world has to read this, so it better be something I am proud of that can stand up to the scrutiny of third-party&amp;nbsp;users.&lt;/p&gt;
&lt;p&gt;My first pull request, which was accepted into the package, calculates age in years, months, or days at an arbitrary date based on date of birth. While even a beginning R programmer can develop a similar function, it is the perfect example of an easily compartmentalized component, with a broad set of applications, that can be accessed frequently&amp;nbsp;.&lt;/p&gt;
&lt;p&gt;Today I submitted by second pull request that I hope will be accepted. This time I covered a much more complex task&amp;#8212; calculating student mobility. To be honest, I am completely unaware of existing business rules and algorithms used to produce the mobility numbers that are federally reported. I wrote this function from scratch thinking through how I would calculate the number of schools attended by a student in a given year. I am really proud of both the business rules I have developed and the code I wrote to apply those rules. My custom function can accept fairly arbitrary inputs, fails gracefully when it finds data it does not expect, and is pretty fast. The original version of my code took close to 10 minutes to run on ~30,000 rows of data. I have reduced that with a complete rewrite prior to submission to 16&amp;nbsp;seconds.&lt;/p&gt;
&lt;p&gt;While I am not sure if this request will be accepted, I will be thrilled if it is. Mobility is a tremendously important statistic in education research and a standard, reproducible way to calculate it would be a great help to researchers. How great would it be if &lt;code&gt;eeptools&lt;/code&gt; becomes one of the first packages education data analysts load and my mobility calculations are used broadly by researchers and analysts? But even if it’s not accepted because it falls out of scope, the process of developing the business rules, writing an initial implementation of those rules, and then refining that code to be far simpler, faster, and less error prone was incredibly&amp;nbsp;rewarding.&lt;/p&gt;
&lt;p&gt;My next post will probably be a review of that process and some parts of my &lt;code&gt;moves_calc&lt;/code&gt; function that I&amp;#8217;m particularly proud&amp;nbsp;of.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:fuckexcel"&gt;
&lt;p&gt;Using a spreadsheet program, such as Excel, encourages directly manipulating and editing the source data. Each change permanently changes the data. Even if you keep an original version of the data, there is no recording of exactly what was done to change the data to produce your results. Reproducibility is all but impossible of any significant analysis done using spreadsheet software.&amp;#160;&lt;a class="footnote-backref" href="#fnref:fuckexcel" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:fallingwithstyle"&gt;
&lt;p&gt;Instead of halting the function with hard to understand error when things go wrong, I do my best to &amp;#8220;correct&amp;#8221; easily anticipated errors or report back to users in a plain way what needs to be fixed. See also &lt;a href="http://en.wikipedia.org/wiki/Fault-tolerant_system"&gt;fault-tolerant system&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref:fallingwithstyle" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:gitterms"&gt;
&lt;p&gt;A &lt;a href="https://help.github.com/articles/using-pull-requests"&gt;pull request&lt;/a&gt; is when you submit your additions, deletions, or any other modifications to be incorporated in someone else&amp;#8217;s repository.&amp;#160;&lt;a class="footnote-backref" href="#fnref:gitterms" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="education"></category><category term="data"></category><category term="rstats"></category></entry><entry><title>Some Changes for Rhode Island State Aid to Education</title><link href="http://blog.jsonbecker.com/2013/08/some-changes-for-rhode-island-state-aid-to-education.html" rel="alternate"></link><updated>2013-08-22T00:00:00-04:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-08-22:2013/08/some-changes-for-rhode-island-state-aid-to-education.html</id><summary type="html">&lt;p&gt;In December 2009, the education department head, Professor Kenneth K. Wong, another graduate student and myself were part of a three-person team consulting the Rhode Island Department of Education (&lt;span class="caps"&gt;RIDE&lt;/span&gt;) on how to establish a new state funding formula. We worked with finance and legal staff at the department to develop the legislation for the 2010 session that would establish a state funding formula for the first time in 15 years.
 
The Board of Regents had already passed a resolution with its policy priorities that they wanted enshrined in the formula. Additionally, there had been many attempts over the past 5-10 years to pass a new formula that failed for various reasons, chief among them that all previously proposed formulas were accompanied with a call to increase state funding for education 30-50%, with some even envisioning nearly doubling the state education funding. Our task was to research funding formulas, both in practice in other states and in the literature research on school finance, and achieve the goals of the Board of Regents without proposing a mammoth increase in state aid that would sink the entire endeavor &lt;sup id="fnref:increase"&gt;&lt;a class="footnote-ref" href="#fn:increase" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;. The general sense was that while more state aid had the potential to improve the progressiveness of education expenditures, the reality is the overall spending level in Rhode Island is high, and introducing new money was less important than redistributing state aid. I share this belief, particularly because I think adding money to the right places is simple once there is already a way to equitably distribute those funds. Tying up the increase in funding alongside a distribution method is a recipe for political horse-trading that can result in all kinds of distortions that prevent aid from flowing where&amp;nbsp;needed. &lt;/p&gt;
&lt;p&gt;My role in this process was primarily to create Excel simulators that would allow us to immediately track the impacts of changing different parts of the formula. I also helped &lt;span class="caps"&gt;RIDE&lt;/span&gt; staff interpret the meaning of changes to the math behind the funding formula and understand what levers existed to change the formula and how these changes impacted both the resulting distribution and&amp;nbsp;policy. &lt;/p&gt;
&lt;p&gt;We had three&amp;nbsp;months. &lt;/p&gt;
&lt;p&gt;There are a lot of people who are unhappy about the results of the formula that ultimately passed in June 2010. Because we are redistributing essentially the same amount of state aid, there are some districts that are losing money while others are gaining funds &lt;sup id="fnref:holdharmless"&gt;&lt;a class="footnote-ref" href="#fn:holdharmless" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;. Some dislike the fact that we used only a &amp;#8220;weight&amp;#8221; for free and reduced price lunch status. Alternative formulas (and formulas in other states) typically include numerous weights, from limited English proficiency and special education status, to gifted and talented and career and technical education &lt;sup id="fnref:ajello"&gt;&lt;a class="footnote-ref" href="#fn:ajello" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;. And yet others were displeased that many costs, including transportation and facilities maintenance, were excluded from the state-base of education aid. Then there are those who think the transition is all off&amp;#8212; five years is too long to wait to get the increases the formula proposes, and ten years is far too fast to lose the money the formula proposes. &lt;sup id="fnref:transitions"&gt;&lt;a class="footnote-ref" href="#fn:transitions" rel="footnote"&gt;4&lt;/a&gt;&lt;/sup&gt; &lt;/p&gt;
&lt;h3&gt;A Good State Aid&amp;nbsp;System&lt;/h3&gt;
&lt;p&gt;In the end, I am proud of the formula produced for several reasons. 
First, it passed successfully and has been fully funded (and sometimes more than fully funded) each year of implementation throughout a period of massive structural budget deficits. This is no small accomplishment. The advocacy community rightfully pushes us to build ideal systems, but in our role of policy entrepreneurs we are faced with the reality that a policy that does not become law and is not supported as law may as well not exist. Producing a formula that has some of the other positive qualities discussed below, passing that formula, and implementing the formula with little fanfare is not a small&amp;nbsp;accomplishment. &lt;/p&gt;
&lt;p&gt;Second, the formula is highly progressive, sending as much as 20 times more aid to some of our poorest communities in Rhode Island compared to the wealthiest. I am not positive how this compares to other states&amp;#8212; that&amp;#8217;s a topic I certainly want to work on for a future post&amp;#8212; but with just 39 cities and towns, it seems to show a high preference for &lt;em&gt;vertical equity&lt;/em&gt;, treating different cities and towns differently. There are communities on both ends of the distribution who want substantially more state funding, and our state aid formula is not sufficient to effectively crowd out local capacity for education spending and ensure that our poorest communities are spending more than our wealthier ones &lt;sup id="fnref:comparative"&gt;&lt;a class="footnote-ref" href="#fn:comparative" rel="footnote"&gt;5&lt;/a&gt;&lt;/sup&gt;, but it&amp;#8217;s a very strong&amp;nbsp;start. &lt;/p&gt;
&lt;p&gt;Third, the formula is relatively simple. While I do not necessarily agree that it is a virtue to have fewer weights and a simple formula in perpetuity, the experience with other states and other formula-based programs show that weights and complexities are very easy to add and very hard to take away. Once a particular policy preference is enshrined in the distribution method, it had better be right because a community of advocacy will maintain that weight long into the future. Personally, I felt it critical to start with the very simple &amp;#8220;core&amp;#8221; formula that could be adjusted over time. I have some ideas on how I might modify/add to this core that I will be sharing in this post, but I firmly believe that starting with a simple core was the right move. It is also worth noting that because of the need to ensure the transition is smoothed out so that gains in some districts equal the total losses in the others meant that even a more progressive weighting scheme would not impact school funding until the far back end of the transition period (which we proposed as 7 years but was pushed to 5 years during the legislative process), since communities were already gaining funds as fast as we could move them. For this reason, not only was a simple core preferable from my technocratic perspective, but it also was not likely to have any immediate&amp;nbsp;downside. &lt;/p&gt;
&lt;p&gt;Fourth, we removed the long-term regionalization bonuses. Rhode Island had sought to reduce the ridiculous number of school districts by providing a bonus for regionalizing in the early 90s. Unfortunately, because of the timing of the abandonment of the previous state aid formula, the districts that did choose to regionalize had their base funding locked in at a level 6-8% higher than it should have been, because they were receiving a bonus that was meant to fade away over the course of several years. I could justify a small increase in state funding to pay some of the transition expenses of regionalizing districts, but long term funding increases? Part of the goal of regionalization is the reduction of overhead that allows for decreased costs (or increased services at the same costs). There is no ongoing need to supply a massive state bonus for&amp;nbsp;regionalizing. &lt;/p&gt;
&lt;p&gt;Now just because I am proud of this work does not mean that I think we have &amp;#8220;solved&amp;#8221; education funding in Rhode Island. Personally, I believe there are other defensible ways to distribute funding in Rhode Island, each of which represents slightly different policy preferences. There is no hard and fast &amp;#8220;right&amp;#8221; or &amp;#8220;wrong&amp;#8221; way to do this, within certain guidelines. As I see it, so long as the formula is progressive and moving toward a greater chance of seeing a day where Providence has the highest paid staff in the state &lt;sup id="fnref:comparative"&gt;&lt;a class="footnote-ref" href="#fn:comparative" rel="footnote"&gt;5&lt;/a&gt;&lt;/sup&gt;, we are on the right path. I don&amp;#8217;t believe that Rhode Island will have a truly &amp;#8220;great&amp;#8221; education finance climate without a substantial growth in the economy or a huge new tax that dramatically lowers the ability of municipalities to generate school funding while bolstering state aid. However, I think we have a great foundation and a &amp;#8220;good&amp;#8221;&amp;nbsp;system. &lt;/p&gt;
&lt;p&gt;For the remainder of this post, I would like to propose a few ideas that could help move Rhode Island from &amp;#8220;good&amp;#8221; to &amp;#8220;very good&amp;#8221; that I think are feasible within the next five years &lt;sup id="fnref:goodtogreat"&gt;&lt;a class="footnote-ref" href="#fn:goodtogreat" rel="footnote"&gt;6&lt;/a&gt;&lt;/sup&gt;. &lt;/p&gt;
&lt;h3&gt;A Very Good State Aid&amp;nbsp;Program&lt;/h3&gt;
&lt;p&gt;After a little over three years since its establishment, I think we are ready to tackle several additional aspects of state education funding in Rhode Island. One thing you may notice is that few of these ideas impact the original formula. Part of why that is comes from my aforementioned preference for a simple formula, and part is because these include some non-formula issues that were not pursued in 2010 in an effort to keep the focus on the main policy matters. 
First, and perhaps the most consequential change that can be made to state funding, is the teacher pension fund payments. Currently, the state and local districts split the cost of teacher pension contributions 60/40. This is a flat split, regardless of the wealth of the community. I think it&amp;#8217;s absurd to ignore community wealth for such a large portion of state education expenditures. Using the Adjusted Equalized Weighted Assessment Values (&lt;span class="caps"&gt;AEWAV&lt;/span&gt;) to determine the reimbursement rates would be a big improvement on the progressiveness of school&amp;nbsp;funding. &lt;/p&gt;
&lt;p&gt;Second, I would make a slight change to the way that we fund charter schools. When we were developing the formula, there was broad agreement among policymakers that the &amp;#8220;money should follow the child&amp;#8221;. In one sense, this is the system we proposed since school district funding is based on enrollments. However, I think an irrational desire to not &amp;#8220;double count&amp;#8221; students, alongside the need to keep funding as flat as possible, pushed the formula a bit too far when it comes to charters. The old way of funding charter schools allowed districts to hold back 5% of the total per pupil expenditure from their charter school tuitions. This meant charter schools received 5% less funding than traditional public schools, but it also recognized that there are some fixed costs in districts that are not immediately recoverable when students leave on the margins. I think the state should return to this practice, however only if the state is willing to pay the withheld 5% to charters. I do think its fair to take into account some fixed costs, but I don&amp;#8217;t believe it&amp;#8217;s fair that charter schools received less funding as a&amp;nbsp;result. &lt;/p&gt;
&lt;p&gt;Third, we excluded all building maintenance costs from the base amount of state aid. This was largely because the formula was supposed to represent only the marginal instructional costs associated with each student. I don&amp;#8217;t necessarily think that these costs have to be added into the base amount. However, I would like to see the state contribute to the maintenance of buildings more directly. I think the state should provide a flat dollar amount, say &amp;#36;100,000, per building in each district, provided that key criteria are met. The buildings should be at 90% occupancy/utilization, should have a minimum size set based on the research on efficiency (roughly 300 students at the elementary level and 600 students for high schools), and there should be some minimum standard for building systems quality and upkeep. These requirements are mostly about making sure this flat fund, which is really about the fixed costs of maintaining buildings, doesn&amp;#8217;t create incentives to build more. It may seem inconsequential, but I think it&amp;#8217;s important to state the preference for well-sized, occupied &lt;sup id="fnref:occupied"&gt;&lt;a class="footnote-ref" href="#fn:occupied" rel="footnote"&gt;7&lt;/a&gt;&lt;/sup&gt;, and maintained buildings is&amp;nbsp;worthwhile. &lt;/p&gt;
&lt;p&gt;I think it&amp;#8217;s wrong that the minimum reimbursement rate for school construction aid was raised to 40% during the funding formula debates in the General Assembly. This amounts to a massive subsidy for suburban schools and the previous 30% minimum is part of why we have such stark facilities inequities in the state. We should remove the minimums on construction reimbursement and simply use &lt;span class="caps"&gt;AEWAV&lt;/span&gt; to determine the reimbursement rate. Also, we need to establish a revolving facilities loan fund, much like the one used for sewers (and now &lt;a href="http://blogs.wpri.com/2013/03/21/ricwfa-explainer/"&gt;roads and bridges&lt;/a&gt;). Access to lower interest bonds should not be dependent on city&amp;nbsp;finances. &lt;/p&gt;
&lt;p&gt;Fourth, one thing we did not include in the original funding formula that has come under considerably criticism is a special weight for students who are labeled English language learners. There are a few reasons we made this decision. The districts that have ELLs are the same districts that have high levels of poverty. In fact, the five communities that had more than 5% of their students classified as ELLs were, in order, also the top five districts with regards to free and reduced price lunch eligibility. Combined with a transition plan that was already increasing funding to these districts as rapidly as could be afforded, there were virtually no short-term consequences of not including an &lt;span class="caps"&gt;ELL&lt;/span&gt; weight. It&amp;#8217;s worth noting that formula dollars are not categorical funds&amp;#8212; there are no restrictions on how districts should spend this money, and there are no guarantees that an &lt;span class="caps"&gt;ELL&lt;/span&gt; weight would have any impact on &lt;span class="caps"&gt;ELL&lt;/span&gt;&amp;nbsp;spending. &lt;/p&gt;
&lt;p&gt;We were also concerned with incentivizing over-identification and failing to exit students who should no longer be classified as ELLs. I am also personally concerned with mistaking the additional supports we want to target as needed for English language acquisition; it would not only inspire the wrong policies and supports for these students, but it fails to recognize a host of needs that persist for these students well beyond English&amp;nbsp;acquisition. &lt;/p&gt;
&lt;p&gt;During the funding formula hearings at House and Senate Finance Committees we discussed the need for further study on this issue. I think that the next weight in the formula should be based on the Census and American Communities Survey. By using these data sets, classification of students who are eligible for the weight would not be dependent on the school district itself. Rather than focus on child language acquisition, I think we should broaden this weight to be applied based on the percentage of households that speak a language other than English in the home, where English is spoken at a level below &amp;#8220;very well&amp;#8221; &lt;sup id="fnref:technical"&gt;&lt;a class="footnote-ref" href="#fn:technical" rel="footnote"&gt;8&lt;/a&gt;&lt;/sup&gt;. This would ensure that students who live in language minority households receive additional supports throughout their education, regardless of their language acquisition status. I would make this weight lower than some in the literature because it would apply to a broader set of students, probably somewhere around 40% like the poverty weight. For reference, the latest five-year estimate from the &lt;span class="caps"&gt;ACS&lt;/span&gt; data shows that 24.3% of households fit this definition in the city of Providence. With a 40% weight, at 22,500 students, with a foundation amount of around \&lt;mathjax&gt;$9,000 per student, this weight would increase funding to Providence by a little over \$&lt;/mathjax&gt;16,000,000. Similar to other formula aid, these funds would be&amp;nbsp;unrestricted. &lt;/p&gt;
&lt;p&gt;Now, while I think that \&lt;mathjax&gt;$16,000,000 is no small potatoes, and I am happy to express our policy preference to drive funding into communities where families are not using English in the home, some perspective is warranted. Providence will receive almost \$&lt;/mathjax&gt;240,000,000 in state aid when the formula is fully transitioned, compared to about \$190,000,000 before. Adding this weight would only represent a 6% increase in state aid from the full formula amount. It&amp;#8217;s an important increase, but I hope you&amp;#8217;ll forgive me if I felt it was not grossly unfair to exclude it in the first iteration of the funding formula, especially considering we still have not fully transitioned to those higher dollar amounts sent to districts that would benefit from these&amp;nbsp;funds. &lt;/p&gt;
&lt;h3&gt;It Takes&amp;nbsp;Money&lt;/h3&gt;
&lt;p&gt;Each of these recommendations, in my view, would improve the way that Rhode Island distributes education aid. Some of the changes are technical, others address areas that are currently not considered, and some are purely about increasing the progressiveness of aid. All of these changes will require an even greater state contribution to education aid, but these increases would be an order of magnitude lower than what it would take to increase the state aid to covering 50-60% of all education expenditures. While I would support some pretty radical changes to drive more money into the state aid system, I think that each of these improvements are worth doing on the path to increased&amp;nbsp;aid. &lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:increase"&gt;
&lt;p&gt;I should note, that few people I spoke to were not in favor of raising the amount of state aid. We all want more money to come from the state because those dollars are far more progressive. However, Rhode Island was deep in its recession at this point in time and the dollar amounts to make a real dent in the state to local share in education are just staggering. Rhode Island currently funds just short of 40% of total school expenditures at the state level. To increase that to 60%, which is closer to the national average, they would have to contribute &amp;#36;500M more&amp;#8212; a roughly 60% increase from the current level. Just for some context, the main tax fight of Rhode Island progressives has been to repeal tax cuts for higher income individuals that were instituted starting in 2006 in an attempt to move toward a flat income tax rate in Rhode Island. The impact of this repeal would be an increase in revenues that would cover roughly 10% of the increase in school funding required to move from 40% to 60% state aid. Of course, those dollars are supposed to pay for some portion of restoring pension benefits, so it&amp;#8217;s already spoken for.&amp;#160;&lt;a class="footnote-backref" href="#fnref:increase" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:holdharmless"&gt;
&lt;p&gt;Hold harmless provisions, when introduced in other states, serve to dramatically distort the redistributive properties of state aid and almost always require a huge influx of funds. In fact, a hold harmless provision in Rhode Island would have required a doubling of state aid, which ultimately would have guaranteed that wealthy communities continue to receive too much state aid while less wealthy communities are stuck fighting year after year for tremendous revenue increases through taxation just to get their fair share. Essentially, hold harmless would ensure that you never reach formula-level spending and guarantee that state aid would not be very progressive.&amp;#160;&lt;a class="footnote-backref" href="#fnref:holdharmless" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:ajello"&gt;
&lt;p&gt;One very popular progressive member of the Rhode Island General Assembly had been working for years to pass a new funding formula and had five or six such weights in her version. Interestingly, with the glaring exception of sending &amp;#36;0 to Newport in state aid, the difference in the overall distribution of funds by district in Rhode Island using this formula and our formula was tiny, almost always &amp;lt;5%.&amp;#160;&lt;a class="footnote-backref" href="#fnref:ajello" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:transitions"&gt;
&lt;p&gt;Smoothing the &amp;#8220;gains&amp;#8221; and &amp;#8220;losses&amp;#8221; overtime was important to keep the formula as close to revenue neutral as possible. Of course, there are increases due to inflation and other factors each year as a part of the base, but our goal was to truly redistribute the funds such that not only is the end number not a big increase in total state aid but that getting through the transition period did not have huge costs. If it did, there is no way we could feel confident we would ever reach the point where the formula actually dictated state aid, much like the hold harmless provision prevents a full transition. Modeling various transition plans was a nightmare for me.&amp;#160;&lt;a class="footnote-backref" href="#fnref:transitions" rev="footnote" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:comparative"&gt;
&lt;p&gt;Many people forget that education spending is about competition within a single market. Overall spending matters less within this market than how you spend compared to others. The trick is that an urban school primarily working with traditionally under served families needs to be able to pay not just for more material supplies, but mostly for higher quality teachers and staff (and perhaps quantity). Because of compensating wage differentials, even hiring teachers and staff that are the same quality as wealthy communities costs more.&amp;#160;&lt;a class="footnote-backref" href="#fnref:comparative" rev="footnote" title="Jump back to footnote 5 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:goodtogreat"&gt;
&lt;p&gt;Perhaps I will write a future post on some ideas of how to push Rhode Island to &amp;#8220;great&amp;#8221;, even though I view all of those solutions as politically impossible.&amp;#160;&lt;a class="footnote-backref" href="#fnref:goodtogreat" rev="footnote" title="Jump back to footnote 6 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:occupied"&gt;
&lt;p&gt;I would include any leased space as occupied. We should encourage full utilization of the buildings, whether that includes charter schools, central office use, city government, or private companies. &amp;#160;&lt;a class="footnote-backref" href="#fnref:occupied" rev="footnote" title="Jump back to footnote 7 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:technical"&gt;
&lt;p&gt;This definition is clunky, but its how the &lt;span class="caps"&gt;ACS&lt;/span&gt; and Census track these things. This definition is clunky, but its how the &lt;span class="caps"&gt;ACS&lt;/span&gt; and Census track these things. We could verify the data using the data reported by districts about language spoken in the home. I would recommend using this data point to assist with whether or not to include these weights for charter schools. For example, approximately half of those families that do not speak English in the home also speak English very poorly. Therefore, I might apply half of the weight to each individual child whose family reports speaking a language other than English at home. Of course, the actual proportion of the weight should be specific to the ratio of speakers of language other than English to non-very well speakers of English by community.&amp;#160;&lt;a class="footnote-backref" href="#fnref:technical" rev="footnote" title="Jump back to footnote 8 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</summary><category term="education"></category><category term="rhode island"></category><category term="policy"></category><category term="funding"></category></entry><entry><title>What can be done for Rhode Island Pensioners?</title><link href="http://blog.jsonbecker.com/2013/08/what-can-be-done-for-rhode-island-pensioners.html" rel="alternate"></link><updated>2013-08-15T00:00:00-04:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-08-15:2013/08/what-can-be-done-for-rhode-island-pensioners.html</id><summary type="html">&lt;p&gt;&lt;em&gt;This post originally appeared on my old blog on January 2, 2013 but did not make the transition to this site due to error. I decided to repost it with a new date after recovering it from a cached version on the&amp;nbsp;web.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Rhode Island &lt;a href="http://blogs.wpri.com/2011/11/17/analysis-why-rhode-island-passed-pension-reform-in-2011/"&gt;passed sweeping pension reform last fall&lt;/a&gt;, &lt;a href="http://blogs.wpri.com/2011/11/21/union-email-blasts-dems-on-pension-law-previews-legal-fight/"&gt;angering&lt;/a&gt; the &lt;a href="http://blogs.wpri.com/2012/02/07/unions-to-ri-negotiate-a-pension-deal-before-you-lose-in-court/"&gt;major labor unions&lt;/a&gt; and &lt;a href="http://www.rifuture.org/tag/pension"&gt;progressives&lt;/a&gt; throughout the state. These reforms have &lt;a href="http://blogs.wpri.com/2011/10/24/moodys-raimondo-chafee-pension-bill-good-for-rhode-island/"&gt;significantly decreased both the short and long-run costs to the state&lt;/a&gt;, while &lt;a href="http://blogs.wpri.com/2011/11/17/ri-lawmakers-ok-historic-pension-overhaul-by-wide-margins/"&gt;decreasing the benefits of both current and future retirees&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;One of the &lt;a href="http://blogs.wpri.com/2011/09/16/raimondo-chafee-set-to-freeze-colas-put-all-in-hybrid-plan/"&gt;most controversial measures&lt;/a&gt; in the pension reform package was suspending annual raises &lt;sup id="fnref:raises"&gt;&lt;a class="footnote-ref" href="#fn:raises" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt; for current retirees. I have noticed two main critiques of this element. The first criticism was that ending this practice constitutes a decrease in benefits to existing retirees who did not consent to these changes, constituting a breach of contract and assault on property rights. This critique is outside of the scope of this post. What I would like to address is the second criticism, that annual raises are critical to retirement security due to inflation, especially for the most vulnerable pensioners who earn near-poverty level wages from their&amp;nbsp;pensions.&lt;/p&gt;
&lt;p&gt;While I am broadly supportive of the changes made to the pension system in Rhode Island, I also believe that it is important to recognize the differential impact suspending annual raises has on a retired statehouse janitor who currently earns \&lt;mathjax&gt;$22,000 a year from their pension and a former state department director earning \$&lt;/mathjax&gt;70,000 a year from their pension. Protecting the income of those most vulnerable to inflation is a worthy goal &lt;sup id="fnref:worthy"&gt;&lt;a class="footnote-ref" href="#fn:worthy" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;I have a simple recommendation that I think can have a substantial, meaningful impact on the most vulnerable retirees at substantially less cost than annual raises. This recommendation will be attractive to liberals and conservatives, as well as the “business elite” that have long called for increasing Rhode Island’s competitiveness with neighboring states. It is time that Rhode Island leaves the company of just three other states– Minnesota, Nebraska, and Vermont– that have no tax exemptions for retirement income &lt;sup id="fnref:exemptions"&gt;&lt;a class="footnote-ref" href="#fn:exemptions" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;. Rhode Island should exempt all income from pensions and social security up to 200% of the federal poverty level from state income taxes. This would go a long way to ensuring retirement security for those who are the most in need. It would also bring greater parity between our tax code and popular retirement destination states, potentially decreasing the impulse to move to New Hampshire, North Carolina, and&amp;nbsp;Florida.&lt;/p&gt;
&lt;p&gt;It’s a progressive win. It’s a decrease in taxes that conservatives should like. It shouldn’t have a serious impact on revenues, especially if it goes a long way toward quelling the union and progressive rancor about the recent reforms. And it’s far from unprecedented– in fact, some form of retirement income tax exemption exists in virtually every other&amp;nbsp;state.&lt;/p&gt;
&lt;p&gt;We should not be proud of taking away our most vulnerable pensioners’ annual raises, even if it was necessary. Instead of ignoring the clear impact of this provision, my hope for 2013 is that we address it, while keeping an overall pretty good change to Rhode Island’s state retirement&amp;nbsp;system.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:worthy"&gt;
&lt;p&gt;Interesting, increases in food prices has largely slowed and the main driver of inflation are healthcare costs. I wonder to what extent Medicare/Medicaid and Obamacare shield retirees from rising healthcare costs&amp;#160;&lt;a class="footnote-backref" href="#fnref:worthy" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:exemptions"&gt;
&lt;p&gt;http://www.ncsl.org/documents/fiscal/TaxonPensions2011.pdf&amp;#160;&lt;a class="footnote-backref" href="#fnref:exemptions" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:raises"&gt;
&lt;p&gt;&lt;a href="http://blog.jasonpbecker.com/blog/2012/01/25/providence-pensions-lets-call-a-spade-a-spade-or-the-cola-a-raise/"&gt;Not a cost-of-living adjustment&lt;/a&gt;, or &lt;span class="caps"&gt;COLA&lt;/span&gt;, as some call them.&amp;#160;&lt;a class="footnote-backref" href="#fnref:raises" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;&lt;script type= "text/javascript"&gt;
    if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
        var mathjaxscript = document.createElement('script');
        mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
        mathjaxscript.type = 'text/javascript';
        mathjaxscript.src = 'https:' == document.location.protocol
                ? 'https://c328740.ssl.cf1.rackcdn.com/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'
                : 'http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML';
        mathjaxscript[(window.opera ? "innerHTML" : "text")] =
            "MathJax.Hub.Config({" +
            "    config: ['MMLorHTML.js']," +
            "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'AMS' } }," +
            "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
            "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
            "    displayAlign: 'center'," +
            "    displayIndent: '0em'," +
            "    showMathMenu: true," +
            "    tex2jax: { " +
            "        inlineMath: [ ['$','$'] ], " +
            "        displayMath: [ ['$$','$$'] ]," +
            "        processEscapes: true," +
            "        preview: 'TeX'," +
            "    }, " +
            "    'HTML-CSS': { " +
            "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'black ! important'} }" +
            "    } " +
            "}); ";
        (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
    }
&lt;/script&gt;
</summary><category term="pensions"></category><category term="rhode island"></category><category term="reform"></category><category term="unions"></category></entry><entry><title>Smarter Balance Released Items Scare Me</title><link href="http://blog.jsonbecker.com/2013/07/smarter-balance-released-items-scare-me.html" rel="alternate"></link><updated>2013-07-23T00:00:00-04:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-07-23:2013/07/smarter-balance-released-items-scare-me.html</id><summary type="html">&lt;p&gt;&lt;a href="http://ccssimath.blogspot.com/2013/06/our-sbac-practice-tests-run-through.html"&gt;&lt;span class="caps"&gt;CCSSI&lt;/span&gt; Mathematics&lt;/a&gt; posted a scathing look at the items released by the &lt;a href="http://www.smarterbalanced.org/"&gt;Smarter Balanced Assessment Consortium&lt;/a&gt; (&lt;span class="caps"&gt;SBAC&lt;/span&gt;). While the rest of the internet seems to be obsessed over &lt;a href="http://blogs.edweek.org/edweek/curriculum/2013/07/georgia_drops_out_of_parcc_tes.html"&gt;Georgia leaving the Partnership for Assessment of College and Careers&lt;/a&gt;&lt;sup id="fnref:absurdity"&gt;&lt;a class="footnote-ref" href="#fn:absurdity" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;, the real concern should be over the quality of these test&amp;nbsp;items.&lt;/p&gt;
&lt;p&gt;Although &lt;span class="caps"&gt;CCSSI&lt;/span&gt; also deligently point out questions that are not well aligned to the standards, this is the least of my worries. Adjusting the difficulty of items and better alignment is something that testing companies know how to do and deal with all the time. Computerized testing is the new ground and a big part of why states are, rightfully, excited about the&amp;nbsp;consortium. &lt;/p&gt;
&lt;p&gt;The problem with the &lt;span class="caps"&gt;SBAC&lt;/span&gt; items is they represent the worst of computerized assessment. Rather than demonstrating more authentic and complex tasks, they present convoluted scenarios and even more convoluted input methods. Rather than present multimedia in a way that is authentic to the tasks, we see heavy language describing how to input what amounts to multiple choice or fill-in the blank answers. What I see here is not worth the investment in time and equipment that states are being asked to make, and it is hardly a &amp;#8220;next generation&amp;#8221; set of items that will allow us to attain more accurate measures of&amp;nbsp;achievement. &lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;SBAC&lt;/span&gt; looks poised to set up students to fail because of the mechanations of test taking. This is not only tragic at face value, but assures an increase in test-prep as the items are less&amp;nbsp;authentic.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:absurdity"&gt;
&lt;p&gt;There was a lot of concern trolling over Georgia leaving &lt;span class="caps"&gt;PARCC&lt;/span&gt; by &lt;a href="http://www.edexcellence.net/commentary/education-gadfly-daily/flypaper/2013/thats-how-the-consortia-crumble.html"&gt;Andy Smarick on Twitter and Flypaper&lt;/a&gt;. I don&amp;#8217;t really see this as devastating, nor do I think some kind of supplication to the Tea Party could have changed this. Short of federal mandating of common tests and standards, Georgia was never going to stay aligned with a consortium that includes Massachusetts. Georgia has an incredibly inexpensive testing program, because they have built really poor assessments that are almost entirely multiple choice. They also have some of the &lt;a href="http://educationnext.org/despite-common-core-states-still-lack-common-standards/"&gt;lowest proficiency standards in the country&lt;/a&gt;. There was no way this state would move up to a testing regime that costs more than twice as much (but is around the country median) that is substantially more complex and will have a much higher standard for proficiency. Georgia is one of those states that clearly demonstrates some of the &amp;#8220;soft bigotry of low expectations&amp;#8221; by hiding behind inflated proficiency due to low standards.&amp;#160;&lt;a class="footnote-backref" href="#fnref:absurdity" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="education"></category><category term="assessment"></category><category term="ccss"></category><category term="sbac"></category></entry><entry><title>Economic Policy Institute is Wrong</title><link href="http://blog.jsonbecker.com/2013/06/economic-policy-institute-is-wrong.html" rel="alternate"></link><updated>2013-06-20T00:00:00-04:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-06-20:2013/06/economic-policy-institute-is-wrong.html</id><summary type="html">&lt;p&gt;The &lt;a href="http://www.epi.org/"&gt;Economic Policy Institute&lt;/a&gt; has release a &lt;a href="http://www.epi.org/files/2013/ib366-rhode-islands-hybrid-pension-plan.pdf"&gt;short issue brief&lt;/a&gt; on the Rhode Island Retirement Security Act (&lt;span class="caps"&gt;RIRSA&lt;/span&gt;) by &lt;a href="https://twitter.com/rhiltnsmth"&gt;Robert Hiltonsmith&lt;/a&gt; that manages to get all of the details right but the big picture entirely&amp;nbsp;wrong.&lt;/p&gt;
&lt;p&gt;The &lt;span class="caps"&gt;EPI&lt;/span&gt; Issue Brief details the differences between the retirement system for state workers before and after the passage of &lt;span class="caps"&gt;RIRSA&lt;/span&gt; as accurately and clearly as I have ever seen. Mr. Hiltonsmith has done a notable job explaining the differences between the new system and the old&amp;nbsp;system.&lt;/p&gt;
&lt;p&gt;The brief, unfortunately, fails by engaging in two common fallacies to support its broader conclusions. The first is the &lt;a href="http://en.wikipedia.org/wiki/Straw_man"&gt;straw man fallacy&lt;/a&gt;. Mr. Hiltonsmith takes a limited set of the objectives of the entire &lt;span class="caps"&gt;RIRSA&lt;/span&gt; legislation and says defined contribution plans do not meet those objectives. That is true, but ignores the other objectives it does accomplish which were also part of the motivation behind &lt;span class="caps"&gt;RIRSA&lt;/span&gt;. The second is &lt;a href="http://en.wikipedia.org/wiki/Circular_reasoning"&gt;circular reasoning&lt;/a&gt;. In this case, Mr. Hiltonsmith states that the reason for a low funding ratio is because the state did not put 100% of its paper liability into the pension fund. This is a tautology and not in dispute and should not be trumpeted as a conclusion of&amp;nbsp;analysis.&lt;/p&gt;
&lt;p&gt;Here are his three main points that he believes makes &lt;span class="caps"&gt;RIRSA&lt;/span&gt; a bad&amp;nbsp;policy:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The defined contribution plan does not save the state money from its annual pension&amp;nbsp;contributions.&lt;/li&gt;
&lt;li&gt;The defined contribution plan is likely to earn lower returns and therefore result in lower benefits for&amp;nbsp;retirees.&lt;/li&gt;
&lt;li&gt;The defined contribution plan does not solve the low funding ratio of the pension plan which exists because law makers did not make required&amp;nbsp;contributions.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Of course, the defined contribution portion of &lt;span class="caps"&gt;RIRSA&lt;/span&gt; was not in place to do any of these three things. The purpose of including a defined contribution plan in the new state pension system is to create stability in annual budget allocations and avoid locking the government into promises it has demonstrated it fails to keep. Defined benefit plans require the state to change pension contributions when there are market fluctuations and leads to anti-cyclical costs, where the state is forced to put substantially more resources into pensions when revenues are lowest and spending on social welfare is most important. The defined contribution plan keeps the payments required by the state consistent and highly predictable. This is far preferable from a budget&amp;nbsp;perspective. &lt;/p&gt;
&lt;p&gt;It is unfortunate that there are lower returns to defined contribution plans which may lead to a decrease in overall benefits. It is my opinion that the unions in Rhode Island should be pushing for a substantially better match on the defined contribution portion of their plan that more closely resembles private sector match rates. This could more than alleviate the difference in benefits while maintaining the predictability, for budgeting purposes, of the defined contribution plan. I doubt this policy would have much hope of passing while Rhode Island slowly crawls out of a deep recession, but it is certainly a reasonable matter for future&amp;nbsp;legislatures.&lt;/p&gt;
&lt;p&gt;There are only two ways to decrease the current pension fund shortfalls: increase payments to the fund or decrease benefits. There is no structural magic sauce to get around this. Structural changes in the pension system are aimed at reducing the likelihood that the state will reproduce its current situation, with liabilities well outstripping funds. It is true that the &amp;#8220;savings&amp;#8221; largely came from cutting benefits. I have not heard anyone claim otherwise. The only alternative was to put a big lump sum into the pension fund. That clearly was not a part of &lt;span class="caps"&gt;RIRSA&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;It is absurd to judge &lt;span class="caps"&gt;RIRSA&lt;/span&gt; on the ability of defined contribution plans to achieve policy objectives that are unrelated to the purpose of this structural&amp;nbsp;change.&lt;/p&gt;
&lt;p&gt;Perhaps the most troubling conclusion of this brief was&amp;nbsp;that, &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The shortfall in Rhode Island’s pension plan for public employees is largely due not to overly generous benefits, but to the failure of state and local government employers to pay their required share of pensions’&amp;nbsp;cost.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I read that and expected to see evidence of skipped payments or a discussion of overly ambitious expectations for investment returns, etc. Instead, it seems that this conclusion is based simply on the fact that the benefits in Rhode Island were not deemed outrageously large, and therefore Rhode Island should just pay the liability hole. The &amp;#8220;failure&amp;#8221; here is predicated entirely on the idea that the pensions as offered should be met, period, whatever the cost to the government. This is the &amp;#8220;required share&amp;#8221;. Which, of course, is technically true without a change in the law, but feels disingenuous. It is essentially a wholesale agreement with the union interpretation of the state pension system as an immutable contract. The courts will likely resolve whether or not this is true. My objection is that Mr. Hiltonsmith makes a definitive statement on this rationale without describing it. In such a lucid description of how the retirement system has changed, it seems this could only be intentional omission intended to support a predetermined conclusion rather than illuminate the&amp;nbsp;unconvinced.&lt;/p&gt;
&lt;p&gt;Mr. Hiltonsmith also claims that, &amp;#8220;Over the long term, &lt;span class="caps"&gt;RIRSA&lt;/span&gt; may cost the state upwards of \$15 million a year in additional contributions while providing a smaller benefit for the average full-career worker.&amp;#8221; I am not 100% certain, but based on his use of the normal cost &lt;sup id="fnref:normal cost"&gt;&lt;a class="footnote-ref" href="#fn:normal cost" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; to do these calculations, it appears this conclusion is drawn only based on the marginal contributions to current employees. In other words, if we &lt;em&gt;completely ignore&lt;/em&gt; the existing liability, the new plan cost the state more money marginally while potentially decreasing benefits for employees. It is my opinion that Mr. Hiltonsmith is intentionally creating the perception that &lt;span class="caps"&gt;RIRSA&lt;/span&gt; costs more than the current plan while providing fewer benefits. Again, this is true for future liabilities, but ignores that &lt;span class="caps"&gt;RIRSA&lt;/span&gt; also dramatically decreased the unfunded liabilities through cutting existing retiree benefits. So the overall cost for the act is far less, while the marginal cost was increased with the objective of decreasing the instability in government&amp;nbsp;appropriations.&lt;/p&gt;
&lt;p&gt;We can have a serious debate about whether there is value in the state goals of a defined contribution plan. In my view, the purpose of switching to this structure is&amp;nbsp;about: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Portability of plans for more mobile workers, potentially serving to attract younger and more highly skilled&amp;nbsp;employees. &lt;/li&gt;
&lt;li&gt;Stability in government expenditures on retiree benefits from year to year that are less susceptible to market forces. This includes avoiding the temptation to reduce payments when there are strong market returns as well as the crushing difficulty of increasing payments when the market (and almost certainly government receipts) are&amp;nbsp;down.&lt;/li&gt;
&lt;li&gt;Insulating workers from a government that perpetually writes checks they can cash, as was the case with the current&amp;nbsp;system.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This paper does not address any of these objectives or others I might have forgotten. In essence, the brief looks at only one subset of the perceived costs of this structural change, but it is far from a comprehensive analysis of the potential universe of both costs and benefits. In fact, it fails to even address the most commonly cited benefits. That is why I view it as heavily biased and flawed, even if I might draw similar conclusions from a more thorough&amp;nbsp;analysis.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:normal cost"&gt;
&lt;p&gt;Definition: Active participants earn new benefits each year. Actuaries call that the normal cost. The normal cost is always reflected in the cash and accounting cost of the plan. &lt;a href="http://www.actuary.org/pdf/pension/fundamentals_0704.pdf"&gt;Source&lt;/a&gt; In other words, the normal cost only looks at the new benefits added to the liability, not the existing liability.&amp;#160;&lt;a class="footnote-backref" href="#fnref:normal cost" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="rirsa"></category><category term="ri"></category><category term="pension"></category></entry><entry><title>Calculating Age in R</title><link href="http://blog.jsonbecker.com/2013/06/calculating-age-in-r.html" rel="alternate"></link><updated>2013-06-12T00:00:00-04:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-06-12:2013/06/calculating-age-in-r.html</id><summary type="html">&lt;p&gt;A few months back I wrote some code to calculate age from a date of birth and arbitrary end date. It is not a real tricky task, but it is certainly one that comes up often when doing research on individual-level&amp;nbsp;data.&lt;/p&gt;
&lt;p&gt;I was a bit surprised to only find bits and pieces of code and advice on how to best go about this task. After reading through some old R-help and Stack Overflow responses on various ways to do date math in R, this is the function I wrote &lt;sup id="fnref:wrote"&gt;&lt;a class="footnote-ref" href="#fn:wrote" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;age_calc &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;dob&lt;span class="p"&gt;,&lt;/span&gt; enddate&lt;span class="o"&gt;=&lt;/span&gt;Sys.Date&lt;span class="p"&gt;(),&lt;/span&gt; units&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;months&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
  &lt;span class="kr"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;inherits&lt;span class="p"&gt;(&lt;/span&gt;dob&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Date&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="o"&gt;!&lt;/span&gt;inherits&lt;span class="p"&gt;(&lt;/span&gt;enddate&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Date&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    stop&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Both dob and enddate must be Date class objects&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  start &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; as.POSIXlt&lt;span class="p"&gt;(&lt;/span&gt;dob&lt;span class="p"&gt;)&lt;/span&gt;
  end &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; as.POSIXlt&lt;span class="p"&gt;(&lt;/span&gt;enddate&lt;span class="p"&gt;)&lt;/span&gt;

  years &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; end&lt;span class="o"&gt;$&lt;/span&gt;year &lt;span class="o"&gt;-&lt;/span&gt; start&lt;span class="o"&gt;$&lt;/span&gt;year
  &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;units&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;years&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    result &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; ifelse&lt;span class="p"&gt;((&lt;/span&gt;end&lt;span class="o"&gt;$&lt;/span&gt;mon &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; start&lt;span class="o"&gt;$&lt;/span&gt;mon&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; 
                      &lt;span class="p"&gt;((&lt;/span&gt;end&lt;span class="o"&gt;$&lt;/span&gt;mon &lt;span class="o"&gt;==&lt;/span&gt; start&lt;span class="o"&gt;$&lt;/span&gt;mon&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;end&lt;span class="o"&gt;$&lt;/span&gt;mday &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; start&lt;span class="o"&gt;$&lt;/span&gt;mday&lt;span class="p"&gt;)),&lt;/span&gt;
                      years &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; years&lt;span class="p"&gt;)&lt;/span&gt;    
  &lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="kr"&gt;else&lt;/span&gt; &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;units&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;months&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    months &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;years&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="m"&gt;12&lt;/span&gt;
    result &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; months &lt;span class="o"&gt;+&lt;/span&gt; start&lt;span class="o"&gt;$&lt;/span&gt;mon
  &lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="kr"&gt;else&lt;/span&gt; &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;units&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;days&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    result &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; difftime&lt;span class="p"&gt;(&lt;/span&gt;end&lt;span class="p"&gt;,&lt;/span&gt; start&lt;span class="p"&gt;,&lt;/span&gt; units&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;days&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="kr"&gt;else&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
    stop&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Unrecognized units. Please choose years, months, or days.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="kr"&gt;return&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;result&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;A few notes on proper usage and the choices I made in writing this&amp;nbsp;function: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The parameters &lt;code&gt;dob&lt;/code&gt; and &lt;code&gt;enddate&lt;/code&gt; expect data that is already in one of the various classes that minimally inherits the base class &lt;code&gt;Date&lt;/code&gt;. &lt;/li&gt;
&lt;li&gt;This function takes advantage of the way that R treats vectors, so both &lt;code&gt;dob&lt;/code&gt; and &lt;code&gt;enddate&lt;/code&gt; can be a single or multi-element vector. For example &lt;code&gt;enddate&lt;/code&gt; is a single date, as is the default, then the function will return a vector that calculates the difference between &lt;code&gt;dob&lt;/code&gt; and that single date for each element in &lt;code&gt;dob&lt;/code&gt;. If &lt;code&gt;dob&lt;/code&gt; and &lt;code&gt;enddate&lt;/code&gt; are both vectors with n&amp;gt;1, then the returned vector will contain the &lt;a href="http://heather.cs.ucdavis.edu/~matloff/r.old.html#elementwise"&gt;element-wise&lt;/a&gt; difference between &lt;code&gt;dob&lt;/code&gt; and &lt;code&gt;enddate&lt;/code&gt;. When the vectors are of different sizes, the shorter vector will be repeated over until it reaches the same length as the longer vector. This is known as &lt;a href="http://cran.r-project.org/doc/manuals/R-intro.html#The-recycling-rule"&gt;recycling&lt;/a&gt;, and it is the default behavior in&amp;nbsp;R.&lt;/li&gt;
&lt;li&gt;This function always returns an integer. Calculating age in years will never return, say, 26.2. Instead, it assumes that the correct behavior for age calculations is something like a &lt;code&gt;floor&lt;/code&gt; function. For examle, the function will only return 27 if &lt;code&gt;enddate&lt;/code&gt; is minimally your 27th birthday. Up until that day you are considered 26. The same is true for age in&amp;nbsp;months.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is probably the first custom function in almost 3 years using R that I wrote to be truly generalizable. I was inspired by three factors. First, this is a truly frequent task that I will have to apply to many data sets in the future that I don&amp;#8217;t want to have to revisit. Second, a professional acquaintance, &lt;a href="http://jaredknowles.com/"&gt;Jared Knowles&lt;/a&gt;, is putting together a &lt;span class="caps"&gt;CRAN&lt;/span&gt; package with various convenience functions for folks who are new to R and using it to analyze education data &lt;sup id="fnref:eeptools"&gt;&lt;a class="footnote-ref" href="#fn:eeptools" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;. This seemed like an appropriate addition to that package, so I wanted to write it to that standard. In fact, it was my first (and to date, only) submitted and accepted pull request on Github. Third, it is a tiny, simple function so it was easy to wrap my head around and write it well. I will let you be the judge of my success or failure &lt;sup id="fnref:inspiration"&gt;&lt;a class="footnote-ref" href="#fn:inspiration" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:wrote"&gt;
&lt;p&gt;I originally used &lt;code&gt;Sys.time()&lt;/code&gt; not realizing there was a &lt;code&gt;Sys.Date()&lt;/code&gt; function. Thanks to Jared Knowles for that edit in preparation for a &lt;span class="caps"&gt;CRAN&lt;/span&gt; check.&amp;#160;&lt;a class="footnote-backref" href="#fnref:wrote" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:eeptools"&gt;
&lt;p&gt;Check out &lt;a href="https://github.com/jknowles/eeptools"&gt;eeptools&lt;/a&gt; on Github.&amp;#160;&lt;a class="footnote-backref" href="#fnref:eeptools" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:inspiration"&gt;
&lt;p&gt;Thanks to &lt;a href="http://mcfromnz.wordpress.com/2013/06/12/updated-age-calculation-function/"&gt;Matt&amp;#8217;s Stats n Stuff&lt;/a&gt; for getting me to write this post. When I saw another age calculation function pop up on the r-bloggers feed I immediately thought of this function. Matt pointed out that it was quite hard to Google for age calculations in R, lamenting that Google doesn&amp;#8217;t meaningfully crawl Github where I linked to find my code. So this post is mostly about providing some help to less experience R folks who are frantically Googling as both Matt and I did when faced with this need.&amp;#160;&lt;a class="footnote-backref" href="#fnref:inspiration" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="rstats"></category><category term="r"></category><category term="code"></category></entry><entry><title>Linear Thinking</title><link href="http://blog.jsonbecker.com/2013/06/linear-thinking.html" rel="alternate"></link><updated>2013-06-02T00:00:00-04:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-06-02:2013/06/linear-thinking.html</id><summary type="html">&lt;p&gt;Apple will be revealing new details for both of its major operating systems at &lt;span class="caps"&gt;WWDC&lt;/span&gt; on June 10, 2013. The focus of much speculation has been how Apple will improve multi-tasking and inter-app communication in iOS7. As batteries have grown, CPUs have become increasingly powerful, and the application &lt;a href="http://blog.jsonbecker.com/2012/11/frictionless.html"&gt;ecosystem&lt;/a&gt; has matured &lt;sup id="fnref:viticci"&gt;&lt;a class="footnote-ref" href="#fn:viticci" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;, the iOS sandboxing model has felt increasingly limiting and&amp;nbsp;outdated.&lt;/p&gt;
&lt;p&gt;I think that there is a simple change that could dramatically increase the effectiveness of multitasking on iOS by re-examining how application switching&amp;nbsp;works.&lt;/p&gt;
&lt;p&gt;Scrolling through a long list of applications, either through the basement shelf or via the four-finger gesture on an iPad, is both slow and lacking in contextual cues. In a simple case where I am working with two applications simultaneously, how do I switch between them? The list of open applications always places the current application in the first position. The previously used application sits in the second position. The first time I want to change to another application this is not so bad. I move to the &amp;#8220;right&amp;#8221; on the list to progress forward into the next application &lt;sup id="fnref:next"&gt;&lt;a class="footnote-ref" href="#fn:next" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;. &lt;/p&gt;
&lt;p&gt;The trouble comes when I want to return to where I was just working. The most natural mental model for this switch is to move &amp;#8220;left&amp;#8221; in the list. I moved &amp;#8220;right&amp;#8221; to get here and millions of years of evolution has taught me the the &amp;#8220;undo button&amp;#8221; for moving right is to move left &lt;sup id="fnref:inform7"&gt;&lt;a class="footnote-ref" href="#fn:inform7" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;. But of course, when I attempt to move &amp;#8220;left&amp;#8221;, I find no destination &lt;sup id="fnref:youcant"&gt;&lt;a class="footnote-ref" href="#fn:youcant" rel="footnote"&gt;4&lt;/a&gt;&lt;/sup&gt;. I can pop an application from anywhere on the list, but I can only prepend new applications to the list &lt;sup id="fnref:ignorant"&gt;&lt;a class="footnote-ref" href="#fn:ignorant" rel="footnote"&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;Apple needs to move away from its linear thinking and enter the second&amp;nbsp;dimension.&lt;/p&gt;
&lt;p&gt;What if I could drag apps in the switcher on top of each other to make a new stack, not unlike the option on the &lt;span class="caps"&gt;OS&lt;/span&gt; X launch bar? Throughout this stack, position is maintained regardless of which application is in use/was last used. I can always move &lt;strong&gt;up&lt;/strong&gt; from Chrome to ByWord, and &lt;strong&gt;down&lt;/strong&gt; to Good Reader, for example, if I was writing a report. Apple might call this a Stack, mirroring the term in &lt;span class="caps"&gt;OSX&lt;/span&gt;, but I would prefer this to be called a &lt;em&gt;Flow&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The goal of this feature is to organize a &lt;em&gt;Flow&lt;/em&gt; for a particular task that requires using multiple apps. One feature might be saving a &amp;#8220;Flow&amp;#8221;, this way each time I want to write a blog post, I tap the same home screen button and the same four apps in the same order launch in a &lt;em&gt;Flow&lt;/em&gt;, ready for easy switching using the familiar four-finger swipe gesture up and down. I no longer have to worry about the sequence I have recently accessed applications which is confusing and requires me to look at the app switcher draw or needlessly and repeatedly swipe through applications. I never have to worry about lingering too long on one application while swiping through and switching to that app, changing my position to the origin of the list and starting over&amp;nbsp;again. &lt;/p&gt;
&lt;p&gt;For all the calls for complex inter-app communication or having multiple apps active on the screen at the same time, it seems a simple interface change to application switching could complete change the way we multitask on&amp;nbsp;iOS.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:viticci"&gt;
&lt;p&gt;And Federico Viticci has either shown us the light or gone completely mad.&amp;#160;&lt;a class="footnote-backref" href="#fnref:viticci" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:next"&gt;
&lt;p&gt;For now, lets assume the right application is next in the stack. I&amp;#8217;ll get to that issue with my second change.&amp;#160;&lt;a class="footnote-backref" href="#fnref:next" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:inform7"&gt;
&lt;p&gt;&lt;code&gt;You are in a green room. &amp;gt; Go east. You are in a red room. &amp;gt; Go west. You are in a green room.&lt;/code&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:inform7" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:youcant"&gt;
&lt;p&gt;&lt;code&gt;You can't go that way.&lt;/code&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:youcant" rev="footnote" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:ignorant"&gt;
&lt;p&gt;I don&amp;#8217;t know enough about data structures yet to name what&amp;#8217;s going on here. I am tempted to think that the challenge is they have presented a list to users, with a decidedly horizontal metaphor, when they actually have created something more akin to a stack, with a decidedly vertical metaphor. But a stack isn&amp;#8217;t quite the right way to understand the app switcher. You can &amp;#8220;pop&amp;#8221; an app from any arbitrary position on the app switcher, but funny enough can only push a new app on to the top of the switcher.&amp;#160;&lt;a class="footnote-backref" href="#fnref:ignorant" rev="footnote" title="Jump back to footnote 5 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="apple"></category><category term="ios7"></category><category term="osx"></category><category term="interface"></category></entry><entry><title>Cleaning URLs with TextExpander</title><link href="http://blog.jsonbecker.com/2013/05/cleaning-urls-with-textexpander.html" rel="alternate"></link><updated>2013-05-30T00:00:00-04:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-05-30:2013/05/cleaning-urls-with-textexpander.html</id><summary type="html">&lt;p&gt;One thing I really dislike about Google Reader is it replaces the links to posts in my &lt;span class="caps"&gt;RSS&lt;/span&gt; feed. My &lt;a href="http://pinboard.in/u:jasonpbecker"&gt;Pinboard account&lt;/a&gt; is littered with links that start with &lt;code&gt;http://feedproxy.google.com&lt;/code&gt;. I am quite concerned that with the demise of &lt;a href="http://googlereader.blogspot.com/2013/03/powering-down-google-reader.html"&gt;Google Reader&lt;/a&gt; on July 1, 2013, these redirects will no longer&amp;nbsp;work.&lt;/p&gt;
&lt;p&gt;It&amp;#8217;s not just Google that obscures the actually address of links on the internet. The popularity of using link shortening services, both to save characters on Twitter and to collect analytics, has proliferated the &lt;em&gt;Internet of Redirects&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Worse still, after I am done cutting through redirects, I often find that the ultimate link include all kinds of extraneous attributes, most especially a barrage of &lt;code&gt;utm_*&lt;/code&gt; campaign&amp;nbsp;tracking.&lt;/p&gt;
&lt;p&gt;Now, I understand why all of this is happening and the importance of the services and analytics this link cruft provides. I am quite happy to click on shortened links, move through all the redirects, and let sites know just how I found them. But quite often, like when using a bookmarking service or writing a blog post, I just want the simple, plain text &lt;span class="caps"&gt;URL&lt;/span&gt; that gets me directly to the permanent home of the&amp;nbsp;content.&lt;/p&gt;
&lt;p&gt;One part of my workflow to deal with link cruft is a TextExpander snippet I call &lt;code&gt;cleanURL&lt;/code&gt;. It triggers a simple Python script that grabs the &lt;span class="caps"&gt;URL&lt;/span&gt; in my clipboard, traces through the redirects to the final destination, then strips links of campaign tracking attributes, and ultimately pastes a new &lt;span class="caps"&gt;URL&lt;/span&gt; that is much&amp;nbsp;&amp;#8220;cleaner&amp;#8221;.&lt;/p&gt;
&lt;p&gt;Below I have provided the script. I hope it is useful to some other folks, and I would love some recommendations for additional &amp;#8220;cleaning&amp;#8221; that could be&amp;nbsp;performed.&lt;/p&gt;
&lt;p&gt;My next task is expanding this script to work with &lt;a href="http://pinboard.in"&gt;Pinboard&lt;/a&gt; so that I can clean up all my links before the end of the month when Google Reader goes belly&amp;nbsp;up.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/usr/bin/python&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;requests&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;re&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;search&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;subprocess&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;check_output&lt;/span&gt;

&lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;check_output&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;pbpaste&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# Go through the redirects to get the destination URL&lt;/span&gt;
&lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# Look for utm attributes&lt;/span&gt;
&lt;span class="n"&gt;match&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;r&amp;#39;[?&amp;amp;#]utm_&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# Because I&amp;#39;m not smart and trigger this with&lt;/span&gt;
&lt;span class="c"&gt;# already clean URLs&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;match&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;cleanURL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;match&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;group&lt;/span&gt;&lt;span class="p"&gt;())[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;cleanURL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;cleanURL&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="textexpander"></category><category term="code"></category><category term="snippets"></category></entry></feed>