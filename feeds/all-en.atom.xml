<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>jasonpbecker</title><link href="http://blog.jsonbecker.com/" rel="alternate"></link><link href="http://blog.jsonbecker.com/feeds/all-en.atom.xml" rel="self"></link><id>http://blog.jsonbecker.com/</id><updated>2013-11-19T00:00:00-05:00</updated><entry><title>More evidence for “mere facts”</title><link href="http://blog.jsonbecker.com/2013/11/more-evidence-for-mere-facts.html" rel="alternate"></link><updated>2013-11-19T00:00:00-05:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-11-19:2013/11/more-evidence-for-mere-facts.html</id><summary type="html">&lt;blockquote&gt;
&lt;p&gt;To recap, the first study discussed above established that children from disadvantaged backgrounds know less about a topic (i.e., birds) than their middle-class peers. Next, in study two, the researchers showed that differences in domain knowledge influenced children’s ability to understand words out of context, and to comprehend a story. Moreover, poor kids — who also had more limited knowledge — perform worse on these tasks than did their middle class peers. But could additional knowledge be used to level the playing field for children from less affluent backgrounds? &lt;br&gt;&lt;br&gt;
In study three, the researchers held the children’s prior knowledge constant by introducing a fictitious topic — i.e., a topic that was sure to be unknown to both groups. When the two groups of children were assessed on word learning and comprehension related to this new domain, the researchers found no significant differences in how poor and middle-class children learned words, comprehended a story or made&amp;nbsp;inferences.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;One of the &amp;#8220;old&amp;#8221; divides in education, from before the current crop of &amp;#8220;edreform&amp;#8221;, is whether or not content matters. Broadly, there are two camps, let&amp;#8217;s call them the &amp;#8220;Facts&amp;#8221; and &amp;#8220;Skills&amp;#8221;, with the &amp;#8220;Skills&amp;#8221; camp clearly ahead in terms of mind&amp;nbsp;share.&lt;/p&gt;
&lt;p&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Skills&amp;#8221; is based on a fundamentally intuitive insight&amp;#8212; students need to know how to do things not about the things themselves. In many ways it is built on our common experience of forgetting facts over time. We need &lt;em&gt;21st century skills&lt;/em&gt;, not an accumulation of specific, privileged knowledge that fades over time. Whatever the latest technology, from encyclopedias to calculators through to Google, each generation decides that the tools that adults use end the necessity of knowing &lt;em&gt;about&lt;/em&gt; things rather than knowing how to &lt;em&gt;find&lt;/em&gt;&amp;nbsp;things.&lt;/p&gt;
&lt;p&gt;This is very attractive. It seems to match our adult experiences accumulating knowledge and using it in our work. It seems to address students&amp;#8217; boredom with learning &lt;em&gt;irrelevant&lt;/em&gt; information. It leaves space for groups to advocate for teaching whatever content they want since everyone can argue that content is fundamentally limited in&amp;nbsp;value.&lt;/p&gt;
&lt;p&gt;In classic &lt;strong&gt;&lt;a href="http://blog.jsonbecker.com/images/turnsout.mp3"&gt;turns out&lt;/a&gt;&lt;/strong&gt; sense, however, the evidence keeps mounting that one must teach from the &amp;#8220;Facts&amp;#8221; approach to achieve the goals of the &amp;#8220;Skills&amp;#8221;&amp;nbsp;position.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Turns out:&lt;/strong&gt; skills and knowledge do not transfer well across domains. There is little evidence that learning how to read literary fiction translates to reading technical manuals with comprehension. In other words, critical thinking is not really an independent ability free of domain context &lt;sup id="fnref:critthinking"&gt;&lt;a class="footnote-ref" href="#fn:critthinking" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;. In fact, experts are able to learn more quickly, but only in their domain and only when they have prior knowledge to use as scaffolding &lt;sup id="fnref:scaffold"&gt;&lt;a class="footnote-ref" href="#fn:scaffold" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Turns out:&lt;/strong&gt; reading comprehension is strongly connected to whether or not students have prior knowledge (&amp;#8220;Facts&amp;#8221;) about the topic of the passage &lt;sup id="fnref:priorknowledge"&gt;&lt;a class="footnote-ref" href="#fn:priorknowledge" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;. Reading techniques only provide modest assistance for&amp;nbsp;comprehension.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Turns out:&lt;/strong&gt; privileging skills over content may have a serious differential impact on disadvantaged children. A well-intentioned goal of achieving equity through equality has led many to advocate that we do a disservice to children of color and children in poverty because their schools have not as completely embraced a &amp;#8220;Skills&amp;#8221; world and are too focused on &amp;#8220;Facts&amp;#8221;. The problem is that deep disparities we see when these students enter schooling point to having less prior knowledge than their peers &lt;sup id="fnref:culturalliteracy"&gt;&lt;a class="footnote-ref" href="#fn:culturalliteracy" rel="footnote"&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;What is remarkable, and tragic, is that the &amp;#8220;Skills&amp;#8221; camp has maintained its dominance through the demonization of &amp;#8220;Facts&amp;#8221;, with dramatic misinterpretations&amp;nbsp;like:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The &amp;#8220;Facts&amp;#8221; folks are just White colonialists seeking to maintain existing power structures through teaching the information of&amp;nbsp;privilege.&lt;/li&gt;
&lt;li&gt;The &amp;#8220;Facts&amp;#8221; folks privilege memorization, rote learning, and recall-based assessment over other pedagogy that is more engaging and&amp;nbsp;authentic.&lt;/li&gt;
&lt;li&gt;The &amp;#8220;Facts&amp;#8221; folks can only ever teach what was important yesterday; &amp;#8220;Skills&amp;#8221; camp can teach what matters to become a lifelong learner for tomorrow&amp;#8217;s&amp;nbsp;world.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;None of these are&amp;nbsp;true.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This post is largely brought to you by: &lt;span class="caps"&gt;E.D.&lt;/span&gt; Hirsch, Dan T. Willingham, and Malcolm Gladwell via Merlin&amp;nbsp;Mann.&lt;/em&gt;&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:critthinking"&gt;
&lt;p&gt;&lt;a href=""&gt;http://www.aft.org/pdfs/americaneducator/summer2007/Crit_Thinking.pdf&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:critthinking" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:scaffold"&gt;
&lt;p&gt;&lt;a href=""&gt;http://www.ncbi.nlm.nih.gov/pubmed/11550744&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:scaffold" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:priorknowledge"&gt;
&lt;p&gt;&lt;a href=""&gt;http://www.aft.org/newspubs/periodicals/ae/spring2006/willingham.cfm&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:priorknowledge" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:comptech"&gt;
&lt;p&gt;http://www.aft.org/pdfs/americaneducator/winter0607/CogSci.pdf&amp;#160;&lt;a class="footnote-backref" href="#fnref:comptech" rev="footnote" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:culturalliteracy"&gt;
&lt;p&gt;This has pretty much been the thrust behind &lt;span class="caps"&gt;E.D.&lt;/span&gt; Hirsch&amp;#8217;s work, who has been accused of being on the far right in education, despite his consistent belief that education equity is one of the most important goals to achieve. His firm belief, and I am mostly convinced, is that explicit factual content is the key tool for how teaching can dramatically improve educational equity.&amp;#160;&lt;a class="footnote-backref" href="#fnref:culturalliteracy" rev="footnote" title="Jump back to footnote 5 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary></entry><entry><title>The four ways to really fix education</title><link href="http://blog.jsonbecker.com/2013/11/the-four-ways-to-really-fix-education.html" rel="alternate"></link><updated>2013-11-19T00:00:00-05:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-11-19:2013/11/the-four-ways-to-really-fix-education.html</id><summary type="html">&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;More schooling, reoriented&amp;nbsp;calendar&lt;/li&gt;
&lt;li&gt;Wider range of higher&amp;nbsp;education&lt;/li&gt;
&lt;li&gt;Cheaper four-year&amp;nbsp;degrees&lt;/li&gt;
&lt;li&gt;Eliminate property tax-based public&amp;nbsp;education&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is an interesting list. I don&amp;#8217;t agree with number four. There are several benefits to using property taxes not the least of which is their stability and lagged response during traditional economic downturns. However, there are many things we should do to reform our revenue system for education. I am keen on &lt;em&gt;more&lt;/em&gt; taxes on &amp;#8220;property&amp;#8221;, using land value taxes that are levvied either statewide or regionally to address some of the inequities traditional, highly localized property taxes can lead&amp;nbsp;to.&lt;/p&gt;</summary></entry><entry><title>It’s Poverty Stupid… or is it?</title><link href="http://blog.jsonbecker.com/2013/11/its-poverty-stupid-or-is-it.html" rel="alternate"></link><updated>2013-11-18T00:00:00-05:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-11-18:2013/11/its-poverty-stupid-or-is-it.html</id><summary type="html">&lt;p&gt;If I had to point to the key fissure in the education policy and research community it would be around poverty. Some seem to view it as an inexorable obstacle, deeply believing that the key improvement strategy is to decrease inequity of inputs. Some seem to view it as an obstacle that can be overcome by systems functioning at peak efficacy, deeply believing the great challenge is achieving that efficacy sustainably at scale. Both positions seem to grossly simplify causes and suggest policy structures and outcomes that are&amp;nbsp;unachievable.&lt;/p&gt;
&lt;p&gt;Paraphrasing &lt;a href="http://www.kungfugrippe.com"&gt;Merlin Mann&lt;/a&gt;, &lt;em&gt;always be skeptical of &amp;#8220;turns out&amp;#8221; research&lt;/em&gt;. In this case, are the results really that surprising? If they are, I might suggest that you have been focusing too much on the partial equilibrium impact of poverty and ignoring the bigger&amp;nbsp;picture.&lt;/p&gt;
&lt;p&gt;Not that I think integration is likely, easy, quick, or magically fixes&amp;nbsp;things.&lt;/p&gt;</summary></entry><entry><title>A New Calculation for Student Mobility</title><link href="http://blog.jsonbecker.com/2013/09/a-new-calculation-for-student-mobility.html" rel="alternate"></link><updated>2013-09-17T00:00:00-04:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-09-17:2013/09/a-new-calculation-for-student-mobility.html</id><summary type="html">&lt;p&gt;How do we calculate student mobility? I am currently soliciting responses from other data professionals across the country. But when I needed to produce mobility numbers for some of my work a couple of months ago, I decided to develop a set of business rules without any exposure to how the federal government, states, or other existing systems define mobility. &lt;sup id="fnref:ignorance"&gt;&lt;a class="footnote-ref" href="#fn:ignorance" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;I am fairly proud of my work on mobility. This post will review how I defined student mobility. I am hopeful that it matches or bests current techniques for calculating the number of schools a student has attended. In my next post, I will share the first two major versions of my implementation of these mobility business rules in &lt;code&gt;R&lt;/code&gt;. &lt;sup id="fnref:learningexperience"&gt;&lt;a class="footnote-ref" href="#fn:learningexperience" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt; Together, these posts will represent the work I referred to in my previous post on the &lt;a href="http://blog.jsonbecker.com/2013/09/documentation-of-business-rules-and-analysis.html"&gt;importance of documenting business rules and sharing code&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;The&amp;nbsp;Rules&lt;/h2&gt;
&lt;p&gt;Working with district data presents a woefully incomplete picture of the education mobile students receive. Particularly in a state like Rhode Island, where our districts are only a few miles wide, there is substantial interdistrict mobility. When a student moves across district lines, their enrollment is not recorded in local district data. However, even with state level data, highly mobile students cross state lines and present incomplete data. A key consideration for calculating how many schools a student has attended in a particular year is capturing &amp;#8220;missing&amp;#8221; data&amp;nbsp;sensibly.&lt;/p&gt;
&lt;p&gt;The typical structure of enrollment records looks something like&amp;nbsp;this:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Unique Student &lt;span class="caps"&gt;ID&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;School Code&lt;/th&gt;
&lt;th&gt;Enrollment Date&lt;/th&gt;
&lt;th&gt;Exit Date&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;10101&lt;/td&gt;
&lt;td&gt;2012-09-01&lt;/td&gt;
&lt;td&gt;2012-11-15&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;10103&lt;/td&gt;
&lt;td&gt;2012-11-16&lt;/td&gt;
&lt;td&gt;2013-06-15&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;A compound key for this data consists of the Unique Student &lt;span class="caps"&gt;ID&lt;/span&gt;, School Code, and Enrollment Date, meaning that each row must be a unique combination of these three factors. The data above shows a simple case of a student enrolling at the start of the school year, switching schools once with no gap in enrollment, and continuing at the new school until the end of the school year. For the purposes of mobility, I would define the above as having moved one&amp;nbsp;time.&lt;/p&gt;
&lt;p&gt;But it is easy to see how some very complex scenarios could quickly arise. What if student &lt;code&gt;1000000&lt;/code&gt;&amp;#8216;s record looked like&amp;nbsp;this?&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Unique Student &lt;span class="caps"&gt;ID&lt;/span&gt;&lt;/th&gt;
&lt;th&gt;School Code&lt;/th&gt;
&lt;th&gt;Enrollment Date&lt;/th&gt;
&lt;th&gt;Exit Date&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;10101&lt;/td&gt;
&lt;td&gt;2012-10-15&lt;/td&gt;
&lt;td&gt;2012-11-15&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;10103&lt;/td&gt;
&lt;td&gt;2013-01-03&lt;/td&gt;
&lt;td&gt;2013-03-13&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td&gt;1000000&lt;/td&gt;
&lt;td&gt;10103&lt;/td&gt;
&lt;td&gt;2013-03-20&lt;/td&gt;
&lt;td&gt;2013-05-13&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;There are several features that make it challenging to assign a number of &amp;#8220;moves&amp;#8221; to this student. First, the student does not enroll in school until October 15, 2012. This is nearly six weeks into the typical school year in the Northeastern United States. Should we assume that this student has enrolled in no school at all prior to October 15th or should we assume that the student was enrolled in a school that was outside of this district and therefore missing in the data? Next, we notice the enrollment gap between November 15, 2012 and January 3, 2013. Is it right to assume that the student has moved only once in this period of time with a gap of enrollment of over a month and a half? Then we notice that the student exited school &lt;code&gt;10103&lt;/code&gt; on March 13, 2013 but was re-enrolled in the same school a week later on March 20, 2013. Has the student truly &amp;#8220;moved&amp;#8221; in this period? Lastly, the student exits the district on May 13, 2013 for the final time. This is nearly a month before the end of school. Has this student moved to a different&amp;nbsp;school?&lt;/p&gt;
&lt;p&gt;There is an element missing that most enrollment data has which can enrich our understanding of this student&amp;#8217;s record. All district collect an exit type, which explains if a student is leaving to enroll in another school within the district, another school in a different district in the same state, another school in a different state, a private school, etc. It also defines whether a student is dropping out, graduating, or has entered the juvenile justice system, for example. However, it has been my experience that this data is reported inconsistently and unreliably. Frequently a student will be reported as changing schools within the district without a subsequent enrollment record, or reported as leaving the district but enroll within the same district a few days later. Therefore, I think that we should try and infer the number of schools that a student has attended using soley the enrollment date, exit date, and school code for each student record. This data is far more reliable for a host of reasons, and, ultimately, provides us with all the information we need to make intelligent&amp;nbsp;decisions.&lt;/p&gt;
&lt;p&gt;My proposed set of business rules examines &lt;code&gt;school code&lt;/code&gt;, &lt;code&gt;enrollment date&lt;/code&gt;, and &lt;code&gt;exit date&lt;/code&gt; against three parameters: &lt;code&gt;enrollment by&lt;/code&gt;, &lt;code&gt;exit by&lt;/code&gt;, and &lt;code&gt;gap&lt;/code&gt;. 
Each students minimum enrollment date is compared to &lt;code&gt;enrollment by&lt;/code&gt;. If that student entered the data set for the first time before the &lt;code&gt;enrollment by&lt;/code&gt;, the assumption is that this record represents the first time the student enrolls in any school for that year, and therefore the student has 0 &lt;code&gt;moves&lt;/code&gt;. If the student enrolls for the first time after &lt;code&gt;enrollment by&lt;/code&gt;, then the record is considered the second school a student has attended and their &lt;code&gt;moves&lt;/code&gt; attribute is incremented by &lt;code&gt;1&lt;/code&gt;. Similarly, if a student&amp;#8217;s maximium &lt;code&gt;exit date&lt;/code&gt; is after &lt;code&gt;exit by&lt;/code&gt;, then this considered to be the student&amp;#8217;s last school enrolled in for the year and they are credited with &lt;code&gt;0&lt;/code&gt; &lt;code&gt;moves&lt;/code&gt;, but if &lt;code&gt;exit date&lt;/code&gt; is prior to &lt;code&gt;exit by&lt;/code&gt;, then that student&amp;#8217;s &lt;code&gt;moves&lt;/code&gt; is incremented by &lt;code&gt;1&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;That takes care of the &amp;#8220;ends&amp;#8221;, but what happens as students switch schools in the &amp;#8220;middle&amp;#8221;? I proposed that each &lt;code&gt;exit date&lt;/code&gt; is compared to the subsequent &lt;code&gt;enrollment date&lt;/code&gt;. If &lt;code&gt;enrollment date&lt;/code&gt; occurs within &lt;code&gt;gap&lt;/code&gt; days of the previous &lt;code&gt;exit date&lt;/code&gt;, and the &lt;code&gt;school code&lt;/code&gt; of enrollment is not the same as the &lt;code&gt;school code&lt;/code&gt; of exit, then a student&amp;#8217;s &lt;code&gt;moves&lt;/code&gt; are incremented by &lt;code&gt;1&lt;/code&gt;. If the &lt;code&gt;school codes&lt;/code&gt; are identical and the difference between dates is less than &lt;code&gt;gap&lt;/code&gt;, then the student is said to have not moved at all. If the difference between the &lt;code&gt;enrollment date&lt;/code&gt; and the previous &lt;code&gt;exit date&lt;/code&gt; is greater than &lt;code&gt;gap&lt;/code&gt;, then the student&amp;#8217;s &lt;code&gt;moves&lt;/code&gt; is incremented by &lt;code&gt;2&lt;/code&gt;, the assumption being that the student likely attended a different school between the two observations in the&amp;nbsp;data.&lt;/p&gt;
&lt;p&gt;Whereas calculating student mobility may have seemed a simple matter of counting the number of records in the enrollment file, clearly there is a level of complexity this would fail to&amp;nbsp;capture.&lt;/p&gt;
&lt;p&gt;Check back in a few days to see my next post where I will share my initial implementation of these business rules and how I achieved an 10x speed up with a massive code&amp;nbsp;refactor.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:ignorance"&gt;
&lt;p&gt;My ignorance was intentional. It is good to stretch those brain muscles that think through sticky problems like developing business rules for a key statistic. I can&amp;#8217;t be sure that I have developed the most considered and complete set of rules for mobility, which is why I&amp;#8217;m now soliciting other&amp;#8217;s views, but I am hopeful my solution is at least as good.&amp;#160;&lt;a class="footnote-backref" href="#fnref:ignorance" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:learningexperience"&gt;
&lt;p&gt;I think showing my first two implementation of these business rules is an excellent opportunity to review several key design considerations when programming in &lt;code&gt;R&lt;/code&gt;. From version 1 to version 2 I achieved a 10x speedup due to a complete refactor that avoided &lt;code&gt;for&lt;/code&gt; loops, used &lt;code&gt;data.table&lt;/code&gt;, and included some clever use of recursion.&amp;#160;&lt;a class="footnote-backref" href="#fnref:learningexperience" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary></entry><entry><title>Documentation of Business Rules and Analysis</title><link href="http://blog.jsonbecker.com/2013/09/documentation-of-business-rules-and-analysis.html" rel="alternate"></link><updated>2013-09-13T00:00:00-04:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-09-13:2013/09/documentation-of-business-rules-and-analysis.html</id><summary type="html">&lt;p&gt;One of the most challenging aspects of being a data analyst is translating programmatic terms like &amp;#8220;student mobility&amp;#8221; into precise business rules. Almost any simple statistic involves a series of decisions that are often opaque to the ultimate users of that&amp;nbsp;statistic.&lt;/p&gt;
&lt;p&gt;Documentation of business rules is a critical aspect of a data analysts job that, in my experience, is often regrettably overlooked. If you have ever tried to reproduce someone else&amp;#8217;s analysis, asked different people for the same statistic, or tried to compare data from multiple years, you have probably encountered difficulties getting a consistent answer on standard statistics, e.g. how many students were proficient in math, how many students graduated in four years, what proportion of students were chronically absent? All too often documentation of business rules is poor or non-existent. The result is that two analysts with the same data will produce inconsistent statistics. This is not because of something inherent in the quality of the data or an indictment of the analyst’s skills. In most cases, the undocumented business rules are essentially trivial, in that the results of any decision has a small impact on the final result and any of the decisions made by the analysts are equally&amp;nbsp;defensible.&lt;/p&gt;
&lt;p&gt;This major problem of lax or non-existent documentation is one of the main reasons I feel that analysts, and in particular analysts working in the public sector, should extensively use tools for code sharing and version control like &lt;a href="http://www.github.com/"&gt;Github&lt;/a&gt;, use free tools whenever possible, and generally adhere to best practices in reproducible&amp;nbsp;research.&lt;/p&gt;
&lt;p&gt;I am trying to put as much of my code on Github as I can these days. Much of what I write is still very disorganized and, frankly, embarrassing. A lot of what is in my Github repositories is old, abandoned code written as I was learning my craft. A lot of it is written to work with very specific, private data. Most of it is poorly documented because I am the only one who has ever had to use it, I don&amp;#8217;t interact with anyone through practices like code reviews, and frankly I am lazy when pressed with a deadline. But that&amp;#8217;s not really the point, is it? The worst documented code is code that is hidden away on a personal hard drive, written for an expensive proprietary environment most people and organizations cannot use, or worse, is not code at all but rather a series of destructive data edits and manipulations. &lt;sup id="fnref:fuckexcel"&gt;&lt;a class="footnote-ref" href="#fn:fuckexcel" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;One way that I have been trying to improve the quality and utility of the code I write is by contributing to an open source R package, &lt;code&gt;eeptools&lt;/code&gt;. This is a package written and maintained by Jared Knowles, an employee of the Wisconsin Department of Public Instruction, whom I met at a &lt;a href="http://www.gse.harvard.edu/sdp/"&gt;Strategic Data Project&lt;/a&gt; convening. &lt;code&gt;eeptools&lt;/code&gt; is consolidating several functions in R for common tasks education data analysts are faced with. Because this package is available on &lt;a href="http://cran.us.r-project.org/"&gt;&lt;span class="caps"&gt;CRAN&lt;/span&gt;&lt;/a&gt;, the primary repository for R packages, any education analyst can have access to its functions in one&amp;nbsp;line: &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;install.packages&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;eeptools&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;);&lt;/span&gt; require&lt;span class="p"&gt;(&lt;/span&gt;eeptools&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Submitting code to a &lt;span class="caps"&gt;CRAN&lt;/span&gt; package reinforces several habits. First, I get to practice writing R documentation,  explaining how to use a function, and therefore, articulating the assumptions and business rules I am applying. Second, I have to write my code with a wider tolerance for input data. One of the easy pitfalls of a beginning analyst is writing code that is too specific to the dataset in front of you. Most of the errors I have found in analyses during quality control stem from assumptions embedded in code that were perfectly reasonable with a single data set that lead to serious errors when using different data. One way to avoid this issue is through &lt;a href="http://en.wikipedia.org/wiki/Test-driven_development"&gt;test-driven development&lt;/a&gt;, writing a good testing suite that tests a wide range of unexpected inputs. I am not quite there yet, personally, but thinking about how my code would have to work with arbitrary inputs and ensuring it fails gracefully &lt;sup id="fnref:fallingwithstyle"&gt;&lt;a class="footnote-ref" href="#fn:fallingwithstyle" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt; is an excellent side benefit of preparing a pull request &lt;sup id="fnref:gitterms"&gt;&lt;a class="footnote-ref" href="#fn:gitterms" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt; . Third, it is an opportunity to write code for someone other than myself. Because I am often the sole analyst with my skillset working on a project, it is easy to not consider things like style, optimizations, clarity, etc. This can lead to large build-ups of &lt;a href="http://en.wikipedia.org/wiki/Technical_debt"&gt;technical debt&lt;/a&gt;, complacency toward learning new techniques, and general sloppiness. Submitting a pull request feels like publishing. The world has to read this, so it better be something I am proud of that can stand up to the scrutiny of third-party&amp;nbsp;users.&lt;/p&gt;
&lt;p&gt;My first pull request, which was accepted into the package, calculates age in years, months, or days at an arbitrary date based on date of birth. While even a beginning R programmer can develop a similar function, it is the perfect example of an easily compartmentalized component, with a broad set of applications, that can be accessed frequently&amp;nbsp;.&lt;/p&gt;
&lt;p&gt;Today I submitted by second pull request that I hope will be accepted. This time I covered a much more complex task&amp;#8212; calculating student mobility. To be honest, I am completely unaware of existing business rules and algorithms used to produce the mobility numbers that are federally reported. I wrote this function from scratch thinking through how I would calculate the number of schools attended by a student in a given year. I am really proud of both the business rules I have developed and the code I wrote to apply those rules. My custom function can accept fairly arbitrary inputs, fails gracefully when it finds data it does not expect, and is pretty fast. The original version of my code took close to 10 minutes to run on ~30,000 rows of data. I have reduced that with a complete rewrite prior to submission to 16&amp;nbsp;seconds.&lt;/p&gt;
&lt;p&gt;While I am not sure if this request will be accepted, I will be thrilled if it is. Mobility is a tremendously important statistic in education research and a standard, reproducible way to calculate it would be a great help to researchers. How great would it be if &lt;code&gt;eeptools&lt;/code&gt; becomes one of the first packages education data analysts load and my mobility calculations are used broadly by researchers and analysts? But even if it’s not accepted because it falls out of scope, the process of developing the business rules, writing an initial implementation of those rules, and then refining that code to be far simpler, faster, and less error prone was incredibly&amp;nbsp;rewarding.&lt;/p&gt;
&lt;p&gt;My next post will probably be a review of that process and some parts of my &lt;code&gt;moves_calc&lt;/code&gt; function that I&amp;#8217;m particularly proud&amp;nbsp;of.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:fuckexcel"&gt;
&lt;p&gt;Using a spreadsheet program, such as Excel, encourages directly manipulating and editing the source data. Each change permanently changes the data. Even if you keep an original version of the data, there is no recording of exactly what was done to change the data to produce your results. Reproducibility is all but impossible of any significant analysis done using spreadsheet software.&amp;#160;&lt;a class="footnote-backref" href="#fnref:fuckexcel" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:fallingwithstyle"&gt;
&lt;p&gt;Instead of halting the function with hard to understand error when things go wrong, I do my best to &amp;#8220;correct&amp;#8221; easily anticipated errors or report back to users in a plain way what needs to be fixed. See also &lt;a href="http://en.wikipedia.org/wiki/Fault-tolerant_system"&gt;fault-tolerant system&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref:fallingwithstyle" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:gitterms"&gt;
&lt;p&gt;A &lt;a href="https://help.github.com/articles/using-pull-requests"&gt;pull request&lt;/a&gt; is when you submit your additions, deletions, or any other modifications to be incorporated in someone else&amp;#8217;s repository.&amp;#160;&lt;a class="footnote-backref" href="#fnref:gitterms" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary></entry><entry><title>Some Changes for Rhode Island State Aid to Education</title><link href="http://blog.jsonbecker.com/2013/08/some-changes-for-rhode-island-state-aid-to-education.html" rel="alternate"></link><updated>2013-08-22T00:00:00-04:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-08-22:2013/08/some-changes-for-rhode-island-state-aid-to-education.html</id><summary type="html">&lt;p&gt;In December 2009, the education department head, Professor Kenneth K. Wong, another graduate student and myself were part of a three-person team consulting the Rhode Island Department of Education (&lt;span class="caps"&gt;RIDE&lt;/span&gt;) on how to establish a new state funding formula. We worked with finance and legal staff at the department to develop the legislation for the 2010 session that would establish a state funding formula for the first time in 15 years.
 
The Board of Regents had already passed a resolution with its policy priorities that they wanted enshrined in the formula. Additionally, there had been many attempts over the past 5-10 years to pass a new formula that failed for various reasons, chief among them that all previously proposed formulas were accompanied with a call to increase state funding for education 30-50%, with some even envisioning nearly doubling the state education funding. Our task was to research funding formulas, both in practice in other states and in the literature research on school finance, and achieve the goals of the Board of Regents without proposing a mammoth increase in state aid that would sink the entire endeavor &lt;sup id="fnref:increase"&gt;&lt;a class="footnote-ref" href="#fn:increase" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;. The general sense was that while more state aid had the potential to improve the progressiveness of education expenditures, the reality is the overall spending level in Rhode Island is high, and introducing new money was less important than redistributing state aid. I share this belief, particularly because I think adding money to the right places is simple once there is already a way to equitably distribute those funds. Tying up the increase in funding alongside a distribution method is a recipe for political horse-trading that can result in all kinds of distortions that prevent aid from flowing where&amp;nbsp;needed. &lt;/p&gt;
&lt;p&gt;My role in this process was primarily to create Excel simulators that would allow us to immediately track the impacts of changing different parts of the formula. I also helped &lt;span class="caps"&gt;RIDE&lt;/span&gt; staff interpret the meaning of changes to the math behind the funding formula and understand what levers existed to change the formula and how these changes impacted both the resulting distribution and&amp;nbsp;policy. &lt;/p&gt;
&lt;p&gt;We had three&amp;nbsp;months. &lt;/p&gt;
&lt;p&gt;There are a lot of people who are unhappy about the results of the formula that ultimately passed in June 2010. Because we are redistributing essentially the same amount of state aid, there are some districts that are losing money while others are gaining funds &lt;sup id="fnref:holdharmless"&gt;&lt;a class="footnote-ref" href="#fn:holdharmless" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;. Some dislike the fact that we used only a &amp;#8220;weight&amp;#8221; for free and reduced price lunch status. Alternative formulas (and formulas in other states) typically include numerous weights, from limited English proficiency and special education status, to gifted and talented and career and technical education &lt;sup id="fnref:ajello"&gt;&lt;a class="footnote-ref" href="#fn:ajello" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;. And yet others were displeased that many costs, including transportation and facilities maintenance, were excluded from the state-base of education aid. Then there are those who think the transition is all off&amp;#8212; five years is too long to wait to get the increases the formula proposes, and ten years is far too fast to lose the money the formula proposes. &lt;sup id="fnref:transitions"&gt;&lt;a class="footnote-ref" href="#fn:transitions" rel="footnote"&gt;4&lt;/a&gt;&lt;/sup&gt; &lt;/p&gt;
&lt;h3&gt;A Good State Aid&amp;nbsp;System&lt;/h3&gt;
&lt;p&gt;In the end, I am proud of the formula produced for several reasons. 
First, it passed successfully and has been fully funded (and sometimes more than fully funded) each year of implementation throughout a period of massive structural budget deficits. This is no small accomplishment. The advocacy community rightfully pushes us to build ideal systems, but in our role of policy entrepreneurs we are faced with the reality that a policy that does not become law and is not supported as law may as well not exist. Producing a formula that has some of the other positive qualities discussed below, passing that formula, and implementing the formula with little fanfare is not a small&amp;nbsp;accomplishment. &lt;/p&gt;
&lt;p&gt;Second, the formula is highly progressive, sending as much as 20 times more aid to some of our poorest communities in Rhode Island compared to the wealthiest. I am not positive how this compares to other states&amp;#8212; that&amp;#8217;s a topic I certainly want to work on for a future post&amp;#8212; but with just 39 cities and towns, it seems to show a high preference for &lt;em&gt;vertical equity&lt;/em&gt;, treating different cities and towns differently. There are communities on both ends of the distribution who want substantially more state funding, and our state aid formula is not sufficient to effectively crowd out local capacity for education spending and ensure that our poorest communities are spending more than our wealthier ones &lt;sup id="fnref:comparative"&gt;&lt;a class="footnote-ref" href="#fn:comparative" rel="footnote"&gt;5&lt;/a&gt;&lt;/sup&gt;, but it&amp;#8217;s a very strong&amp;nbsp;start. &lt;/p&gt;
&lt;p&gt;Third, the formula is relatively simple. While I do not necessarily agree that it is a virtue to have fewer weights and a simple formula in perpetuity, the experience with other states and other formula-based programs show that weights and complexities are very easy to add and very hard to take away. Once a particular policy preference is enshrined in the distribution method, it had better be right because a community of advocacy will maintain that weight long into the future. Personally, I felt it critical to start with the very simple &amp;#8220;core&amp;#8221; formula that could be adjusted over time. I have some ideas on how I might modify/add to this core that I will be sharing in this post, but I firmly believe that starting with a simple core was the right move. It is also worth noting that because of the need to ensure the transition is smoothed out so that gains in some districts equal the total losses in the others meant that even a more progressive weighting scheme would not impact school funding until the far back end of the transition period (which we proposed as 7 years but was pushed to 5 years during the legislative process), since communities were already gaining funds as fast as we could move them. For this reason, not only was a simple core preferable from my technocratic perspective, but it also was not likely to have any immediate&amp;nbsp;downside. &lt;/p&gt;
&lt;p&gt;Fourth, we removed the long-term regionalization bonuses. Rhode Island had sought to reduce the ridiculous number of school districts by providing a bonus for regionalizing in the early 90s. Unfortunately, because of the timing of the abandonment of the previous state aid formula, the districts that did choose to regionalize had their base funding locked in at a level 6-8% higher than it should have been, because they were receiving a bonus that was meant to fade away over the course of several years. I could justify a small increase in state funding to pay some of the transition expenses of regionalizing districts, but long term funding increases? Part of the goal of regionalization is the reduction of overhead that allows for decreased costs (or increased services at the same costs). There is no ongoing need to supply a massive state bonus for&amp;nbsp;regionalizing. &lt;/p&gt;
&lt;p&gt;Now just because I am proud of this work does not mean that I think we have &amp;#8220;solved&amp;#8221; education funding in Rhode Island. Personally, I believe there are other defensible ways to distribute funding in Rhode Island, each of which represents slightly different policy preferences. There is no hard and fast &amp;#8220;right&amp;#8221; or &amp;#8220;wrong&amp;#8221; way to do this, within certain guidelines. As I see it, so long as the formula is progressive and moving toward a greater chance of seeing a day where Providence has the highest paid staff in the state &lt;sup id="fnref:comparative"&gt;&lt;a class="footnote-ref" href="#fn:comparative" rel="footnote"&gt;5&lt;/a&gt;&lt;/sup&gt;, we are on the right path. I don&amp;#8217;t believe that Rhode Island will have a truly &amp;#8220;great&amp;#8221; education finance climate without a substantial growth in the economy or a huge new tax that dramatically lowers the ability of municipalities to generate school funding while bolstering state aid. However, I think we have a great foundation and a &amp;#8220;good&amp;#8221;&amp;nbsp;system. &lt;/p&gt;
&lt;p&gt;For the remainder of this post, I would like to propose a few ideas that could help move Rhode Island from &amp;#8220;good&amp;#8221; to &amp;#8220;very good&amp;#8221; that I think are feasible within the next five years &lt;sup id="fnref:goodtogreat"&gt;&lt;a class="footnote-ref" href="#fn:goodtogreat" rel="footnote"&gt;6&lt;/a&gt;&lt;/sup&gt;. &lt;/p&gt;
&lt;h3&gt;A Very Good State Aid&amp;nbsp;Program&lt;/h3&gt;
&lt;p&gt;After a little over three years since its establishment, I think we are ready to tackle several additional aspects of state education funding in Rhode Island. One thing you may notice is that few of these ideas impact the original formula. Part of why that is comes from my aforementioned preference for a simple formula, and part is because these include some non-formula issues that were not pursued in 2010 in an effort to keep the focus on the main policy matters. 
First, and perhaps the most consequential change that can be made to state funding, is the teacher pension fund payments. Currently, the state and local districts split the cost of teacher pension contributions 60/40. This is a flat split, regardless of the wealth of the community. I think it&amp;#8217;s absurd to ignore community wealth for such a large portion of state education expenditures. Using the Adjusted Equalized Weighted Assessment Values (&lt;span class="caps"&gt;AEWAV&lt;/span&gt;) to determine the reimbursement rates would be a big improvement on the progressiveness of school&amp;nbsp;funding. &lt;/p&gt;
&lt;p&gt;Second, I would make a slight change to the way that we fund charter schools. When we were developing the formula, there was broad agreement among policymakers that the &amp;#8220;money should follow the child&amp;#8221;. In one sense, this is the system we proposed since school district funding is based on enrollments. However, I think an irrational desire to not &amp;#8220;double count&amp;#8221; students, alongside the need to keep funding as flat as possible, pushed the formula a bit too far when it comes to charters. The old way of funding charter schools allowed districts to hold back 5% of the total per pupil expenditure from their charter school tuitions. This meant charter schools received 5% less funding than traditional public schools, but it also recognized that there are some fixed costs in districts that are not immediately recoverable when students leave on the margins. I think the state should return to this practice, however only if the state is willing to pay the withheld 5% to charters. I do think its fair to take into account some fixed costs, but I don&amp;#8217;t believe it&amp;#8217;s fair that charter schools received less funding as a&amp;nbsp;result. &lt;/p&gt;
&lt;p&gt;Third, we excluded all building maintenance costs from the base amount of state aid. This was largely because the formula was supposed to represent only the marginal instructional costs associated with each student. I don&amp;#8217;t necessarily think that these costs have to be added into the base amount. However, I would like to see the state contribute to the maintenance of buildings more directly. I think the state should provide a flat dollar amount, say &amp;#36;100,000, per building in each district, provided that key criteria are met. The buildings should be at 90% occupancy/utilization, should have a minimum size set based on the research on efficiency (roughly 300 students at the elementary level and 600 students for high schools), and there should be some minimum standard for building systems quality and upkeep. These requirements are mostly about making sure this flat fund, which is really about the fixed costs of maintaining buildings, doesn&amp;#8217;t create incentives to build more. It may seem inconsequential, but I think it&amp;#8217;s important to state the preference for well-sized, occupied &lt;sup id="fnref:occupied"&gt;&lt;a class="footnote-ref" href="#fn:occupied" rel="footnote"&gt;7&lt;/a&gt;&lt;/sup&gt;, and maintained buildings is&amp;nbsp;worthwhile. &lt;/p&gt;
&lt;p&gt;I think it&amp;#8217;s wrong that the minimum reimbursement rate for school construction aid was raised to 40% during the funding formula debates in the General Assembly. This amounts to a massive subsidy for suburban schools and the previous 30% minimum is part of why we have such stark facilities inequities in the state. We should remove the minimums on construction reimbursement and simply use &lt;span class="caps"&gt;AEWAV&lt;/span&gt; to determine the reimbursement rate. Also, we need to establish a revolving facilities loan fund, much like the one used for sewers (and now &lt;a href="http://blogs.wpri.com/2013/03/21/ricwfa-explainer/"&gt;roads and bridges&lt;/a&gt;). Access to lower interest bonds should not be dependent on city&amp;nbsp;finances. &lt;/p&gt;
&lt;p&gt;Fourth, one thing we did not include in the original funding formula that has come under considerably criticism is a special weight for students who are labeled English language learners. There are a few reasons we made this decision. The districts that have ELLs are the same districts that have high levels of poverty. In fact, the five communities that had more than 5% of their students classified as ELLs were, in order, also the top five districts with regards to free and reduced price lunch eligibility. Combined with a transition plan that was already increasing funding to these districts as rapidly as could be afforded, there were virtually no short-term consequences of not including an &lt;span class="caps"&gt;ELL&lt;/span&gt; weight. It&amp;#8217;s worth noting that formula dollars are not categorical funds&amp;#8212; there are no restrictions on how districts should spend this money, and there are no guarantees that an &lt;span class="caps"&gt;ELL&lt;/span&gt; weight would have any impact on &lt;span class="caps"&gt;ELL&lt;/span&gt;&amp;nbsp;spending. &lt;/p&gt;
&lt;p&gt;We were also concerned with incentivizing over-identification and failing to exit students who should no longer be classified as ELLs. I am also personally concerned with mistaking the additional supports we want to target as needed for English language acquisition; it would not only inspire the wrong policies and supports for these students, but it fails to recognize a host of needs that persist for these students well beyond English&amp;nbsp;acquisition. &lt;/p&gt;
&lt;p&gt;During the funding formula hearings at House and Senate Finance Committees we discussed the need for further study on this issue. I think that the next weight in the formula should be based on the Census and American Communities Survey. By using these data sets, classification of students who are eligible for the weight would not be dependent on the school district itself. Rather than focus on child language acquisition, I think we should broaden this weight to be applied based on the percentage of households that speak a language other than English in the home, where English is spoken at a level below &amp;#8220;very well&amp;#8221; &lt;sup id="fnref:technical"&gt;&lt;a class="footnote-ref" href="#fn:technical" rel="footnote"&gt;8&lt;/a&gt;&lt;/sup&gt;. This would ensure that students who live in language minority households receive additional supports throughout their education, regardless of their language acquisition status. I would make this weight lower than some in the literature because it would apply to a broader set of students, probably somewhere around 40% like the poverty weight. For reference, the latest five-year estimate from the &lt;span class="caps"&gt;ACS&lt;/span&gt; data shows that 24.3% of households fit this definition in the city of Providence. With a 40% weight, at 22,500 students, with a foundation amount of around \$9,000 per student, this weight would increase funding to Providence by a little over \$16,000,000. Similar to other formula aid, these funds would be&amp;nbsp;unrestricted. &lt;/p&gt;
&lt;p&gt;Now, while I think that \$16,000,000 is no small potatoes, and I am happy to express our policy preference to drive funding into communities where families are not using English in the home, some perspective is warranted. Providence will receive almost \$240,000,000 in state aid when the formula is fully transitioned, compared to about \$190,000,000 before. Adding this weight would only represent a 6% increase in state aid from the full formula amount. It&amp;#8217;s an important increase, but I hope you&amp;#8217;ll forgive me if I felt it was not grossly unfair to exclude it in the first iteration of the funding formula, especially considering we still have not fully transitioned to those higher dollar amounts sent to districts that would benefit from these&amp;nbsp;funds. &lt;/p&gt;
&lt;h3&gt;It Takes&amp;nbsp;Money&lt;/h3&gt;
&lt;p&gt;Each of these recommendations, in my view, would improve the way that Rhode Island distributes education aid. Some of the changes are technical, others address areas that are currently not considered, and some are purely about increasing the progressiveness of aid. All of these changes will require an even greater state contribution to education aid, but these increases would be an order of magnitude lower than what it would take to increase the state aid to covering 50-60% of all education expenditures. While I would support some pretty radical changes to drive more money into the state aid system, I think that each of these improvements are worth doing on the path to increased&amp;nbsp;aid. &lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:increase"&gt;
&lt;p&gt;I should note, that few people I spoke to were not in favor of raising the amount of state aid. We all want more money to come from the state because those dollars are far more progressive. However, Rhode Island was deep in its recession at this point in time and the dollar amounts to make a real dent in the state to local share in education are just staggering. Rhode Island currently funds just short of 40% of total school expenditures at the state level. To increase that to 60%, which is closer to the national average, they would have to contribute &amp;#36;500M more&amp;#8212; a roughly 60% increase from the current level. Just for some context, the main tax fight of Rhode Island progressives has been to repeal tax cuts for higher income individuals that were instituted starting in 2006 in an attempt to move toward a flat income tax rate in Rhode Island. The impact of this repeal would be an increase in revenues that would cover roughly 10% of the increase in school funding required to move from 40% to 60% state aid. Of course, those dollars are supposed to pay for some portion of restoring pension benefits, so it&amp;#8217;s already spoken for.&amp;#160;&lt;a class="footnote-backref" href="#fnref:increase" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:holdharmless"&gt;
&lt;p&gt;Hold harmless provisions, when introduced in other states, serve to dramatically distort the redistributive properties of state aid and almost always require a huge influx of funds. In fact, a hold harmless provision in Rhode Island would have required a doubling of state aid, which ultimately would have guaranteed that wealthy communities continue to receive too much state aid while less wealthy communities are stuck fighting year after year for tremendous revenue increases through taxation just to get their fair share. Essentially, hold harmless would ensure that you never reach formula-level spending and guarantee that state aid would not be very progressive.&amp;#160;&lt;a class="footnote-backref" href="#fnref:holdharmless" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:ajello"&gt;
&lt;p&gt;One very popular progressive member of the Rhode Island General Assembly had been working for years to pass a new funding formula and had five or six such weights in her version. Interestingly, with the glaring exception of sending &amp;#36;0 to Newport in state aid, the difference in the overall distribution of funds by district in Rhode Island using this formula and our formula was tiny, almost always &amp;lt;5%.&amp;#160;&lt;a class="footnote-backref" href="#fnref:ajello" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:transitions"&gt;
&lt;p&gt;Smoothing the &amp;#8220;gains&amp;#8221; and &amp;#8220;losses&amp;#8221; overtime was important to keep the formula as close to revenue neutral as possible. Of course, there are increases due to inflation and other factors each year as a part of the base, but our goal was to truly redistribute the funds such that not only is the end number not a big increase in total state aid but that getting through the transition period did not have huge costs. If it did, there is no way we could feel confident we would ever reach the point where the formula actually dictated state aid, much like the hold harmless provision prevents a full transition. Modeling various transition plans was a nightmare for me.&amp;#160;&lt;a class="footnote-backref" href="#fnref:transitions" rev="footnote" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:comparative"&gt;
&lt;p&gt;Many people forget that education spending is about competition within a single market. Overall spending matters less within this market than how you spend compared to others. The trick is that an urban school primarily working with traditionally under served families needs to be able to pay not just for more material supplies, but mostly for higher quality teachers and staff (and perhaps quantity). Because of compensating wage differentials, even hiring teachers and staff that are the same quality as wealthy communities costs more.&amp;#160;&lt;a class="footnote-backref" href="#fnref:comparative" rev="footnote" title="Jump back to footnote 5 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:goodtogreat"&gt;
&lt;p&gt;Perhaps I will write a future post on some ideas of how to push Rhode Island to &amp;#8220;great&amp;#8221;, even though I view all of those solutions as politically impossible.&amp;#160;&lt;a class="footnote-backref" href="#fnref:goodtogreat" rev="footnote" title="Jump back to footnote 6 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:occupied"&gt;
&lt;p&gt;I would include any leased space as occupied. We should encourage full utilization of the buildings, whether that includes charter schools, central office use, city government, or private companies. &amp;#160;&lt;a class="footnote-backref" href="#fnref:occupied" rev="footnote" title="Jump back to footnote 7 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:technical"&gt;
&lt;p&gt;This definition is clunky, but its how the &lt;span class="caps"&gt;ACS&lt;/span&gt; and Census track these things. This definition is clunky, but its how the &lt;span class="caps"&gt;ACS&lt;/span&gt; and Census track these things. We could verify the data using the data reported by districts about language spoken in the home. I would recommend using this data point to assist with whether or not to include these weights for charter schools. For example, approximately half of those families that do not speak English in the home also speak English very poorly. Therefore, I might apply half of the weight to each individual child whose family reports speaking a language other than English at home. Of course, the actual proportion of the weight should be specific to the ratio of speakers of language other than English to non-very well speakers of English by community.&amp;#160;&lt;a class="footnote-backref" href="#fnref:technical" rev="footnote" title="Jump back to footnote 8 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary></entry><entry><title>What can be done for Rhode Island Pensioners?</title><link href="http://blog.jsonbecker.com/2013/08/what-can-be-done-for-rhode-island-pensioners.html" rel="alternate"></link><updated>2013-08-15T00:00:00-04:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-08-15:2013/08/what-can-be-done-for-rhode-island-pensioners.html</id><summary type="html">&lt;p&gt;&lt;em&gt;This post originally appeared on my old blog on January 2, 2013 but did not make the transition to this site due to error. I decided to repost it with a new date after recovering it from a cached version on the&amp;nbsp;web.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Rhode Island &lt;a href="http://blogs.wpri.com/2011/11/17/analysis-why-rhode-island-passed-pension-reform-in-2011/"&gt;passed sweeping pension reform last fall&lt;/a&gt;, &lt;a href="http://blogs.wpri.com/2011/11/21/union-email-blasts-dems-on-pension-law-previews-legal-fight/"&gt;angering&lt;/a&gt; the &lt;a href="http://blogs.wpri.com/2012/02/07/unions-to-ri-negotiate-a-pension-deal-before-you-lose-in-court/"&gt;major labor unions&lt;/a&gt; and &lt;a href="http://www.rifuture.org/tag/pension"&gt;progressives&lt;/a&gt; throughout the state. These reforms have &lt;a href="http://blogs.wpri.com/2011/10/24/moodys-raimondo-chafee-pension-bill-good-for-rhode-island/"&gt;significantly decreased both the short and long-run costs to the state&lt;/a&gt;, while &lt;a href="http://blogs.wpri.com/2011/11/17/ri-lawmakers-ok-historic-pension-overhaul-by-wide-margins/"&gt;decreasing the benefits of both current and future retirees&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;One of the &lt;a href="http://blogs.wpri.com/2011/09/16/raimondo-chafee-set-to-freeze-colas-put-all-in-hybrid-plan/"&gt;most controversial measures&lt;/a&gt; in the pension reform package was suspending annual raises &lt;sup id="fnref:raises"&gt;&lt;a class="footnote-ref" href="#fn:raises" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt; for current retirees. I have noticed two main critiques of this element. The first criticism was that ending this practice constitutes a decrease in benefits to existing retirees who did not consent to these changes, constituting a breach of contract and assault on property rights. This critique is outside of the scope of this post. What I would like to address is the second criticism, that annual raises are critical to retirement security due to inflation, especially for the most vulnerable pensioners who earn near-poverty level wages from their&amp;nbsp;pensions.&lt;/p&gt;
&lt;p&gt;While I am broadly supportive of the changes made to the pension system in Rhode Island, I also believe that it is important to recognize the differential impact suspending annual raises has on a retired statehouse janitor who currently earns \$22,000 a year from their pension and a former state department director earning \$70,000 a year from their pension. Protecting the income of those most vulnerable to inflation is a worthy goal &lt;sup id="fnref:worthy"&gt;&lt;a class="footnote-ref" href="#fn:worthy" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;I have a simple recommendation that I think can have a substantial, meaningful impact on the most vulnerable retirees at substantially less cost than annual raises. This recommendation will be attractive to liberals and conservatives, as well as the “business elite” that have long called for increasing Rhode Island’s competitiveness with neighboring states. It is time that Rhode Island leaves the company of just three other states– Minnesota, Nebraska, and Vermont– that have no tax exemptions for retirement income &lt;sup id="fnref:exemptions"&gt;&lt;a class="footnote-ref" href="#fn:exemptions" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;. Rhode Island should exempt all income from pensions and social security up to 200% of the federal poverty level from state income taxes. This would go a long way to ensuring retirement security for those who are the most in need. It would also bring greater parity between our tax code and popular retirement destination states, potentially decreasing the impulse to move to New Hampshire, North Carolina, and&amp;nbsp;Florida.&lt;/p&gt;
&lt;p&gt;It’s a progressive win. It’s a decrease in taxes that conservatives should like. It shouldn’t have a serious impact on revenues, especially if it goes a long way toward quelling the union and progressive rancor about the recent reforms. And it’s far from unprecedented– in fact, some form of retirement income tax exemption exists in virtually every other&amp;nbsp;state.&lt;/p&gt;
&lt;p&gt;We should not be proud of taking away our most vulnerable pensioners’ annual raises, even if it was necessary. Instead of ignoring the clear impact of this provision, my hope for 2013 is that we address it, while keeping an overall pretty good change to Rhode Island’s state retirement&amp;nbsp;system.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:worthy"&gt;
&lt;p&gt;Interesting, increases in food prices has largely slowed and the main driver of inflation are healthcare costs. I wonder to what extent Medicare/Medicaid and Obamacare shield retirees from rising healthcare costs&amp;#160;&lt;a class="footnote-backref" href="#fnref:worthy" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:exemptions"&gt;
&lt;p&gt;http://www.ncsl.org/documents/fiscal/TaxonPensions2011.pdf&amp;#160;&lt;a class="footnote-backref" href="#fnref:exemptions" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:raises"&gt;
&lt;p&gt;&lt;a href="http://blog.jasonpbecker.com/blog/2012/01/25/providence-pensions-lets-call-a-spade-a-spade-or-the-cola-a-raise/"&gt;Not a cost-of-living adjustment&lt;/a&gt;, or &lt;span class="caps"&gt;COLA&lt;/span&gt;, as some call them.&amp;#160;&lt;a class="footnote-backref" href="#fnref:raises" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary></entry><entry><title>Smarter Balance Released Items Scare Me</title><link href="http://blog.jsonbecker.com/2013/07/smarter-balance-released-items-scare-me.html" rel="alternate"></link><updated>2013-07-23T00:00:00-04:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-07-23:2013/07/smarter-balance-released-items-scare-me.html</id><summary type="html">&lt;p&gt;&lt;a href="http://ccssimath.blogspot.com/2013/06/our-sbac-practice-tests-run-through.html"&gt;&lt;span class="caps"&gt;CCSSI&lt;/span&gt; Mathematics&lt;/a&gt; posted a scathing look at the items released by the &lt;a href="http://www.smarterbalanced.org/"&gt;Smarter Balanced Assessment Consortium&lt;/a&gt; (&lt;span class="caps"&gt;SBAC&lt;/span&gt;). While the rest of the internet seems to be obsessed over &lt;a href="http://blogs.edweek.org/edweek/curriculum/2013/07/georgia_drops_out_of_parcc_tes.html"&gt;Georgia leaving the Partnership for Assessment of College and Careers&lt;/a&gt;&lt;sup id="fnref:absurdity"&gt;&lt;a class="footnote-ref" href="#fn:absurdity" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;, the real concern should be over the quality of these test&amp;nbsp;items.&lt;/p&gt;
&lt;p&gt;Although &lt;span class="caps"&gt;CCSSI&lt;/span&gt; also deligently point out questions that are not well aligned to the standards, this is the least of my worries. Adjusting the difficulty of items and better alignment is something that testing companies know how to do and deal with all the time. Computerized testing is the new ground and a big part of why states are, rightfully, excited about the&amp;nbsp;consortium. &lt;/p&gt;
&lt;p&gt;The problem with the &lt;span class="caps"&gt;SBAC&lt;/span&gt; items is they represent the worst of computerized assessment. Rather than demonstrating more authentic and complex tasks, they present convoluted scenarios and even more convoluted input methods. Rather than present multimedia in a way that is authentic to the tasks, we see heavy language describing how to input what amounts to multiple choice or fill-in the blank answers. What I see here is not worth the investment in time and equipment that states are being asked to make, and it is hardly a &amp;#8220;next generation&amp;#8221; set of items that will allow us to attain more accurate measures of&amp;nbsp;achievement. &lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;SBAC&lt;/span&gt; looks poised to set up students to fail because of the mechanations of test taking. This is not only tragic at face value, but assures an increase in test-prep as the items are less&amp;nbsp;authentic.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:absurdity"&gt;
&lt;p&gt;There was a lot of concern trolling over Georgia leaving &lt;span class="caps"&gt;PARCC&lt;/span&gt; by &lt;a href="http://www.edexcellence.net/commentary/education-gadfly-daily/flypaper/2013/thats-how-the-consortia-crumble.html"&gt;Andy Smarick on Twitter and Flypaper&lt;/a&gt;. I don&amp;#8217;t really see this as devastating, nor do I think some kind of supplication to the Tea Party could have changed this. Short of federal mandating of common tests and standards, Georgia was never going to stay aligned with a consortium that includes Massachusetts. Georgia has an incredibly inexpensive testing program, because they have built really poor assessments that are almost entirely multiple choice. They also have some of the &lt;a href="http://educationnext.org/despite-common-core-states-still-lack-common-standards/"&gt;lowest proficiency standards in the country&lt;/a&gt;. There was no way this state would move up to a testing regime that costs more than twice as much (but is around the country median) that is substantially more complex and will have a much higher standard for proficiency. Georgia is one of those states that clearly demonstrates some of the &amp;#8220;soft bigotry of low expectations&amp;#8221; by hiding behind inflated proficiency due to low standards.&amp;#160;&lt;a class="footnote-backref" href="#fnref:absurdity" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary></entry><entry><title>Economic Policy Institute is Wrong</title><link href="http://blog.jsonbecker.com/2013/06/economic-policy-institute-is-wrong.html" rel="alternate"></link><updated>2013-06-20T00:00:00-04:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-06-20:2013/06/economic-policy-institute-is-wrong.html</id><summary type="html">&lt;p&gt;The &lt;a href="http://www.epi.org/"&gt;Economic Policy Institute&lt;/a&gt; has release a &lt;a href="http://www.epi.org/files/2013/ib366-rhode-islands-hybrid-pension-plan.pdf"&gt;short issue brief&lt;/a&gt; on the Rhode Island Retirement Security Act (&lt;span class="caps"&gt;RIRSA&lt;/span&gt;) by &lt;a href="https://twitter.com/rhiltnsmth"&gt;Robert Hiltonsmith&lt;/a&gt; that manages to get all of the details right but the big picture entirely&amp;nbsp;wrong.&lt;/p&gt;
&lt;p&gt;The &lt;span class="caps"&gt;EPI&lt;/span&gt; Issue Brief details the differences between the retirement system for state workers before and after the passage of &lt;span class="caps"&gt;RIRSA&lt;/span&gt; as accurately and clearly as I have ever seen. Mr. Hiltonsmith has done a notable job explaining the differences between the new system and the old&amp;nbsp;system.&lt;/p&gt;
&lt;p&gt;The brief, unfortunately, fails by engaging in two common fallacies to support its broader conclusions. The first is the &lt;a href="http://en.wikipedia.org/wiki/Straw_man"&gt;straw man fallacy&lt;/a&gt;. Mr. Hiltonsmith takes a limited set of the objectives of the entire &lt;span class="caps"&gt;RIRSA&lt;/span&gt; legislation and says defined contribution plans do not meet those objectives. That is true, but ignores the other objectives it does accomplish which were also part of the motivation behind &lt;span class="caps"&gt;RIRSA&lt;/span&gt;. The second is &lt;a href="http://en.wikipedia.org/wiki/Circular_reasoning"&gt;circular reasoning&lt;/a&gt;. In this case, Mr. Hiltonsmith states that the reason for a low funding ratio is because the state did not put 100% of its paper liability into the pension fund. This is a tautology and not in dispute and should not be trumpeted as a conclusion of&amp;nbsp;analysis.&lt;/p&gt;
&lt;p&gt;Here are his three main points that he believes makes &lt;span class="caps"&gt;RIRSA&lt;/span&gt; a bad&amp;nbsp;policy:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The defined contribution plan does not save the state money from its annual pension&amp;nbsp;contributions.&lt;/li&gt;
&lt;li&gt;The defined contribution plan is likely to earn lower returns and therefore result in lower benefits for&amp;nbsp;retirees.&lt;/li&gt;
&lt;li&gt;The defined contribution plan does not solve the low funding ratio of the pension plan which exists because law makers did not make required&amp;nbsp;contributions.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Of course, the defined contribution portion of &lt;span class="caps"&gt;RIRSA&lt;/span&gt; was not in place to do any of these three things. The purpose of including a defined contribution plan in the new state pension system is to create stability in annual budget allocations and avoid locking the government into promises it has demonstrated it fails to keep. Defined benefit plans require the state to change pension contributions when there are market fluctuations and leads to anti-cyclical costs, where the state is forced to put substantially more resources into pensions when revenues are lowest and spending on social welfare is most important. The defined contribution plan keeps the payments required by the state consistent and highly predictable. This is far preferable from a budget&amp;nbsp;perspective. &lt;/p&gt;
&lt;p&gt;It is unfortunate that there are lower returns to defined contribution plans which may lead to a decrease in overall benefits. It is my opinion that the unions in Rhode Island should be pushing for a substantially better match on the defined contribution portion of their plan that more closely resembles private sector match rates. This could more than alleviate the difference in benefits while maintaining the predictability, for budgeting purposes, of the defined contribution plan. I doubt this policy would have much hope of passing while Rhode Island slowly crawls out of a deep recession, but it is certainly a reasonable matter for future&amp;nbsp;legislatures.&lt;/p&gt;
&lt;p&gt;There are only two ways to decrease the current pension fund shortfalls: increase payments to the fund or decrease benefits. There is no structural magic sauce to get around this. Structural changes in the pension system are aimed at reducing the likelihood that the state will reproduce its current situation, with liabilities well outstripping funds. It is true that the &amp;#8220;savings&amp;#8221; largely came from cutting benefits. I have not heard anyone claim otherwise. The only alternative was to put a big lump sum into the pension fund. That clearly was not a part of&amp;nbsp;&lt;span class="caps"&gt;RIRSA&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;It is absurd to judge &lt;span class="caps"&gt;RIRSA&lt;/span&gt; on the ability of defined contribution plans to achieve policy objectives that are unrelated to the purpose of this structural&amp;nbsp;change.&lt;/p&gt;
&lt;p&gt;Perhaps the most troubling conclusion of this brief was&amp;nbsp;that, &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The shortfall in Rhode Island’s pension plan for public employees is largely due not to overly generous benefits, but to the failure of state and local government employers to pay their required share of pensions’&amp;nbsp;cost.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I read that and expected to see evidence of skipped payments or a discussion of overly ambitious expectations for investment returns, etc. Instead, it seems that this conclusion is based simply on the fact that the benefits in Rhode Island were not deemed outrageously large, and therefore Rhode Island should just pay the liability hole. The &amp;#8220;failure&amp;#8221; here is predicated entirely on the idea that the pensions as offered should be met, period, whatever the cost to the government. This is the &amp;#8220;required share&amp;#8221;. Which, of course, is technically true without a change in the law, but feels disingenuous. It is essentially a wholesale agreement with the union interpretation of the state pension system as an immutable contract. The courts will likely resolve whether or not this is true. My objection is that Mr. Hiltonsmith makes a definitive statement on this rationale without describing it. In such a lucid description of how the retirement system has changed, it seems this could only be intentional omission intended to support a predetermined conclusion rather than illuminate the&amp;nbsp;unconvinced.&lt;/p&gt;
&lt;p&gt;Mr. Hiltonsmith also claims that, &amp;#8220;Over the long term, &lt;span class="caps"&gt;RIRSA&lt;/span&gt; may cost the state upwards of \$15 million a year in additional contributions while providing a smaller benefit for the average full-career worker.&amp;#8221; I am not 100% certain, but based on his use of the normal cost &lt;sup id="fnref:normal cost"&gt;&lt;a class="footnote-ref" href="#fn:normal cost" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; to do these calculations, it appears this conclusion is drawn only based on the marginal contributions to current employees. In other words, if we &lt;em&gt;completely ignore&lt;/em&gt; the existing liability, the new plan cost the state more money marginally while potentially decreasing benefits for employees. It is my opinion that Mr. Hiltonsmith is intentionally creating the perception that &lt;span class="caps"&gt;RIRSA&lt;/span&gt; costs more than the current plan while providing fewer benefits. Again, this is true for future liabilities, but ignores that &lt;span class="caps"&gt;RIRSA&lt;/span&gt; also dramatically decreased the unfunded liabilities through cutting existing retiree benefits. So the overall cost for the act is far less, while the marginal cost was increased with the objective of decreasing the instability in government&amp;nbsp;appropriations.&lt;/p&gt;
&lt;p&gt;We can have a serious debate about whether there is value in the state goals of a defined contribution plan. In my view, the purpose of switching to this structure is&amp;nbsp;about: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Portability of plans for more mobile workers, potentially serving to attract younger and more highly skilled&amp;nbsp;employees. &lt;/li&gt;
&lt;li&gt;Stability in government expenditures on retiree benefits from year to year that are less susceptible to market forces. This includes avoiding the temptation to reduce payments when there are strong market returns as well as the crushing difficulty of increasing payments when the market (and almost certainly government receipts) are&amp;nbsp;down.&lt;/li&gt;
&lt;li&gt;Insulating workers from a government that perpetually writes checks they can cash, as was the case with the current&amp;nbsp;system.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This paper does not address any of these objectives or others I might have forgotten. In essence, the brief looks at only one subset of the perceived costs of this structural change, but it is far from a comprehensive analysis of the potential universe of both costs and benefits. In fact, it fails to even address the most commonly cited benefits. That is why I view it as heavily biased and flawed, even if I might draw similar conclusions from a more thorough&amp;nbsp;analysis.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:normal cost"&gt;
&lt;p&gt;Definition: Active participants earn new benefits each year. Actuaries call that the normal cost. The normal cost is always reflected in the cash and accounting cost of the plan. &lt;a href="http://www.actuary.org/pdf/pension/fundamentals_0704.pdf"&gt;Source&lt;/a&gt; In other words, the normal cost only looks at the new benefits added to the liability, not the existing liability.&amp;#160;&lt;a class="footnote-backref" href="#fnref:normal cost" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary></entry><entry><title>Calculating Age in R</title><link href="http://blog.jsonbecker.com/2013/06/calculating-age-in-r.html" rel="alternate"></link><updated>2013-06-12T00:00:00-04:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-06-12:2013/06/calculating-age-in-r.html</id><summary type="html">&lt;p&gt;A few months back I wrote some code to calculate age from a date of birth and arbitrary end date. It is not a real tricky task, but it is certainly one that comes up often when doing research on individual-level&amp;nbsp;data.&lt;/p&gt;
&lt;p&gt;I was a bit surprised to only find bits and pieces of code and advice on how to best go about this task. After reading through some old R-help and Stack Overflow responses on various ways to do date math in R, this is the function I wrote &lt;sup id="fnref:wrote"&gt;&lt;a class="footnote-ref" href="#fn:wrote" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;age_calc &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;dob&lt;span class="p"&gt;,&lt;/span&gt; enddate&lt;span class="o"&gt;=&lt;/span&gt;Sys.Date&lt;span class="p"&gt;(),&lt;/span&gt; units&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;months&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
  &lt;span class="kr"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;inherits&lt;span class="p"&gt;(&lt;/span&gt;dob&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Date&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; &lt;span class="o"&gt;!&lt;/span&gt;inherits&lt;span class="p"&gt;(&lt;/span&gt;enddate&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;Date&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    stop&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Both dob and enddate must be Date class objects&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  start &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; as.POSIXlt&lt;span class="p"&gt;(&lt;/span&gt;dob&lt;span class="p"&gt;)&lt;/span&gt;
  end &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; as.POSIXlt&lt;span class="p"&gt;(&lt;/span&gt;enddate&lt;span class="p"&gt;)&lt;/span&gt;

  years &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; end&lt;span class="o"&gt;$&lt;/span&gt;year &lt;span class="o"&gt;-&lt;/span&gt; start&lt;span class="o"&gt;$&lt;/span&gt;year
  &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;units&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;years&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    result &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; ifelse&lt;span class="p"&gt;((&lt;/span&gt;end&lt;span class="o"&gt;$&lt;/span&gt;mon &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; start&lt;span class="o"&gt;$&lt;/span&gt;mon&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; 
                      &lt;span class="p"&gt;((&lt;/span&gt;end&lt;span class="o"&gt;$&lt;/span&gt;mon &lt;span class="o"&gt;==&lt;/span&gt; start&lt;span class="o"&gt;$&lt;/span&gt;mon&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;end&lt;span class="o"&gt;$&lt;/span&gt;mday &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; start&lt;span class="o"&gt;$&lt;/span&gt;mday&lt;span class="p"&gt;)),&lt;/span&gt;
                      years &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; years&lt;span class="p"&gt;)&lt;/span&gt;    
  &lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="kr"&gt;else&lt;/span&gt; &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;units&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;months&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    months &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;years&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="m"&gt;12&lt;/span&gt;
    result &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; months &lt;span class="o"&gt;+&lt;/span&gt; start&lt;span class="o"&gt;$&lt;/span&gt;mon
  &lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="kr"&gt;else&lt;/span&gt; &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;units&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;days&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    result &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; difftime&lt;span class="p"&gt;(&lt;/span&gt;end&lt;span class="p"&gt;,&lt;/span&gt; start&lt;span class="p"&gt;,&lt;/span&gt; units&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;days&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="kr"&gt;else&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
    stop&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Unrecognized units. Please choose years, months, or days.&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="kr"&gt;return&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;result&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;A few notes on proper usage and the choices I made in writing this&amp;nbsp;function: &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The parameters &lt;code&gt;dob&lt;/code&gt; and &lt;code&gt;enddate&lt;/code&gt; expect data that is already in one of the various classes that minimally inherits the base class &lt;code&gt;Date&lt;/code&gt;. &lt;/li&gt;
&lt;li&gt;This function takes advantage of the way that R treats vectors, so both &lt;code&gt;dob&lt;/code&gt; and &lt;code&gt;enddate&lt;/code&gt; can be a single or multi-element vector. For example &lt;code&gt;enddate&lt;/code&gt; is a single date, as is the default, then the function will return a vector that calculates the difference between &lt;code&gt;dob&lt;/code&gt; and that single date for each element in &lt;code&gt;dob&lt;/code&gt;. If &lt;code&gt;dob&lt;/code&gt; and &lt;code&gt;enddate&lt;/code&gt; are both vectors with n&amp;gt;1, then the returned vector will contain the &lt;a href="http://heather.cs.ucdavis.edu/~matloff/r.old.html#elementwise"&gt;element-wise&lt;/a&gt; difference between &lt;code&gt;dob&lt;/code&gt; and &lt;code&gt;enddate&lt;/code&gt;. When the vectors are of different sizes, the shorter vector will be repeated over until it reaches the same length as the longer vector. This is known as &lt;a href="http://cran.r-project.org/doc/manuals/R-intro.html#The-recycling-rule"&gt;recycling&lt;/a&gt;, and it is the default behavior in&amp;nbsp;R.&lt;/li&gt;
&lt;li&gt;This function always returns an integer. Calculating age in years will never return, say, 26.2. Instead, it assumes that the correct behavior for age calculations is something like a &lt;code&gt;floor&lt;/code&gt; function. For examle, the function will only return 27 if &lt;code&gt;enddate&lt;/code&gt; is minimally your 27th birthday. Up until that day you are considered 26. The same is true for age in&amp;nbsp;months.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is probably the first custom function in almost 3 years using R that I wrote to be truly generalizable. I was inspired by three factors. First, this is a truly frequent task that I will have to apply to many data sets in the future that I don&amp;#8217;t want to have to revisit. Second, a professional acquaintance, &lt;a href="http://jaredknowles.com/"&gt;Jared Knowles&lt;/a&gt;, is putting together a &lt;span class="caps"&gt;CRAN&lt;/span&gt; package with various convenience functions for folks who are new to R and using it to analyze education data &lt;sup id="fnref:eeptools"&gt;&lt;a class="footnote-ref" href="#fn:eeptools" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;. This seemed like an appropriate addition to that package, so I wanted to write it to that standard. In fact, it was my first (and to date, only) submitted and accepted pull request on Github. Third, it is a tiny, simple function so it was easy to wrap my head around and write it well. I will let you be the judge of my success or failure &lt;sup id="fnref:inspiration"&gt;&lt;a class="footnote-ref" href="#fn:inspiration" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:wrote"&gt;
&lt;p&gt;I originally used &lt;code&gt;Sys.time()&lt;/code&gt; not realizing there was a &lt;code&gt;Sys.Date()&lt;/code&gt; function. Thanks to Jared Knowles for that edit in preparation for a &lt;span class="caps"&gt;CRAN&lt;/span&gt; check.&amp;#160;&lt;a class="footnote-backref" href="#fnref:wrote" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:eeptools"&gt;
&lt;p&gt;Check out &lt;a href="https://github.com/jknowles/eeptools"&gt;eeptools&lt;/a&gt; on Github.&amp;#160;&lt;a class="footnote-backref" href="#fnref:eeptools" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:inspiration"&gt;
&lt;p&gt;Thanks to &lt;a href="http://mcfromnz.wordpress.com/2013/06/12/updated-age-calculation-function/"&gt;Matt&amp;#8217;s Stats n Stuff&lt;/a&gt; for getting me to write this post. When I saw another age calculation function pop up on the r-bloggers feed I immediately thought of this function. Matt pointed out that it was quite hard to Google for age calculations in R, lamenting that Google doesn&amp;#8217;t meaningfully crawl Github where I linked to find my code. So this post is mostly about providing some help to less experience R folks who are frantically Googling as both Matt and I did when faced with this need.&amp;#160;&lt;a class="footnote-backref" href="#fnref:inspiration" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary></entry><entry><title>Linear Thinking</title><link href="http://blog.jsonbecker.com/2013/06/linear-thinking.html" rel="alternate"></link><updated>2013-06-02T00:00:00-04:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-06-02:2013/06/linear-thinking.html</id><summary type="html">&lt;p&gt;Apple will be revealing new details for both of its major operating systems at &lt;span class="caps"&gt;WWDC&lt;/span&gt; on June 10, 2013. The focus of much speculation has been how Apple will improve multi-tasking and inter-app communication in iOS7. As batteries have grown, CPUs have become increasingly powerful, and the application &lt;a href="http://blog.jsonbecker.com/2012/11/frictionless.html"&gt;ecosystem&lt;/a&gt; has matured &lt;sup id="fnref:viticci"&gt;&lt;a class="footnote-ref" href="#fn:viticci" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;, the iOS sandboxing model has felt increasingly limiting and&amp;nbsp;outdated.&lt;/p&gt;
&lt;p&gt;I think that there is a simple change that could dramatically increase the effectiveness of multitasking on iOS by re-examining how application switching&amp;nbsp;works.&lt;/p&gt;
&lt;p&gt;Scrolling through a long list of applications, either through the basement shelf or via the four-finger gesture on an iPad, is both slow and lacking in contextual cues. In a simple case where I am working with two applications simultaneously, how do I switch between them? The list of open applications always places the current application in the first position. The previously used application sits in the second position. The first time I want to change to another application this is not so bad. I move to the &amp;#8220;right&amp;#8221; on the list to progress forward into the next application &lt;sup id="fnref:next"&gt;&lt;a class="footnote-ref" href="#fn:next" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;. &lt;/p&gt;
&lt;p&gt;The trouble comes when I want to return to where I was just working. The most natural mental model for this switch is to move &amp;#8220;left&amp;#8221; in the list. I moved &amp;#8220;right&amp;#8221; to get here and millions of years of evolution has taught me the the &amp;#8220;undo button&amp;#8221; for moving right is to move left &lt;sup id="fnref:inform7"&gt;&lt;a class="footnote-ref" href="#fn:inform7" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;. But of course, when I attempt to move &amp;#8220;left&amp;#8221;, I find no destination &lt;sup id="fnref:youcant"&gt;&lt;a class="footnote-ref" href="#fn:youcant" rel="footnote"&gt;4&lt;/a&gt;&lt;/sup&gt;. I can pop an application from anywhere on the list, but I can only prepend new applications to the list &lt;sup id="fnref:ignorant"&gt;&lt;a class="footnote-ref" href="#fn:ignorant" rel="footnote"&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;Apple needs to move away from its linear thinking and enter the second&amp;nbsp;dimension.&lt;/p&gt;
&lt;p&gt;What if I could drag apps in the switcher on top of each other to make a new stack, not unlike the option on the &lt;span class="caps"&gt;OS&lt;/span&gt; X launch bar? Throughout this stack, position is maintained regardless of which application is in use/was last used. I can always move &lt;strong&gt;up&lt;/strong&gt; from Chrome to ByWord, and &lt;strong&gt;down&lt;/strong&gt; to Good Reader, for example, if I was writing a report. Apple might call this a Stack, mirroring the term in &lt;span class="caps"&gt;OSX&lt;/span&gt;, but I would prefer this to be called a &lt;em&gt;Flow&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;The goal of this feature is to organize a &lt;em&gt;Flow&lt;/em&gt; for a particular task that requires using multiple apps. One feature might be saving a &amp;#8220;Flow&amp;#8221;, this way each time I want to write a blog post, I tap the same home screen button and the same four apps in the same order launch in a &lt;em&gt;Flow&lt;/em&gt;, ready for easy switching using the familiar four-finger swipe gesture up and down. I no longer have to worry about the sequence I have recently accessed applications which is confusing and requires me to look at the app switcher draw or needlessly and repeatedly swipe through applications. I never have to worry about lingering too long on one application while swiping through and switching to that app, changing my position to the origin of the list and starting over&amp;nbsp;again. &lt;/p&gt;
&lt;p&gt;For all the calls for complex inter-app communication or having multiple apps active on the screen at the same time, it seems a simple interface change to application switching could complete change the way we multitask on&amp;nbsp;iOS.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:viticci"&gt;
&lt;p&gt;And Federico Viticci has either shown us the light or gone completely mad.&amp;#160;&lt;a class="footnote-backref" href="#fnref:viticci" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:next"&gt;
&lt;p&gt;For now, lets assume the right application is next in the stack. I&amp;#8217;ll get to that issue with my second change.&amp;#160;&lt;a class="footnote-backref" href="#fnref:next" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:inform7"&gt;
&lt;p&gt;&lt;code&gt;You are in a green room. &amp;gt; Go east. You are in a red room. &amp;gt; Go west. You are in a green room.&lt;/code&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:inform7" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:youcant"&gt;
&lt;p&gt;&lt;code&gt;You can't go that way.&lt;/code&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:youcant" rev="footnote" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:ignorant"&gt;
&lt;p&gt;I don&amp;#8217;t know enough about data structures yet to name what&amp;#8217;s going on here. I am tempted to think that the challenge is they have presented a list to users, with a decidedly horizontal metaphor, when they actually have created something more akin to a stack, with a decidedly vertical metaphor. But a stack isn&amp;#8217;t quite the right way to understand the app switcher. You can &amp;#8220;pop&amp;#8221; an app from any arbitrary position on the app switcher, but funny enough can only push a new app on to the top of the switcher.&amp;#160;&lt;a class="footnote-backref" href="#fnref:ignorant" rev="footnote" title="Jump back to footnote 5 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary></entry><entry><title>Cleaning URLs with TextExpander</title><link href="http://blog.jsonbecker.com/2013/05/cleaning-urls-with-textexpander.html" rel="alternate"></link><updated>2013-05-30T00:00:00-04:00</updated><author><name>Jason P. Becker</name></author><id>tag:blog.jsonbecker.com,2013-05-30:2013/05/cleaning-urls-with-textexpander.html</id><summary type="html">&lt;p&gt;One thing I really dislike about Google Reader is it replaces the links to posts in my &lt;span class="caps"&gt;RSS&lt;/span&gt; feed. My &lt;a href="http://pinboard.in/u:jasonpbecker"&gt;Pinboard account&lt;/a&gt; is littered with links that start with &lt;code&gt;http://feedproxy.google.com&lt;/code&gt;. I am quite concerned that with the demise of &lt;a href="http://googlereader.blogspot.com/2013/03/powering-down-google-reader.html"&gt;Google Reader&lt;/a&gt; on July 1, 2013, these redirects will no longer&amp;nbsp;work.&lt;/p&gt;
&lt;p&gt;It&amp;#8217;s not just Google that obscures the actually address of links on the internet. The popularity of using link shortening services, both to save characters on Twitter and to collect analytics, has proliferated the &lt;em&gt;Internet of Redirects&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;Worse still, after I am done cutting through redirects, I often find that the ultimate link include all kinds of extraneous attributes, most especially a barrage of &lt;code&gt;utm_*&lt;/code&gt; campaign&amp;nbsp;tracking.&lt;/p&gt;
&lt;p&gt;Now, I understand why all of this is happening and the importance of the services and analytics this link cruft provides. I am quite happy to click on shortened links, move through all the redirects, and let sites know just how I found them. But quite often, like when using a bookmarking service or writing a blog post, I just want the simple, plain text &lt;span class="caps"&gt;URL&lt;/span&gt; that gets me directly to the permanent home of the&amp;nbsp;content.&lt;/p&gt;
&lt;p&gt;One part of my workflow to deal with link cruft is a TextExpander snippet I call &lt;code&gt;cleanURL&lt;/code&gt;. It triggers a simple Python script that grabs the &lt;span class="caps"&gt;URL&lt;/span&gt; in my clipboard, traces through the redirects to the final destination, then strips links of campaign tracking attributes, and ultimately pastes a new &lt;span class="caps"&gt;URL&lt;/span&gt; that is much&amp;nbsp;&amp;#8220;cleaner&amp;#8221;.&lt;/p&gt;
&lt;p&gt;Below I have provided the script. I hope it is useful to some other folks, and I would love some recommendations for additional &amp;#8220;cleaning&amp;#8221; that could be&amp;nbsp;performed.&lt;/p&gt;
&lt;p&gt;My next task is expanding this script to work with &lt;a href="http://pinboard.in"&gt;Pinboard&lt;/a&gt; so that I can clean up all my links before the end of the month when Google Reader goes belly&amp;nbsp;up.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/usr/bin/python&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;requests&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;re&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;search&lt;/span&gt;
&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;subprocess&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;check_output&lt;/span&gt;

&lt;span class="n"&gt;url&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;check_output&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;pbpaste&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# Go through the redirects to get the destination &lt;span class="caps"&gt;URL&lt;/span&gt;&lt;/span&gt;
&lt;span class="n"&gt;r&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;requests&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;get&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# Look for utm attributes&lt;/span&gt;
&lt;span class="n"&gt;match&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt;  &lt;span class="n"&gt;search&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;r&amp;#39;[?&amp;amp;#]utm_&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# Because I&amp;#39;m not smart and trigger this with&lt;/span&gt;
&lt;span class="c"&gt;# already clean URLs&lt;/span&gt;
&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;match&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;cleanURL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;split&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;match&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;group&lt;/span&gt;&lt;span class="p"&gt;())[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
  &lt;span class="n"&gt;cleanURL&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;r&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;url&lt;/span&gt;

&lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="n"&gt;cleanURL&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary></entry><entry><title>The Slow Trek to Pelican</title><link href="http://blog.jsonbecker.com/2012/12/the-slow-trek-to-pelican.html" rel="alternate"></link><updated>2012-12-20T10:10:00-05:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-12-20:2012/12/the-slow-trek-to-pelican.html</id><summary type="html">&lt;p&gt;&lt;em&gt;Update: Please see below for two&amp;nbsp;solutions.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;I have grown increasingly unhappy with Wordpress lately. My blog is simple. My design tastes are simple. My needs are simple. I like control. I am a geek. And I really need an excuse to learn Python, which seems to be rapidly growing into one of the most important programming languages for a data&amp;nbsp;analyst.&lt;/p&gt;
&lt;p&gt;I have decided to migrate this blog over to &lt;a href="http://docs.getpelican.com/en/3.1.1/"&gt;Pelican&lt;/a&gt;, a static site generator written in Python. Static sites are the &amp;#8220;classic&amp;#8221; way to do a webpage&amp;#8212; just upload a bunch of &lt;span class="caps"&gt;HTML&lt;/span&gt; and &lt;span class="caps"&gt;CSS&lt;/span&gt; files, maybe some Javascript. But no databases and no constructing the page a user sees in the browser as they request it. This puts substantially less strain on a web server and makes it far easier to export and move a webpage since all you need to do is duplicate files. What makes static sites a real pain is that there is a lot of repetition. Folks adopted dynamic sites that use content management system so that they can write a page called &amp;#8220;post.php&amp;#8221; one time, and for each unique post just query a database for the unique content. The frame around the post, layout, components, etc are all just written once. Static site generators allow you to build a webpage using a similar, but far more stripped down, layout system. However, rather than generate each page on the web server, you generate each page by running a script locally that transforms plain text documents into well-formed &lt;span class="caps"&gt;HTML&lt;/span&gt;/&lt;span class="caps"&gt;CSS&lt;/span&gt;. Then you can just upload a directory and the whole site is ready to&amp;nbsp;go.&lt;/p&gt;
&lt;p&gt;Pelican comes with a pretty good script that will take Wordpress &lt;span class="caps"&gt;XML&lt;/span&gt; that&amp;#8217;s available via the built-in export tools and transform each post into a &lt;a href="http://docutils.sourceforge.net/rst.html"&gt;reStructuredText&lt;/a&gt; files, a format similar to &lt;a href="http://daringfireball.net/projects/markdown/"&gt;Markdown&lt;/a&gt;. I prefer Markdown so I used &lt;a href="http://johnmacfarlane.net/pandoc/"&gt;pandoc&lt;/a&gt; to convert all my *.rst posts into *.md&amp;nbsp;files.&lt;/p&gt;
&lt;p&gt;So far, so&amp;nbsp;good.&lt;/p&gt;
&lt;p&gt;But one of the really big problems I had with Wordpress was a growing dependency on plugins that added non-standard, text-based markup in my posts that would be rendered a particular way. For example, text surrounded by two parenthesis, &amp;#8216;[^0]&amp;#8217;, became a footnote. For code syntax highlighting, I use a &amp;#8220;short code&amp;#8221;, which puts &amp;#8220;sourcecode language=&amp;#8217;r&amp;#8217;&amp;#8221;, for example, between brackets []. All of these plugins have been great, but now when you try to export a post you get the non-standard markup in-line as part of your posts. It makes it very difficult to recreate a post the way it looks&amp;nbsp;today.&lt;/p&gt;
&lt;p&gt;This presents a great opportunity to learn a little Python. So I have begun to scrounge together some basic Python knowledge to write some scripts to clean up my Markdown files and convert the syntax of the short codes that I have used to properly formatted Markdown so that when I run the pelican script it will accurately reproduce each&amp;nbsp;post.&lt;/p&gt;
&lt;p&gt;Unfortunately, I&amp;#8217;ve hit a snag with my very first attempt. Footnotes are a big deal to me and have standard Markdown interpretation. In Markdown, footnotes are inserted in the text where &amp;#8220;[\^#]&amp;#8221; appears in the text, where # = the footnote identifier/key. Then, at the end of the document, surrounded by new lines, the footnote text is found with &amp;#8220;[\^#]: footnote text&amp;#8221; where # is the same identifier. So I needed to write a script that found each instance of text surrounded by two parentheses, insert the [\^#] part in place of the footnote, and then add the footnote at the bottom of the post in the right&amp;nbsp;format.&lt;/p&gt;
&lt;p&gt;I created a test text&amp;nbsp;file:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;This&lt;/span&gt; &lt;span class="n"&gt;is&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="n"&gt;footnote&lt;/span&gt;&lt;span class="p"&gt;)).&lt;/span&gt;
&lt;span class="n"&gt;And&lt;/span&gt; &lt;span class="n"&gt;here&lt;/span&gt; &lt;span class="n"&gt;is&lt;/span&gt; &lt;span class="n"&gt;another&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;footnote2&lt;/span&gt;&lt;span class="p"&gt;)).&lt;/span&gt; &lt;span class="n"&gt;Why&lt;/span&gt; &lt;span class="n"&gt;not&lt;/span&gt; &lt;span class="n"&gt;add&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;third&lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;Three&lt;/span&gt;
&lt;span class="n"&gt;Three&lt;/span&gt;&lt;span class="p"&gt;)).&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The goal was to end up with a file like&amp;nbsp;this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;This&lt;/span&gt; &lt;span class="n"&gt;is&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt; &lt;span class="n"&gt;And&lt;/span&gt; &lt;span class="n"&gt;here&lt;/span&gt; &lt;span class="n"&gt;is&lt;/span&gt; &lt;span class="n"&gt;another&lt;/span&gt;
&lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt; &lt;span class="n"&gt;Why&lt;/span&gt; &lt;span class="n"&gt;not&lt;/span&gt; &lt;span class="n"&gt;add&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;third&lt;/span&gt;&lt;span class="o"&gt;?&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;].&lt;/span&gt;

&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="n"&gt;footnote&lt;/span&gt;

&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;footnote2&lt;/span&gt;

&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;Three&lt;/span&gt; &lt;span class="n"&gt;Three&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Unfortunately, the output isn&amp;#8217;t quite right. My best attempt resulted in
a file like&amp;nbsp;this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;This&lt;/span&gt; &lt;span class="n"&gt;is&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="n"&gt;And&lt;/span&gt; &lt;span class="n"&gt;here&lt;/span&gt; &lt;span class="n"&gt;is&lt;/span&gt; &lt;span class="n"&gt;another&lt;/span&gt; &lt;span class="n"&gt;te&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])).&lt;/span&gt; &lt;span class="n"&gt;Why&lt;/span&gt; &lt;span class="n"&gt;not&lt;/span&gt; &lt;span class="n"&gt;add&lt;/span&gt; &lt;span class="n"&gt;a&lt;/span&gt;
&lt;span class="n"&gt;t&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="n"&gt;ree&lt;/span&gt;&lt;span class="p"&gt;)).&lt;/span&gt;

&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="n"&gt;footnote&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;footnote2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;^&lt;/span&gt;&lt;span class="mi"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="p"&gt;((&lt;/span&gt;&lt;span class="n"&gt;Three&lt;/span&gt; &lt;span class="n"&gt;Three&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ugh.&lt;/p&gt;
&lt;p&gt;So I am turning to the tiny slice of my readership that might actually know Python or just code in general to help me out. Where did I screw up? The source to my Python script is below so feel free to comment here or on this &lt;a href="https://gist.github.com/4342554#file-wpfootnotestomarkdown-py"&gt;Gist&lt;/a&gt;. I am particularly frustrate that the regex appears to be capturing the parenthesis, because that&amp;#8217;s not how the same code behaves on &lt;a href="http://www.pythonregex.com"&gt;PythonRegex.com&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;If anyone can help me with the next step, which will be creating arguments that will understand an input like &lt;em&gt;.rst and set the output to creating a file that&amp;#8217;s &lt;/em&gt;.md, that would be appreciated as&amp;nbsp;well. &lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;re&lt;/span&gt;

&lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;\(\(([^\(\(\)\)]+)\)\)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;file_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="nb"&gt;raw_input&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;File Name &amp;gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;footnoteMatches&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;finditer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;coordinates&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="n"&gt;footnotes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;

&lt;span class="c"&gt;# Print span of matches&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;match&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;footnoteMatches&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;coordinates&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;match&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
    &lt;span class="n"&gt;footnotes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;match&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;group&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;

&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coordinates&lt;/span&gt;&lt;span class="p"&gt;)):&lt;/span&gt;
    &lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;&lt;span class="n"&gt;coordinates&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;[^&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;]&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
            &lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;coordinates&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;:])&lt;/span&gt;
    &lt;span class="n"&gt;shift&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;coordinates&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;coordinates&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;
    &lt;span class="k"&gt;while&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coordinates&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
        &lt;span class="n"&gt;coordinates&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coordinates&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;shift&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;coordinates&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="n"&gt;shift&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
        &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;

&lt;span class="n"&gt;referenceLinkList&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&amp;#39;&lt;/span&gt;
&lt;span class="s"&gt;&amp;#39;&amp;quot; language=&amp;quot;,&amp;quot;][/text]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;footnotes&lt;/span&gt;&lt;span class="p"&gt;)):&lt;/span&gt;
    &lt;span class="n"&gt;insertList&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;[^&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;str&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;]: &amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;footnotes&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
    &lt;span class="n"&gt;referenceLinkList&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;insertList&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;referenceLinkList&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;newFile&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;newFile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;truncate&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;newFile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;newFile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Update with&amp;nbsp;solutions:&lt;/h2&gt;
&lt;p&gt;I am happy to report I now have two working solutions. The first one comes courtesy of &lt;a href="https://github.com/ilikepi"&gt;James Blanding&lt;/a&gt; who was kind enough to &lt;a href="https://gist.github.com/4355865"&gt;fork&lt;/a&gt; the gist I put up. While I was hoping to take a look tonight at his fork tonight, &lt;a href="http://news.ycombinator.com/item?id=4957935"&gt;Github was experiencing some downtime&lt;/a&gt;.  So I ended up fixing the script myself a slightly different way (seen below). I think James&amp;#8217;s approach is superior for a few reasons, not the least of which was avoiding the ugly if/elif/else found in my code by using a global counter. He also used .format() a lot better than I did, which I didn&amp;#8217;t know existed until I found it&amp;nbsp;tonight.&lt;/p&gt;
&lt;p&gt;I made two other changes before coming to my solution. First, I realized my regex was completely wrong. I didn&amp;#8217;t want to capture anything within the two parenthesis when no parenthesis were contained, as the original regex did. Instead, I wanted to make sure to preserve any parenthetical comments contained within my footnotes. So the resulting regex looks a bit different. I also switched from using user input to taking in the filepath as an&amp;nbsp;argument.&lt;/p&gt;
&lt;p&gt;My next step will be to learn a bit more about the os module which seems to contain what I need so that this Python script can behave like a good Unix script and know what to do with one file or a list of files as a parameter (and of course, most importantly, a list generated from a wild card like *.rst). I will also be incorporating the bits of James&amp;#8217;s code that I feel confident I understand and that I like&amp;nbsp;better.&lt;/p&gt;
&lt;p&gt;Without further ado, my solution (I updated the gist as&amp;nbsp;well):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kn"&gt;from&lt;/span&gt; &lt;span class="nn"&gt;sys&lt;/span&gt; &lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="n"&gt;argv&lt;/span&gt;
&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;re&lt;/span&gt;

&lt;span class="n"&gt;name&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;file_path&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;argv&lt;/span&gt;

&lt;span class="n"&gt;p&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;re&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;compile&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;r&amp;quot;[\s]\(\((.*?[)]{0,1})\)\)[\s]{0,1}&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c"&gt;# The tricky part here is to match all text between &amp;quot;((&amp;quot;&amp;quot;))&amp;quot;, including as &lt;/span&gt;
&lt;span class="c"&gt;# many as one set of (), which may even terminate ))). The {0,1} captures as&lt;/span&gt;
&lt;span class="c"&gt;# many as one ). The trailing space is there because I often surrounded the &lt;/span&gt;
&lt;span class="c"&gt;# &amp;quot;((&amp;quot;&amp;quot;))&amp;quot; with a space to make it clear in the WordPress editor.&lt;/span&gt;

&lt;span class="c"&gt;# file_path = str(raw_input(&amp;#39;File Name &amp;gt;&amp;#39;))&lt;/span&gt;
&lt;span class="n"&gt;text&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_path&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;read&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="n"&gt;footnoteMatches&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;p&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;finditer&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;coordinates&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="n"&gt;footnotes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;

&lt;span class="c"&gt;# Print span of matches&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;match&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;footnoteMatches&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;coordinates&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;match&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;span&lt;/span&gt;&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="c"&gt;# Capture only group(1) so you get the content of the footnote, not the &lt;/span&gt;
&lt;span class="c"&gt;# whole pattern which includes the parenthesis delimiter.&lt;/span&gt;
    &lt;span class="n"&gt;footnotes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;match&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;group&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

&lt;span class="n"&gt;newText&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coordinates&lt;/span&gt;&lt;span class="p"&gt;)):&lt;/span&gt;
    &lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;newText&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;[:&lt;/span&gt;&lt;span class="n"&gt;coordinates&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                               &lt;span class="s"&gt;&amp;#39; [^{}]&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;elif&lt;/span&gt; &lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;coordinates&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt; &lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;newText&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;coordinates&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;&lt;span class="n"&gt;coordinates&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                          &lt;span class="s"&gt;&amp;#39; [^{}]&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    &lt;span class="k"&gt;else&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
        &lt;span class="n"&gt;newText&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;coordinates&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]:&lt;/span&gt;&lt;span class="n"&gt;coordinates&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                          &lt;span class="s"&gt;&amp;#39; [^{}]&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
        &lt;span class="c"&gt;# Accounts for text after the last footnote which only runs once.&lt;/span&gt;
        &lt;span class="n"&gt;newText&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;text&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;coordinates&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;i&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]:]&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;endNotes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[]&lt;/span&gt;
&lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="nb"&gt;range&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="mi"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="nb"&gt;len&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;footnotes&lt;/span&gt;&lt;span class="p"&gt;)):&lt;/span&gt;
    &lt;span class="n"&gt;insertList&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;([&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;[^{}]: &amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;footnotes&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;format&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;j&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="n"&gt;endNotes&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;append&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;insertList&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;newText&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;newText&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&lt;/span&gt;&lt;span class="se"&gt;\n&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;join&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;endNotes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="n"&gt;newFile&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;open&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;file_path&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;w&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;newFile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;truncate&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="n"&gt;newFile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;write&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;newText&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="n"&gt;newFile&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;close&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="code"></category><category term="pelican"></category><category term="python"></category><category term="regex"></category><category term="wordpress"></category></entry><entry><title>A little knowledge is a wonderful (dangerous) thing</title><link href="http://blog.jsonbecker.com/2012/11/a-little-knowledge-is-a-wonderful-dangerous-thing.html" rel="alternate"></link><updated>2012-11-20T10:17:00-05:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-11-20:2012/11/a-little-knowledge-is-a-wonderful-dangerous-thing.html</id><summary type="html">&lt;p&gt;It is so tempting to try to apply cognitive science results in education. It seems like an obvious step on the long road of moving education from a field of theory and philosophies to one more grounded in empirical research. Yet, learning myths are persistent. Even scarier, &amp;#8220;&lt;a href="http://cedarsdigest.wordpress.com/2012/11/18/myths-come-from-values-not-from-ignorance/"&gt;those who know the most about neuroscience also believe the most myths.&lt;/a&gt;&amp;#8221;&lt;/p&gt;
&lt;p&gt;Educators may have the best intentions when trying to infuse their practice with evidence, but they all too often are not equipped as critical consumers of research. Worse, the education profession has historically been wrapped in &amp;#8220;thoughtworld&amp;#8221; &lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;, where schools of education have taught same ideas about effective teaching and learning for decades without a basis in empirical research. These same ideas are taught to principals, district administrators, and teachers, so nary a critical voice can stop the myths from being repeated and mutually reinforcing each&amp;nbsp;other.&lt;/p&gt;
&lt;p&gt;Effectively conducting empirical research, translating research for policymakers, and implementing research-based program design is my job. I came to education purely from a research and policy perspective, and I am equipped to understand some of the empirical research done on effective schooling &lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;I have to confront an awful history of &amp;#8220;outsiders&amp;#8221; like myself who have brought round after round of poorly supported, poorly evaluated reforms. I have to confront the history of districts and schools discarding some very effective programs because of leadership changes, lack of resources, and most of all a lack good, systematic evaluation of programs. And I have to be damn good at what I do, because even a small misstep could paint me just like every other &amp;#8220;expert&amp;#8221; that has rolled through with the newest great&amp;nbsp;idea.&lt;/p&gt;
&lt;p&gt;I think this is why I tend to favor interventions that are very small. Simple, small, hard to &amp;#8220;mess up&amp;#8221; interventions,  based in research, implemented just a few at a time have tremendous potential. I love the oft-cited work on &lt;a href="http://www.nber.org/papers/w15361"&gt;filling out the &lt;span class="caps"&gt;FAFSA&lt;/span&gt; along with tax filing at H&amp;amp;R Block&lt;/a&gt;. It is simple. There is no fear of &amp;#8220;dosage&amp;#8221; or implementation fidelity. There are both sound theoretical reasons and empirical results from other domains that suggest a high likelihood of success. It has the potential to make a huge impact on students without adding any load to teachers who are, say, implementing a brand new and complicated curriculum this year. This is how you earn trust through building&amp;nbsp;success.&lt;/p&gt;
&lt;p&gt;I am also a fan of some really big, dramatic changes, but how I get there will have to be the subject of a future&amp;nbsp;post.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;&lt;span class="caps"&gt;E.D.&lt;/span&gt; Hirsch&amp;#8217;s term&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;In the area of neuroscience and cognitive science, I am probably only marginally better off than most teachers. My Sc.B. is in chemistry. So a background in empirical physical sciences and my knowledge of social science may help me to access some of the research on how people learn, but I would probably be just as susceptible to overconfidence in my ability to process this research and repeat untruths as many very intelligent educators.&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="edpolicy"></category><category term="education"></category><category term="education policy"></category><category term="research"></category></entry><entry><title>Frictionless</title><link href="http://blog.jsonbecker.com/2012/11/frictionless.html" rel="alternate"></link><updated>2012-11-04T21:38:00-05:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-11-04:2012/11/frictionless.html</id><summary type="html">&lt;p&gt;Apple has released the iPad Mini. Microsoft unveiled the Surface &lt;span class="caps"&gt;RT&lt;/span&gt;. Google has expanded its play with the Nexus 4 (phone) and 10 (tablet) to sandwich the previously released 7. In virtually every review of these
new devices the Apple advantage was&amp;nbsp;ecosystem.&lt;/p&gt;
&lt;p&gt;Time and time again, following descriptions of well designed and built hardware &lt;sup id="fnref:hardware"&gt;&lt;a class="footnote-ref" href="#fn:hardware" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;, reviewers were forced to add some form of, &amp;#8220;But the ecosystem cannot compete with Apple&amp;#8217;s 275,000 tablet-optimized application.&amp;#8221; I think this understates the power of Apple&amp;#8217;s amazing developer&amp;nbsp;advantage.&lt;/p&gt;
&lt;p&gt;I use three distinct computing platforms every day: my phone, my tablet, and my traditional &lt;span class="caps"&gt;PC&lt;/span&gt; (laptop and desktop). There are times where I use an application which is specific to one platform or the other. Dark Sky,
for example, is incredibly useful on my iPhone but would be pretty pointless on my Mac Mini or Macbook Air. This kind of platform-specific, quality application is what most would consider the App Store advantage. Not&amp;nbsp;me.&lt;/p&gt;
&lt;p&gt;Apple&amp;#8217;s true advantage is when applications are available &lt;em&gt;across all three platforms&lt;/em&gt;, offering simultaneously a device-optimized and consistent experience no matter what I am&amp;nbsp;using.&lt;/p&gt;
&lt;p&gt;They offer a &lt;em&gt;frictionless&lt;/em&gt;&amp;nbsp;experience.&lt;/p&gt;
&lt;p&gt;There is a good reason people were so excited for Tweetbot for &lt;span class="caps"&gt;OSX&lt;/span&gt; and love to use Reeder on iPhone, iPad, and &lt;span class="caps"&gt;OSX&lt;/span&gt;. The features, feel, gestures, and even notification sounds having consistency across
environments makes it easier to use computers. The so-called &amp;#8220;halo effect&amp;#8221; of the iPod was widely discussed in the early 2000s. iTunes on every Windows machine represented the tail end of a long play that pushed the promise of frictionless computing with Apple products. iOS delivers on this promise in&amp;nbsp;spades.&lt;/p&gt;
&lt;p&gt;Google knows a big selling point of Android is offering the best mobile experience with their web products. As an early and voracious user of Gmail, Google Contacts, and Google Calendar, I do find this enticing. But Android apps are never going to be able to offer the frictionless experience offered by Apple across the mobile and desktop space. ChromeOS is Google&amp;#8217;s best effort to push a frictionless platform, but it&amp;#8217;s entirely limited to non-native applications so anything but Google products require major modifications and just won&amp;#8217;t be the&amp;nbsp;same.&lt;/p&gt;
&lt;p&gt;Microsoft sees the Apple advantage clearly, and they understand Google&amp;#8217;s inability to fully compete. That&amp;#8217;s why they are launching Windows 8, in many ways attempting to even further integrate the tablet and desktop than Apple. The Surface, and Windows 8 writ large, is a bet that Apple made a mistake grouping tablets with cell phones. The tablet, according to Microsoft, is about replacing laptops and should be grouped with the&amp;nbsp;desktop.&lt;/p&gt;
&lt;p&gt;I think this is a smart play, regardless of some of the rough reviews of both the Surface &lt;span class="caps"&gt;RT&lt;/span&gt; and Windows 8. Version 1 has some awkward transitions on both devices, but that may be worth the cost to take advantage of a near-future where the power available on a large tablet will be comparable to that of a laptop or even desktop computer. Just as the Macbook Air is every bit as good a consumer computer as &amp;#8220;the fatter&amp;#8221; laptop market, soon tablets will be every bit as good a consumer computer that exists. Microsoft&amp;#8217;s bet is that with that power will come more sophisticated and complex uses, better suited to applications at home on the desktop. They are betting the future is the past&amp;#8212; a full multitasking enabled, file-system revealing environment. If that&amp;#8217;s what users will eventually want from their tablets, Windows 8 will have these capabilities baked in from the start while iOS struggles to pump out new features and APIs to mimic (or create) these&amp;nbsp;capabilities.&lt;/p&gt;
&lt;p&gt;The future is frictionless. Apple&amp;#8217;s true advantage is they can already offer one version of that future. If Microsoft plays its cards right, and if it is not too late &lt;sup id="fnref:toolate"&gt;&lt;a class="footnote-ref" href="#fn:toolate" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;, they can offer an equally compelling alternative. It won&amp;#8217;t win over the real, dyed-in-the-wool Apple fans, but it may stem the tide carrying the consumer market swiftly&amp;nbsp;away.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:hardware"&gt;
&lt;p&gt;Hardly a given in the past from either Google (&lt;span class="caps"&gt;LG&lt;/span&gt;/&lt;span class="caps"&gt;ASUS&lt;/span&gt;) and Microsoft partners. Although Microsoft&amp;#8217;s actual hardware, until now primarily keyboards and mice (do you pluralize a computer mouse? It seems strange.)&amp;#160;&lt;a class="footnote-backref" href="#fnref:hardware" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:toolate"&gt;
&lt;p&gt;I really think it might be. Windows Phone 7 was brilliant, but released 2 years too late behind at least 1 year of development.&amp;#160;&lt;a class="footnote-backref" href="#fnref:toolate" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="Apple"></category><category term="google"></category><category term="ipad"></category><category term="microsoft"></category><category term="nexus"></category><category term="surface"></category><category term="tech"></category></entry><entry><title>Paul Cuffee Middle School, Addressing Emotional Needs</title><link href="http://blog.jsonbecker.com/2012/11/paul-cuffee-middle-school-addressing-emotional-needs.html" rel="alternate"></link><updated>2012-11-02T11:59:00-04:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-11-02:2012/11/paul-cuffee-middle-school-addressing-emotional-needs.html</id><summary type="html">&lt;p&gt;I like this piece in Slate on &lt;a href="http://www.paulcuffee.org"&gt;Paul Cuffee Middle School&lt;/a&gt;, a charter school right here in Providence. Most of what I know about child development seems to suggest that middle schools are sort of ridiculous. At the moment children are looking for role models and close relationships with adults (and not just the kids around them), we decide that kids should have many teachers, teachers should have higher loads, and the kids stay consistent while the adults change&amp;nbsp;constantly.&lt;/p&gt;
&lt;p&gt;In many ways, the elementary school model works better for middle school students and vice&amp;nbsp;versa.&lt;/p&gt;
&lt;p&gt;Anyway, some research showing K-8 schools have a built-in advantage against the traditional middle&amp;nbsp;school:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://educationnext.org/the-middle-school-plunge/"&gt;The Middle School Plunge&lt;/a&gt;
&lt;a href="http://www0.gsb.columbia.edu/faculty/jrockoff/papers/Rockoff%20Lockwood%20JPubE%202nd%20Revision%20June%202010.pdf"&gt;Stuck in the Middle&lt;/a&gt; &lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;A more &amp;#8220;popular&amp;#8221; version on Education Next &lt;a href="http://educationnext.org/stuck-in-the-middle/"&gt;here&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="charters"></category><category term="edpolicy"></category><category term="education"></category><category term="middle school"></category><category term="providence"></category><category term="rhode island"></category><category term="ri"></category></entry><entry><title>Where I Share</title><link href="http://blog.jsonbecker.com/2012/10/where-i-share.html" rel="alternate"></link><updated>2012-10-09T13:44:00-04:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-10-09:2012/10/where-i-share.html</id><summary type="html">&lt;p&gt;I have been meaning to write this post for the past couple of weeks. Like most other people, I am constantly experimenting with different ways to publish and share my thoughts and engage with social networking. Lately, I have settled into what feels like an &amp;#8220;end state&amp;#8221; workflow&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;. I will devote a future post to the details of how I manage my online reading, writing, and sharing workflow but for now I just wanted to let folks know where they can find&amp;nbsp;me.&lt;/p&gt;
&lt;p&gt;For random thoughts throughout the day I mostly turn to &lt;a href="http://www.twitter.com/#!/jasonpbecker"&gt;my Twitter account&lt;/a&gt; or increasingly &lt;a href="https://alpha.app.net/jbecker"&gt;my App.net account&lt;/a&gt;. I am a retweet abuser, so if you follow me there be warned. I often just retweet things I find funny or interesting, write some random complaint about coding, policy, or education when I&amp;#8217;m frustrated and don&amp;#8217;t understand the world, and try syndicate some of the other sources I&amp;#8217;ll list here. I also like to talk to people on Twitter, so if you&amp;#8217;re looking for conversation that&amp;#8217;s the place to go. I almost use it like it&amp;#8217;s the new &lt;span class="caps"&gt;IRC&lt;/span&gt;/&lt;span class="caps"&gt;AIM&lt;/span&gt; Chatroom. My Twitter account is a bit more Providence/Rhode Island heavy than most other ways to follow&amp;nbsp;me.&lt;/p&gt;
&lt;p&gt;Some of you may know that &lt;a href="http://tumblr.jasonpbecker.com"&gt;I also have a Tumblr&lt;/a&gt; that has fallen in and out of favor. I used to blog over there before creating this Wordpress site&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;. Recently, I have used my Tumblr account much more. Since Google Reader &lt;a href="http://techcrunch.com/2011/10/20/google-reader-getting-overhauled-removing-your-friends/"&gt;removed its social features&lt;/a&gt; I have tried to find the best way to share the best stuff I read each day with a few thoughts. I &lt;a href="https://plus.google.com/103283548915451814191/"&gt;toyed with Google Plus&lt;/a&gt;, but it really is dead. I don&amp;#8217;t find good content there and engagement with my sharing has been very low. Also, the &lt;a href="https://groups.google.com/forum/?fromgroups=#!topic/google-plus-developers/zBMOUy9pHFc"&gt;lack of a write &lt;span class="caps"&gt;API&lt;/span&gt;&lt;/a&gt; makes it very challenging to incorporate in a non-disruptive way.&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;So right now, head over and follow my Tumblr (natively or &lt;span class="caps"&gt;RSS&lt;/span&gt;) if you want to get 5-10 link posts each day of things I&amp;#8217;ve collected across the web. Some of my favorite online friends found me through my Google Reader sharing and I suspect that they would enjoy my Tumblr most of all. If I start getting more engagement around what type of links folks are enjoying I can begin to shift the topics I post on. I collect many more links than what end up in Tumblr in Google Reader and Pinboard. I have a very specific path to end up in Tumblr that leans more towards long reads and shares from friends and not what I am watching on&amp;nbsp;&lt;span class="caps"&gt;RSS&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;A few months ago I ditched my original Facebook account from 2005 and reopened &lt;a href="https://www.facebook.com/jasonpaulbecker"&gt;a fresh one&lt;/a&gt;. I did this for two reasons: 1) I had collected many friends that I was not truly in contact with. Because of the layers and layers of privacy changes that Facebook went through, it became very difficult to maintain settings I was comfortable with. I wanted to start fresh with friends and fresh with how I manage privacy. 2) Related to 1, I never used Facebook as a networking tool. To me, it was always supposed to be a way to interact and keep in touch with friends from &amp;#8220;real life&amp;#8221;. Ultimately, I didn&amp;#8217;t find that aspect of Facebook to be all that valuable. So I&amp;#8217;m trying to be a believer and use Facebook more like I use other social media&amp;#8212;  a way to tap into my &amp;#8220;interest graph&amp;#8221; and meet new people and read new things and have new conversations. You can follow me there with a few caveats. I hate using Facebook, so it is probably going to have the least content. There will still be some personal stuff as most of my friends still see Facebook as an intimate space, shocking though that may seem. Finally, I may not friend you back. Yes, the point of this account is to be more open, but Facebook still creeps me out and on any given day I may feel more or less incline to be open on&amp;nbsp;there.&lt;/p&gt;
&lt;p&gt;This blog will remain where I write longer pieces that are primarily &amp;#8220;original&amp;#8221; analysis/thoughts and less news/broadcast-like. I hope to share a lot more code and thoughts on current research in the near future now that I&amp;#8217;m changing&amp;nbsp;jobs. &lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Subject to change, but I&amp;#8217;m betting it&amp;#8217;s more tweaks at this point than dramatic shifts&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;and I really want to leave Wordpress, but that is going to be a big project&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;Definitely more on this in my future workflow post &amp;#160;&lt;a class="footnote-backref" href="#fnref:3" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="meta"></category><category term="sharing"></category><category term="social media"></category></entry><entry><title>What Can Management Do? iOS6 Maps Monday-Morning Quarterbacking</title><link href="http://blog.jsonbecker.com/2012/10/what-can-management-do-ios6-maps-monday-morning-quarterbacking.html" rel="alternate"></link><updated>2012-10-01T20:06:00-04:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-10-01:2012/10/what-can-management-do-ios6-maps-monday-morning-quarterbacking.html</id><summary type="html">&lt;p&gt;&lt;a href="https://twitter.com/philiped"&gt;Philip Elmer-DeWitt&lt;/a&gt; has &lt;a href="http://tech.fortune.cnn.com/2012/09/29/does-apple-have-a-scott-forstall-problem/"&gt;suggested&lt;/a&gt; the &lt;a href="http://theamazingios6maps.tumblr.com/"&gt;iOS6 Maps debacle&lt;/a&gt; falls on the shoulders of &lt;a href="http://en.wikipedia.org/wiki/Scott_Forstall"&gt;Scott Forstall&lt;/a&gt;&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;. When I first read the piece, I felt like it was unfair to blame management for this kind of failure. In my experience, the Maps application is wonderful software. The turn-by-turn directions are elegant and beautiful. The vector-based maps load fast and use &lt;a href="http://www.loopinsight.com/2012/10/01/apple-maps-up-to-five-times-more-data-efficient-than-google-maps/"&gt;substantially less data&lt;/a&gt;. The reality is the Map app is great; the data are less&amp;nbsp;so.&lt;/p&gt;
&lt;p&gt;Building great mapping data is no easy task. It takes years. &lt;a href="http://www.theatlantic.com/technology/archive/2012/09/how-google-builds-its-maps-and-what-it-means-for-the-future-of-everything/261913/"&gt;It takes human intervention&lt;/a&gt;. It takes users. Short of a massive acquisition of an existing player, like Garmin, there was little hope of Apple developing a great map application for day one of release. Hell, in my experience, most stand alone &lt;span class="caps"&gt;GPS&lt;/span&gt; data is pretty awful in all the ways the Apple data is awful. That&amp;#8217;s why I primarily used my iPhone as my &lt;span class="caps"&gt;GPS&lt;/span&gt; the last few years. The experience was consistently better and less frustrating. Perhaps even more critically, Apple is just not a data company. Google is the king of data. The skills required to build great geographic data simply doesn&amp;#8217;t map well against previous Apple competencies. None of this means that the Apple Map situation is good or even &amp;#8220;excusable&amp;#8221;. I just think the map situation is &amp;#8220;understandable&amp;#8221; and would not be with different&amp;nbsp;guidance.&lt;/p&gt;
&lt;p&gt;But then I reevaluated and realized that there is a major way that management could have improved Apple Maps for iOS. Managers should set the bar for quality, make sure that bar is met, and adjust both resources and expectations when a project is not meeting user expectations. It must have been obvious to Apple management that the quality expectations were not going to be&amp;nbsp;met.&lt;/p&gt;
&lt;p&gt;What could Forstall have done? Some have suggested thrown substantially more money at the project. Others say he should have &amp;#8220;&lt;a href="http://www.mondaynote.com/2012/09/23/apple-maps/"&gt;winked&lt;/a&gt;&amp;#8221; at Apple users and clearly signaled that Maps were in their infancy. And of course there were those who said he should have waited another year for the Google Maps contract to expire. John Gruber is &lt;a href="http://daringfireball.net/2012/09/timing_of_apples_map_switch"&gt;rather convincing&lt;/a&gt; that simply waiting another year was not an option. Apple really couldn&amp;#8217;t swap maps out of iOS in the middle of the &lt;span class="caps"&gt;OS&lt;/span&gt; cycle. It would be jarring and far more frustrating than the current&amp;nbsp;situation.&lt;/p&gt;
&lt;p&gt;I would have recommended a third&amp;nbsp;option.&lt;/p&gt;
&lt;p&gt;Apple should have released iOS6 Maps as &lt;span class="caps"&gt;US&lt;/span&gt;&amp;nbsp;only.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;@&lt;a href="https://twitter.com/jdalrymple"&gt;jdalrymple&lt;/a&gt; what if Apple execs realized it wasn&amp;#8217;t going well &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt;
made maps &lt;span class="caps"&gt;US&lt;/span&gt; only &lt;span class="amp"&gt;&amp;amp;&lt;/span&gt; world in 6-12mo. Still had Google contract time
for&amp;nbsp;that&lt;/p&gt;
&lt;p&gt;— Jason Becker (@jasonpbecker) &lt;a href="https://twitter.com/jasonpbecker/status/252128849469526017"&gt;September 29,&amp;nbsp;2012&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;One of the major themes of the iPhone 5 release was that this was a global phone. Global &lt;span class="caps"&gt;LTE&lt;/span&gt;, with day one [launches in more countries and reaches far more countries, faster, than ever before after that][]. In fact, the Verizon &lt;span class="caps"&gt;CDMA&lt;/span&gt; iPhone comes with an &lt;a href="http://www.theverge.com/2012/9/25/3405610/verizon-iphone-5-unlocked-open-access-fcc"&gt;unlocked &lt;span class="caps"&gt;GSM&lt;/span&gt; radio&lt;/a&gt;. But mapping is hard, and that problem becomes orders of magnitude more difficult with each inch of the planet that needs to be covered. When it became clear that Apple had a beautiful application, but awful data, Forstall and the rest of Apple management should have adjusted expectations and promised a &lt;span class="caps"&gt;US&lt;/span&gt;-only release that met the quality that consumers have come to expect. This would serve to increase resources, while winking at users, and utilizing the remainder of the Google contract for international mapping. With six additional months Apple could make great strides improving international data and possibly signing some additional, high-profile maps data deals with local sources/competitors that would love to be associated with Apple, even if it is just in a footnote. &lt;span class="caps"&gt;US&lt;/span&gt; users would rave about the great vector mapping, the turn by turn directions that are brilliantly integrated into the lock screen and always provide just enough information, and the cool integration into Open Table and Yelp. &lt;span class="caps"&gt;US&lt;/span&gt; maps would get better because they would have constant users. The rest of the world would lap up iPhone 5s and wait anxiously for their chance to taste the Great Apple&amp;nbsp;Maps.&lt;/p&gt;
&lt;p&gt;In this scenario, it is possible that Apple could have had the best of both worlds: a far worse data set in an application that cost just as much, but by limiting the scope to their key market, a reputation for excellence that would lead to excitement for the end of a competitor&amp;#8217;s&amp;nbsp;product.&lt;/p&gt;
&lt;p&gt;I am sure there were other challenges with producing a &lt;span class="caps"&gt;US&lt;/span&gt;-only&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;that I am not considering. I think this is at least one typical techniques in &lt;span class="caps"&gt;IT&lt;/span&gt; management that Apple could have employed for a smoother, better release of their first efforts into a complicated and competitive&amp;nbsp;space.&lt;/p&gt;
&lt;p&gt;[launches in more countries and reaches far more countries, faster,
than ever before after that]:&amp;nbsp;http://appleinsider.com/articles/12/09/13/apples_aggressive_iphone_5_launch_schedule_to_reach_31_countries_in_sept_quarter&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Of &lt;a href="http://www.fastcodesign.com/1670760/will-apples-tacky-software-design-philosophy-cause-a-revolt"&gt;iOS skeumorphism fame&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;Or North America only. There are barely any roads in Canada, right? &amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="Apple"></category><category term="forstall"></category><category term="ios6"></category><category term="management"></category><category term="maps"></category><category term="technology"></category></entry><entry><title>Thoughts on Grit</title><link href="http://blog.jsonbecker.com/2012/10/thoughts-on-grit.html" rel="alternate"></link><updated>2012-10-01T09:45:00-04:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-10-01:2012/10/thoughts-on-grit.html</id><summary type="html">&lt;p&gt;I have not had the opportunity to read &lt;a href="http://www.paultough.com/the-books/how-children-succeed/"&gt;Paul Tough&amp;#8217;s newest book&lt;/a&gt; on &amp;#8220;grit&amp;#8221;&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;. I have, however, read Paul Tough&amp;#8217;s &lt;a href="http://www.nytimes.com/2011/09/18/magazine/what-if-the-secret-to-success-is-failure.html"&gt;New York Times Magazine article on grit&lt;/a&gt; and recently listened to an &lt;a href="http://www.econtalk.org/archives/2012/09/paul_tough_on_h.html"&gt;EconTalk podcast&lt;/a&gt; where he discussed &lt;span style="text-decoration: underline;"&gt;How Children Succeed&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;The thrust of Tough&amp;#8217;s argument, if I were to be so bold, is that there is a definable set of non-cognitive skills, called &amp;#8220;grit&amp;#8221;, that are at least as important as academic achievement in determining long-term positive outcomes for kids. Great schools, therefore, would do well to focus on developing these habits as much and as intentionally as they do developing content knowledge and academic prowess. This, according to Tough, is a big part of the &amp;#8220;magic sauce&amp;#8221;&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;of &amp;#8220;No Excuses&amp;#8221; schools like &lt;span class="caps"&gt;KIPP&lt;/span&gt;. They teach &amp;#8220;grit&amp;#8221; as a part of their intense behavioral management and culture&amp;nbsp;efforts.&lt;/p&gt;
&lt;p&gt;I think Tough is an engaging writer and has a great knack for finding some of the most interesting research not often read in education policy circles, but which is clearly relevant. While listening to the EconLog podcast I found myself often disagreeing with his interpretations/conclusions. But more often, I found myself desperately wishing for a different, slower format because so much of this work begged deeper questioning and conversation. What better reason could there be to buy and read a book-length treatment of these&amp;nbsp;ideas?&lt;/p&gt;
&lt;p&gt;Anyway, I thought I&amp;#8217;d share just a few of my thoughts on &amp;#8220;grit&amp;#8221; based on this interview and the earlier New York Times Magazine&amp;nbsp;piece.&lt;/p&gt;
&lt;h2&gt;Teaching conscientiousness in a society that has been so&amp;nbsp;unconscientious&lt;/h2&gt;
&lt;p&gt;It seems fairly obvious that people who don&amp;#8217;t &amp;#8220;play by the rules&amp;#8221; and aren&amp;#8217;t easily motivated to conform to certain habits are less likely to be successful. It is unsurprising that Tough finds research that suggests that there is a &amp;#8220;grit&amp;#8221; gap between rich and poor. I want to know more about why, and I have, what I hope, is one interesting idea of what contributes to the &amp;#8220;grit&amp;nbsp;gap&amp;#8221;.&lt;/p&gt;
&lt;p&gt;I believe that deterioration of the built environment, especially among the urban and truly rural poor, is a major contributor to low grit. Some parts of this country with high concentrations of poverty look&amp;#8212; bombed out. Roads are littered with deep potholes and scars. The houses have chipped paint, rotting wood exterior elements, and unkept yards. Storefronts were built decades ago on the cheap, aged poorly, and were never updated. Their schools lack good lighting, decent &lt;span class="caps"&gt;HVAC&lt;/span&gt; systems, and functioning toilets. There is no pride found in any of these&amp;nbsp;spaces.&lt;/p&gt;
&lt;p&gt;Children growing up in poverty do not see neighbors obsessing over their lawn. They do not watch one house after another repaint and reface their exteriors to ensure they weren&amp;#8217;t the ugliest house on the block. They do not see brand new cars, fresh asphalt roads, and schools that resemble palaces. I don&amp;#8217;t think virtually any of this has to do with the people who live in these neighborhoods. I do think it reflects the pathetic state that society has deemed acceptable, so long as it remains sight unseen by those with&amp;nbsp;resources.&lt;/p&gt;
&lt;p&gt;Growing up in poverty often means being surrounded by spaces that society has left to rot. How can these children learn conscientiousness when the privileged have been so&amp;nbsp;unconscientious?&lt;/p&gt;
&lt;h2&gt;The M&amp;amp;M&amp;nbsp;Study&lt;/h2&gt;
&lt;p&gt;Tough mentions &lt;a href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1310767/"&gt;a study&lt;/a&gt; where students first take an &lt;span class="caps"&gt;IQ&lt;/span&gt; test under normal conditions. These same students are then given an &lt;span class="caps"&gt;IQ&lt;/span&gt; test but are rewarded with an M&amp;amp;M each time they get a question right. This tiny immediate incentive resulted in a massive, 1.&lt;span class="caps"&gt;8SD&lt;/span&gt; improvement in mean &lt;span class="caps"&gt;IQ&lt;/span&gt;. &lt;sup id="fnref:0"&gt;&lt;a class="footnote-ref" href="#fn:0" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; The implications are fascinating. It demonstrates the importance of motivation even while taking a test that is supposedly measuring an intractable, permanent attribute people have. This seems obvious and is fairly well known, but forgotten in many policy circles. I have often lamented that the New England Common Assessment Program has a sizable downward bias when measuring achievement because the exam is low stakes for students. The dramatic decrease in performance observed on the 11th grade &lt;span class="caps"&gt;NECAP&lt;/span&gt; math exam is almost certainly in part due to lower intrinsic motivation amongst high school students compared to their 8th grade and younger&amp;nbsp;selves.&lt;/p&gt;
&lt;p&gt;There are some students that have no measurable response to the M&amp;amp;M incentive. These students are exhibiting qualities of Tough&amp;#8217;s &amp;#8220;grit&amp;#8221;, conscientiousness that leads one to do well simply because they are being measured, or perhaps because there is no reason to do something if it is not going to be done well. I believe that there is also a bias against schools with concentrated poverty because of an uneven distribution of &amp;#8220;grit&amp;#8221;&amp;#8212; suburban middle to upper class students with college ambitions will likely be the students who will sit down and try hard on a test just because they are being measured whereas urban students living in poverty are far less likely to exert that same effort for an exercise with no immediate or clear long-term&amp;nbsp;consequences.&lt;/p&gt;
&lt;p&gt;All of this would be pretty blasé were it not for the more distal outcomes observed. The group of students that did not respond to the M&amp;amp;M incentives had significantly and practically better outcomes than those that responded to the incentive. I can&amp;#8217;t recall exactly which outcomes were a part of this study, but Tough cites several independent studies that measure a similar set of qualities and find far better outcomes with &lt;span class="caps"&gt;GPA&lt;/span&gt;, graduation from high school, post-secondary degree attainment, juvenile delinquency or adult criminal activity, and&amp;nbsp;wages.&lt;/p&gt;
&lt;p&gt;Tough&amp;#8217;s interpretation of these results seems to &lt;a href="http://blog.jasonpbecker.com/2012/09/19/thoughts-on-grading/"&gt;mirror my feelings on grading&lt;/a&gt;. Low stakes testing (or in this case, no-incentive testing) has omitted variable bias which leads to observing students who lack &amp;#8220;grit&amp;#8221; as lower achieving than they are. The test results are still excellent predictors of later success but lack validity as a pure measure of academic achievement. My complaint about grades that use behavior, attendance, and participation&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3" rel="footnote"&gt;4&lt;/a&gt;&lt;/sup&gt;does not stem from their lack of validity at predicting later outcomes. These grades are excellent predictors of later outcomes. Rather, it stems from these grade conflating two very different qualities into a single measure, making it far more difficult to design appropriate interventions and supports that target individual&amp;nbsp;needs.&lt;/p&gt;
&lt;p&gt;Tough seems thinks this means that high stakes placed on test scores over emphasizes one quality over the other when both are very important. I disagree. I feel that high stakes test scores recreate the M&amp;amp;M incentive and leads to a better measure of academic ability. That is not to say that we don&amp;#8217;t need to cultivate and measure non-cognitive skills. It just means that trying to measure both at once&lt;sup id="fnref:4"&gt;&lt;a class="footnote-ref" href="#fn:4" rel="footnote"&gt;5&lt;/a&gt;&lt;/sup&gt;results in less clear and actionable&amp;nbsp;interpretations.&lt;/p&gt;
&lt;h2&gt;Is the &amp;#8220;grit&amp;#8221; problem properly described as a failure to recognize long-term&amp;nbsp;benefits?&lt;/h2&gt;
&lt;p&gt;Repeatedly both Tough and host Russ Roberts point to the need to provide students who lack grit more information on the long-term benefits of &amp;#8220;doing well&amp;#8221;. For example, Tough cites &lt;span class="caps"&gt;KIPP&lt;/span&gt;&amp;#8217;s posting of the economic benefits of a bachelor&amp;#8217;s degree on walls in the halls of their schools as a way to build grit. Somewhat left unsaid is the idea that grit-like behaviors may not describe some kind of &amp;#8220;intrinsic&amp;#8221; motivation, but instead represent an understanding of the long-term extrinsic benefits of certain actions. Grit really means understanding that, &amp;#8220;If I behave appropriately, I will gain the respect of this authority and earn greater autonomy/responsibility,&amp;#8221; or perhaps, &amp;#8220;Doing my homework each night will teach me good habits of work and help me to learn this academic material so I can succeed in college and get a better&amp;nbsp;job.&amp;#8221;&lt;/p&gt;
&lt;p&gt;Can grit really be just a heuristic developed to better respond to long-term&amp;nbsp;incentives?&lt;/p&gt;
&lt;p&gt;I am not sure. I am equally unsure that the activities of a &amp;#8220;No Excuses&amp;#8221; school actually generate the long-term benefits of &amp;#8220;grit&amp;#8221;. If grit is a powerful heuristic to optimize long-term outcomes, how do we know that many short-term incentives that build behaviors toward academic success mean that students better respond to a broad set of long-term outcomes? Should we believe that behavior bucks/demerit systems, constant small corrections, repeatedly stating the goals of education and its benefits, and other &lt;span class="caps"&gt;KIPP&lt;/span&gt;-like culture-building strategies build a bend toward acting in ways that maximize long-term outcomes? Do students aspire to college because they have internalized its importance, or do the stack of short-term incentives build a desire for sprokets, wignuts, and widgets that just happened to be called a &amp;#8220;bachelor&amp;#8217;s degree&amp;#8221; in this&amp;nbsp;case?&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:0"&gt;
&lt;p&gt;From 79 to 97 according to EconTalk&amp;#160;&lt;a class="footnote-backref" href="#fnref:0" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;I use &amp;#8220;grit&amp;#8221; a lot in this post. Please insert quotes each time. It got obnoxious reading it with the quotes actually in place&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;My term, not his. Probably stolen from one of my colleagues who uses this term a lot. &amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;among other non-cognitive, non-academic skills and activities&amp;#160;&lt;a class="footnote-backref" href="#fnref:3" rev="footnote" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:4"&gt;
&lt;p&gt;Or inadvertently measuring both at once, as many low-stakes standardized tests do&amp;#160;&lt;a class="footnote-backref" href="#fnref:4" rev="footnote" title="Jump back to footnote 5 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="education"></category><category term="education policy"></category><category term="education reform"></category><category term="grit"></category><category term="paul tough"></category><category term="standardized tests"></category><category term="urban development"></category></entry><entry><title>Thoughts on Grading</title><link href="http://blog.jsonbecker.com/2012/09/thoughts-on-grading.html" rel="alternate"></link><updated>2012-09-19T09:05:00-04:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-09-19:2012/09/thoughts-on-grading.html</id><summary type="html">&lt;p&gt;&lt;a href="http://www.twitter.com/MrPABruno"&gt;Bruno&lt;/a&gt; is a skeptic on &lt;a href="http://scholasticadministrator.typepad.com/thisweekineducation/2012/09/bruno-is-standards-based-grading-a-good-idea.html"&gt;standards-based grading&lt;/a&gt;. He seems to think
that &amp;#8220;mastery of content&amp;#8221; is too abstract for students to work toward
and rightly cites evidence that motivation and changed behavior are
tightly linked to a sense of efficacy, which in turn is tightly linked
to feeling as though you know precisely what to do to get to a
particular&amp;nbsp;outcome.&lt;/p&gt;
&lt;p&gt;But isn&amp;#8217;t mastery of content essentially, &amp;#8220;Do well on your assignments
and tests&amp;#8221;? And while a massive, standards-based report card may be hard
for a parent to read, is it any more confusing than seeing awful results
on standardized tests and a student who clearly doesn&amp;#8217;t read on
grade-level receive good grades because of participation, attendance,
and behavior? As a parent, how do you know to intercede on your child&amp;#8217;s
behalf when you see a &amp;#8220;B&amp;#8221; which actually represents a C- on content
knowledge and skills and an A+ for effort, behavior, and&amp;nbsp;completion?&lt;/p&gt;
&lt;p&gt;Ultimately, I am against including behavior, attendance, and effort as a
part of the same grade as academics. I think there needs to be a clear
place to present evidence of academic ability and growth independent of
behavioral growth. Both are important, and while linked, are certainly
not moving in lockstep for the typical child. Accurate information in
both domains is far better than falsely presenting a singular, mixed-up
&amp;#8220;truth&amp;#8221; about a child&amp;#8217;s success in&amp;nbsp;school.&lt;/p&gt;
&lt;p&gt;For the same reason I am not a fan of school report cards with a single
letter grade rating, I am not for just a single letter grade for
students. Ultimately, they both represent poor combinations of data that
obscure more than they&amp;nbsp;reveal.&lt;/p&gt;
&lt;p&gt;Developing report cards or &amp;#8220;grading&amp;#8221; systems, both for program
evaluation and for students, always conjures one of the few concepts I
recall from linear algebra. It seems to me that any good grading system
should provide a basis, that is, a minimal set of linearly independent
vectors which, via linear combination, can describe an entire vector
space. Remove the jargon and you&amp;#8217;re left&amp;nbsp;with:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Measure the least amount of unrelated things possible that, taken
together, describe all there is to know about what you are&amp;nbsp;measuring.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;A single grade that combines all the effort, behavior, attendance, and
various unrelated academic standards I might get an overall description
that says &amp;#8220;round&amp;#8221;. But by separating out the data at some other level,
the picture might describe a golf ball and its dimples, a baseball and
its stitches, or a soccer ball with its hexagon-pentagon&amp;nbsp;pattern.&lt;/p&gt;
&lt;p&gt;I think we need to find a way to let people know what kind of ball they&amp;nbsp;have.&lt;/p&gt;</summary><category term="bruno"></category><category term="education"></category><category term="grading"></category><category term="grading policy"></category><category term="twie"></category></entry><entry><title>There must be an easier way… survey questions in R</title><link href="http://blog.jsonbecker.com/2012/08/there-must-be-an-easier-way-survey-questions-in-r.html" rel="alternate"></link><updated>2012-08-22T09:55:00-04:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-08-22:2012/08/there-must-be-an-easier-way-survey-questions-in-r.html</id><summary type="html">&lt;p&gt;So I have this great little custom function I&amp;#8217;ve used when looking at survey data in R. I call this function &lt;code&gt;pull()&lt;/code&gt;. The goal of &lt;code&gt;pull()&lt;/code&gt; is to quickly produce frequency tables with n sizes from individual-level survey&amp;nbsp;data.&lt;/p&gt;
&lt;p&gt;Before using &lt;code&gt;pull()&lt;/code&gt;, I create a big table that includes information about the survey questions I want to pull. The data are structured like&amp;nbsp;this:&lt;/p&gt;
&lt;table align="center"&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;tbody&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td&gt;
quest

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td&gt;
survey

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td&gt;
year

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td&gt;
break

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;/tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td&gt;
ss01985

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td&gt;
elementary

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td&gt;
2011\_12

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td&gt;
schoolcode

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;/tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;/tbody&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;/table&gt;

&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;quest represents the question coding in the raw survey&amp;nbsp;data.&lt;/li&gt;
&lt;li&gt;survey is the name of the survey (in my case, the elementary school students, middle school students, high school students, parents, teachers, or&amp;nbsp;administrators).&lt;/li&gt;
&lt;li&gt;year is the year that the survey data are&amp;nbsp;collected.&lt;/li&gt;
&lt;li&gt;break is the &lt;span class="caps"&gt;ID&lt;/span&gt; I want to aggregate on like schoolcode or&amp;nbsp;districtcode.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;They key is that &lt;code&gt;paste(survey, year,sep='')&lt;/code&gt; produces the name of the &lt;code&gt;data.frame&lt;/code&gt; where I store the relevant survey data. Both quest and break are columns in the survey data.frame. Using a data.frame with this data allows me to apply through the rows and produce the table for all the relevant questions at once. &lt;code&gt;pull()&lt;/code&gt; does the work of taking one row of this &lt;code&gt;data.frame&lt;/code&gt; and producing the output that I&amp;#8217;m looking for. I also use &lt;code&gt;pull()&lt;/code&gt; one row at a time to save a data.frame that contains these data and do other things (like the visualizations in this&amp;nbsp;post).&lt;/p&gt;
&lt;p&gt;In some sense, &lt;code&gt;pull()&lt;/code&gt; is really just a fancy version of &lt;code&gt;prop.table&lt;/code&gt; that takes in passed paramaters and adds an &amp;#8220;n&amp;#8221; to each row and adding a &amp;#8220;total&amp;#8221; row. I feel as though there must be an implementation of an equivalent function in a popular package (or maybe even base) that I should be using rather than this technique. It would probably be more maintainable and easier for collaborators to work with this more common implementation, but I have no idea where to find it. So, please feel free to use the code below, but I&amp;#8217;m actually hoping that someone will chime in and tell me I&amp;#8217;ve wasted my time and I should just be using some function&amp;nbsp;foo::bar.&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;P.S.&lt;/span&gt; This post is a great example of why I really need to change this blog to Markdown/R-flavored Markdown. All those inline references to functions, variables, or code should really be formatted in-line which the syntax highlighter plug-in used on this blog does not support. I&amp;#8217;m nervous that using &lt;span class="caps"&gt;WP&lt;/span&gt;-Markdown plugin will botch formatting on older posts, so I may just need to setup a workflow where I pump out &lt;span class="caps"&gt;HTML&lt;/span&gt; from the Markdown and upload the posts from there. If anyone has experience with Markdown + Wordpress, advice is&amp;nbsp;appreciated.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;pull &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;rows&lt;span class="p"&gt;){&lt;/span&gt;
  &lt;span class="c1"&gt;# Takes in a vector with all the information required to create crosstab with&lt;/span&gt;
  &lt;span class="c1"&gt;# percentages for a specific question for all schools.&lt;/span&gt;
  &lt;span class="c1"&gt;# Args:&lt;/span&gt;
  &lt;span class="c1"&gt;#  rows: Consists of a vector with four objects.&lt;/span&gt;
  &lt;span class="c1"&gt;#        quest: the question code from SurveyWorks&lt;/span&gt;
  &lt;span class="c1"&gt;#        level: the &amp;quot;level&amp;quot; of the survey, i.e.: elem, midd, high, teac, admn,&lt;/span&gt;
  &lt;span class="c1"&gt;#        pare, etc.&lt;/span&gt;
  &lt;span class="c1"&gt;#        year: the year the survey was administered, i.e. 2011_12&lt;/span&gt;
  &lt;span class="c1"&gt;#        sch_lea: the &amp;quot;break&amp;quot; indicator, i.e. schoolcode, districtcode, etc.&lt;/span&gt;
  &lt;span class="c1"&gt;# Returns:&lt;/span&gt;
  &lt;span class="c1"&gt;# A data.frame with a row for each &amp;quot;break&amp;quot;, i.e. school, attributes for&lt;/span&gt;
  &lt;span class="c1"&gt;# each possible answer to quest, i.e. Agree and Disagree, and N size for each&lt;/span&gt;
  &lt;span class="c1"&gt;# break based on how many people responded to that question, not the survey as&lt;/span&gt;
  &lt;span class="c1"&gt;# a whole, i.e.&lt;/span&gt;

  &lt;span class="c1"&gt;# Break each component of the vector rows into separate single-element vectors&lt;/span&gt;
  &lt;span class="c1"&gt;# for convenience and clarity.&lt;/span&gt;
  quest &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; as.character&lt;span class="p"&gt;(&lt;/span&gt;rows&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
  survey &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; as.character&lt;span class="p"&gt;(&lt;/span&gt;rows&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
  year  &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; as.character&lt;span class="p"&gt;(&lt;/span&gt;rows&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
  &lt;span class="kr"&gt;break&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; as.character&lt;span class="p"&gt;(&lt;/span&gt;rows&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
  data &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; get&lt;span class="p"&gt;(&lt;/span&gt;paste&lt;span class="p"&gt;(&lt;/span&gt;level&lt;span class="p"&gt;,&lt;/span&gt;year&lt;span class="p"&gt;,&lt;/span&gt;sep&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="c1"&gt;# Data is an alias for the data.frame described by level and year.&lt;/span&gt;
  &lt;span class="c1"&gt;# This alias reduces the number of &amp;quot;get&amp;quot; calls to speed up code and increase&lt;/span&gt;
  &lt;span class="c1"&gt;# clarity.&lt;/span&gt;
  results &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; with&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="p"&gt;,&lt;/span&gt;
                  dcast&lt;span class="p"&gt;(&lt;/span&gt;data.frame&lt;span class="p"&gt;(&lt;/span&gt;prop.table&lt;span class="p"&gt;(&lt;/span&gt;table&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="kr"&gt;break&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt;
                                                    data&lt;span class="p"&gt;[[&lt;/span&gt;quest&lt;span class="p"&gt;]]),&lt;/span&gt;
                                              &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
                        &lt;span class="p"&gt;,&lt;/span&gt;Var1&lt;span class="o"&gt;~&lt;/span&gt;Var2&lt;span class="p"&gt;,&lt;/span&gt;value.var&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Freq&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="c1"&gt;# Produces a table with the proportions for each response in wide format.&lt;/span&gt;
  n &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; data.frame&lt;span class="p"&gt;(&lt;/span&gt;Var1&lt;span class="o"&gt;=&lt;/span&gt;rle&lt;span class="p"&gt;(&lt;/span&gt;sort&lt;span class="p"&gt;(&lt;/span&gt;
    subset&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="p"&gt;,&lt;/span&gt; 
           is.na&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="p"&gt;[[&lt;/span&gt;quest&lt;span class="p"&gt;]])&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="k-Variable"&gt;F&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; is.na&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="kr"&gt;break&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="k-Variable"&gt;F&lt;/span&gt;&lt;span class="p"&gt;)[[&lt;/span&gt;&lt;span class="kr"&gt;break&lt;/span&gt;&lt;span class="p"&gt;]]))&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;values&lt;span class="p"&gt;,&lt;/span&gt;
                  n&lt;span class="o"&gt;=&lt;/span&gt;rle&lt;span class="p"&gt;(&lt;/span&gt;sort&lt;span class="p"&gt;(&lt;/span&gt;
                    subset&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="p"&gt;,&lt;/span&gt;
                           is.na&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="p"&gt;[[&lt;/span&gt;quest&lt;span class="p"&gt;]])&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="k-Variable"&gt;F&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt;
                             is.na&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="kr"&gt;break&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="k-Variable"&gt;F&lt;/span&gt;&lt;span class="p"&gt;)[[&lt;/span&gt;&lt;span class="kr"&gt;break&lt;/span&gt;&lt;span class="p"&gt;]]))&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;lengths&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="c1"&gt;# Generates a data frame with each break element and the &amp;quot;length&amp;quot; of that break&lt;/span&gt;
  &lt;span class="c1"&gt;# element. rle counts the occurrences of a value in a vector in order. So first&lt;/span&gt;
  &lt;span class="c1"&gt;# you sort the vector so all common break values are adjacent then you use rle&lt;/span&gt;
  &lt;span class="c1"&gt;# to count their uninterupted appearance. The result is an rle object with &lt;/span&gt;
  &lt;span class="c1"&gt;# two components: [[values]] which represent the values in the original, sorted&lt;/span&gt;
  &lt;span class="c1"&gt;# vector and [[length]] which is the count of their uninterupted repeated&lt;/span&gt;
  &lt;span class="c1"&gt;# appearance in that vector.&lt;/span&gt;
  results &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; merge&lt;span class="p"&gt;(&lt;/span&gt;results&lt;span class="p"&gt;,&lt;/span&gt; n&lt;span class="p"&gt;,&lt;/span&gt; by&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Var1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="c1"&gt;# Combines N values with the results table.&lt;/span&gt;

  state &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; data.frame&lt;span class="p"&gt;(&lt;/span&gt;t&lt;span class="p"&gt;(&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;Var1&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Rhode Island&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                          prop.table&lt;span class="p"&gt;(&lt;/span&gt;table&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="p"&gt;[[&lt;/span&gt;quest&lt;span class="p"&gt;]])),&lt;/span&gt;
                          n&lt;span class="o"&gt;=&lt;/span&gt;dim&lt;span class="p"&gt;(&lt;/span&gt;subset&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="p"&gt;,&lt;/span&gt;is.na&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="p"&gt;[[&lt;/span&gt;quest&lt;span class="p"&gt;]])&lt;/span&gt;&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="k-Variable"&gt;F&lt;/span&gt;&lt;span class="p"&gt;))[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])))&lt;/span&gt;
  names&lt;span class="p"&gt;(&lt;/span&gt;state&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; names&lt;span class="p"&gt;(&lt;/span&gt;results&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="kr"&gt;for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;i &lt;span class="kr"&gt;in&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;dim&lt;span class="p"&gt;(&lt;/span&gt;state&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]){&lt;/span&gt;
    state&lt;span class="p"&gt;[,&lt;/span&gt;i&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; as.numeric&lt;span class="p"&gt;(&lt;/span&gt;as.character&lt;span class="p"&gt;(&lt;/span&gt;state&lt;span class="p"&gt;[,&lt;/span&gt;i&lt;span class="p"&gt;]))&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="c1"&gt;# Because the state data.frame has only one row, R coerces to type factor.&lt;/span&gt;
  &lt;span class="c1"&gt;# If I rbind() a factor to a numeric attribute, R will coerce them both to&lt;/span&gt;
  &lt;span class="c1"&gt;# characters and refuses to convert back to type numeric.&lt;/span&gt;
  results &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; rbind&lt;span class="p"&gt;(&lt;/span&gt;results&lt;span class="p"&gt;,&lt;/span&gt; state&lt;span class="p"&gt;)&lt;/span&gt;
  results
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="code"></category><category term="markdown"></category><category term="r"></category><category term="rstats"></category><category term="survey"></category></entry><entry><title>Pay For Quality: Join App.net</title><link href="http://blog.jsonbecker.com/2012/08/pay-for-quality-join-appnet.html" rel="alternate"></link><updated>2012-08-06T10:00:00-04:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-08-06:2012/08/pay-for-quality-join-appnet.html</id><summary type="html">&lt;p&gt;I like paying for good software. There are applications I use every day, some for hours a day, that make my experience on the web and on my computers better. I have paid for &lt;a href="http://reederapp.com/"&gt;Reeder&lt;/a&gt; on three platforms, &lt;a href="http://tapbots.com/software/tweetbot/"&gt;Tweetbot&lt;/a&gt; on two&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;, &lt;a href="http://pinboard.in"&gt;Pinboard&lt;/a&gt;, and many others. I like to pay, because I value my time, my experience, and my&amp;nbsp;productivity.&lt;/p&gt;
&lt;p&gt;I also like to pay because I value my&amp;nbsp;privacy.&lt;/p&gt;
&lt;p&gt;Don&amp;#8217;t get me wrong&amp;#8212; I am a Google addict, using Gmail practically from the beginning, GChat, Google Calendar, &lt;a href="https://plus.google.com/103283548915451814191/about"&gt;Google+&lt;/a&gt;, Google Reader, etc, etc. I have a &lt;a href="https://www.facebook.com/jasonpaulbecker"&gt;Facebook account&lt;/a&gt; (although I recently removed my original account from 2005). I spent quite a bit of time on &lt;a href="http://www.twitter.com/#!/jasonpbecker"&gt;Twitter&lt;/a&gt;. These are g are reat places to do great work and to have a lot of fun. They are key parts of my professional and personal life. All of these services, however, built around the model of selling &lt;em&gt;me&lt;/em&gt;. They offer a real modern day example of &lt;a href="http://en.wikipedia.org/wiki/There_ain't_no_such_thing_as_a_free_lunch"&gt;&lt;span class="caps"&gt;TANSTAAFL&lt;/span&gt;&lt;/a&gt;. Nothing leaves my pocket, but massive hoards of data are used to direct advertising my way and some of that data is even sold to other companies. Knowing your customers has always been valuable, and the price of &amp;#8220;free&amp;#8221; is my very&amp;nbsp;identity.&lt;/p&gt;
&lt;p&gt;Now, generally I think that these major companies are good stewards of my privacy. As a &lt;a href="http://www.linkedin.com/pub/jason-becker/20/94a/80a"&gt;budding data professional&lt;/a&gt;, I know just how difficult and meaningless it would be for any of these companies to truly target &lt;em&gt;me&lt;/em&gt; rather than learn about a cloud of millions people moving at once. I also believe they realize how much of their business model requires trust. Without trust, giving up our privacy will feel like an increasingly large&amp;nbsp;ask.&lt;/p&gt;
&lt;p&gt;I value my privacy, but I value good software as well. Right now, I have not found alternatives for many &amp;#8220;free&amp;#8221; services that are good enough to make up for the cost of my privacy. I am a willing participant in selling my privacy, because I feel I get more value back than I am&amp;nbsp;losing.&lt;/p&gt;
&lt;p&gt;But, privacy is not the only reason I wish there were alternative services and software I could&amp;nbsp;buy.&lt;/p&gt;
&lt;p&gt;I was probably pretty sloppy in this post interchanging &amp;#8220;software&amp;#8221; and &amp;#8220;services&amp;#8221;. Many of the websites or software I mentioned are merely front ends for a more valuable service. Gmail is not the same thing as email. Reeder is actually a software alternative (and more) to Google Reader&amp;#8217;s web-based front end for a &lt;a href="http://en.wikipedia.org/wiki/News_aggregator"&gt;news aggregator&lt;/a&gt;. GChat is just a &lt;a href="http://www.jabber.org/"&gt;Jabber&lt;/a&gt;/&lt;a href="http://xmpp.org/"&gt;&lt;span class="caps"&gt;XMPP&lt;/span&gt;&lt;/a&gt; client. Ultimately, much of what I do around the internet is about moving structured data around between peers and producer-consumer relationships. All of the great things that made the web possible were protocols like &lt;a href="http://en.wikipedia.org/wiki/Hypertext_Transfer_Protocol"&gt;&lt;span class="caps"&gt;HTTP&lt;/span&gt;&lt;/a&gt;, &lt;a href="http://en.wikipedia.org/wiki/Internet_protocol_suite"&gt;&lt;span class="caps"&gt;TCP&lt;/span&gt;/&lt;span class="caps"&gt;IP&lt;/span&gt;&lt;/a&gt;, etc. And the protocols of todays web are the standardized &lt;a href="http://en.wikipedia.org/wiki/Application_programming_interface"&gt;&lt;span class="caps"&gt;API&lt;/span&gt;&lt;/a&gt;s that allow programmers a way to interact with data. Great, innovative software for the web is being built that ultimately change the way we see and edit data on these services. The common analogy here is that of a utility. The &lt;span class="caps"&gt;API&lt;/span&gt; helps users tap into vast networks of pipes and interact with the flow of information in new, exciting&amp;nbsp;ways.&lt;/p&gt;
&lt;p&gt;To get a sense of how amazing new things can be done with an &lt;span class="caps"&gt;API&lt;/span&gt; look no further than &lt;a href="http://ifttt.com"&gt;&lt;span class="caps"&gt;IFTTT&lt;/span&gt;&lt;/a&gt;. It is like a masterful switching station for some of the most useful APIs on the web. Using Recipes on &lt;span class="caps"&gt;IFTTT&lt;/span&gt;, I can do something amazing like&amp;nbsp;this:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Find a really cool link from a friend on&amp;nbsp;Twitter.&lt;/li&gt;
&lt;li&gt;Save that link to Pinboard, a great bookmarking site, with tags and a description so that I can find it later&amp;nbsp;easily.&lt;/li&gt;
&lt;li&gt;Add tags to the Pinboard bookmark for the social sites I want to share on, e.g. to:twitter to:facebook to:linkedin to:tumblr, all of which are special tags that I use with the &lt;span class="caps"&gt;IFTTT&lt;/span&gt;&amp;nbsp;&lt;span class="caps"&gt;API&lt;/span&gt;.&lt;/li&gt;
&lt;li&gt;&lt;span class="caps"&gt;IFTTT&lt;/span&gt;, which is linked to my Pinboard account, looks occasionally to see any recently saved links. It finds a new link with those special tags (called&amp;nbsp;Triggers).&lt;/li&gt;
&lt;li&gt;Each of those special tags tells &lt;span class="caps"&gt;IFTTT&lt;/span&gt; to make a new post on a different social networking site sharing my link (sometimes with tags, sometimes with the description, sometimes with nothing, all of which I set up) seamlessly without any user&amp;nbsp;interaction.&lt;/li&gt;
&lt;li&gt;My cool link gets sent strategically where I want it to be sent without every leaving the site. I just clicked one button and added the right&amp;nbsp;tags.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;This kind of interaction model is impossible without agreed upon standards for sites to read and write information to one&amp;nbsp;another.&lt;/p&gt;
&lt;p&gt;The open &lt;span class="caps"&gt;API&lt;/span&gt; which made it so easy to innovate quickly from the outside&amp;#8212; Facebook&amp;#8217;s Platform, the Twitter &lt;span class="caps"&gt;API&lt;/span&gt;, etc&amp;#8212; is under a serious existential threat. The truth is, these darlings of Web 2.0 don&amp;#8217;t have a great idea about how to make money. The free web has almost entirely depended on advertising revenues to turn a profit. But how can these companies make money if I&amp;#8217;m not using their webpage or their website to get access to &lt;strong&gt;my&lt;/strong&gt;&amp;nbsp;data?&lt;/p&gt;
&lt;p&gt;Do you see the part that I slipped in there? These companies have lost site of one very important part of the equation&amp;#8212; the content was free because the users created it. Its &lt;strong&gt;our&lt;/strong&gt;&amp;nbsp;data.&lt;/p&gt;
&lt;p&gt;Twitter seems to be on the verge of removing or limiting critical portions of the their &lt;span class="caps"&gt;API&lt;/span&gt; at the expense of many developers building new ways to interact with Twitter data, and, more importantly, all of their users who have joined Twitter because it was a powerful platform, not just a fun interactive website. Their tumultuous corporate culture has landed here because they decided that the promise of big revenues for their investors is not enhanced by people accessing Twitter through unofficial channels. Facebook has made similar moves in light of its short, but disastrous history as a public&amp;nbsp;company.&lt;/p&gt;
&lt;p&gt;If things shake out the way they seem to be, the sexy startups of Web 2.0 will turn away from the openness conducive to gaining users as they mature. These sites will consolidate and limit the experience, pushing
for more page views and time on their site by making it hard to leave. They are rebuilding America Online&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;, trying to make it so that their webpage becomes synonymous with &amp;#8220;the Internet&amp;#8221; for their users. Want your ads to be worth more money? Make it hard to change the&amp;nbsp;channel.&lt;/p&gt;
&lt;p&gt;It is for this reason that I am supporting &lt;a href="http://join.app.net"&gt;App.net&lt;/a&gt;. The commitment is a little steep, until you consider how valuable these services have become. For the cost of one pretty nice meal out with my girlfriend, I am purchasing one of the best ways to communicate on the web. I am supporting a model for good software that means that user experience and needs are paramount. I am purchasing customer service because I am sick of ad companies being the customer while I am stuck as the product. I am paying for access so that there is a large competitive market vying for the best way for me to interact with my data. I am paying because I am ready, no desperate, for great consumer software and services that live and breathe to optimize my experience. I used to trust the free web for this, but their business model and their success means they don&amp;#8217;t need me as much as they need their advertisers&amp;nbsp;anymore.&lt;/p&gt;
&lt;p&gt;Please join me in supporting App.net. Even better, please join me in finding ways to buy great software to support the products make our lives more fun and our work more efficient and productive&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;This is the path to a successful Web&amp;nbsp;3.0.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;almost certainly three when they are out of alpha with their &lt;span class="caps"&gt;OSX&lt;/span&gt; application&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;Facebook, especially in my opinion&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;and please choose and support &lt;span class="caps"&gt;FOSS&lt;/span&gt; solutions with your time, labor, and/or money&amp;#160;&lt;a class="footnote-backref" href="#fnref:3" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="api"></category><category term="app.net"></category><category term="facebook"></category><category term="free"></category><category term="google readerr"></category><category term="open api"></category><category term="pinboard"></category><category term="platform"></category><category term="privacy"></category><category term="reeder"></category><category term="rss"></category><category term="tapbot"></category><category term="tweetbot"></category></entry><entry><title>Follow up to Nesi’s Notes Guest Post: Woonsocket School Funding</title><link href="http://blog.jsonbecker.com/2012/07/follow-up-to-nesis-notes-guest-post-woonsocket-school-funding.html" rel="alternate"></link><updated>2012-07-12T09:00:00-04:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-07-12:2012/07/follow-up-to-nesis-notes-guest-post-woonsocket-school-funding.html</id><summary type="html">&lt;p&gt;&lt;a href="http://www.twitter.com/#!/tednesi"&gt;Ted Nesi&lt;/a&gt; was gracious in offering me a &lt;a href="http://blogs.wpri.com/?p=62059"&gt;guest spot on his blog&lt;/a&gt;, &lt;a href="http://blogs.wpri.com/category/nesis-notes/"&gt;Nesi&amp;#8217;s Notes&lt;/a&gt; this week to discuss education funding in Woonsocket. The main conclusions of my post&amp;nbsp;are:&lt;/p&gt;
&lt;p&gt;​1. Woonsocket has not increased local funding for education over the last fifteen years despite massive increases in education expenditures in Rhode Island and&amp;nbsp;nationwide.&lt;/p&gt;
&lt;p&gt;​2. General education aid from the state has rapidly increased over the same period, demonstrating that a lack of sufficient revenue at Woonsocket Public Schools is first, if not exclusively, a local revenue&amp;nbsp;problem.&lt;/p&gt;
&lt;p&gt;I wanted to provide three additional bits of information on my personal&amp;nbsp;blog.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://blog.jsonbecker.com/2012/07/limitations-of-the-nesis-notes-analysis-and-some-additional-questions.html"&gt;First&lt;/a&gt;, I want to outline some analyses that I have not done that I think are critical to understanding education funding in Woonsocket. I will also describe more completely what conclusions cannot be drawn from
the analysis on Nesi&amp;#8217;s&amp;nbsp;Notes.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://blog.jsonbecker.com/2012/07/legal-context-can-woonsocket-successfully-sue-the-state-for-additional-aid.html"&gt;Second&lt;/a&gt;, I want to discuss the legal context of school funding in Rhode Island. This is especially interesting since Pawtucket and Woonsocket are both currently suing the state for additional funds for
the second time. I am going to review what happened the first time these communities brought their fight for education aid to the courthouse and explain why I believe this strategy will fail once&amp;nbsp;again.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://blog.jsonbecker.com/2012/07/using-the-common-core-data-on-nces.html"&gt;Third&lt;/a&gt;, I want to provide instructions on precisely how I retrieved the data and created the graphs in that post. I am a firm believer in &amp;#8220;reproducible research&amp;#8221;, so I want to be entirely transparent on my data
sources and methods. I also think that too few people are acquainted with the Common Core Data provided by the National Center for Education Statistics that I relied on exclusively for my guest blog. Hopefully these instructions will help more concerned citizens and journalists in Rhode Island use data to back up assertions about local&amp;nbsp;education.&lt;/p&gt;
&lt;p&gt;Please reserve your comments on my original posts for Nesi&amp;#8217;s Notes. I have disabled comments on this post, because I would like to keep the comments on the original analysis contained in one place. Feel free to
comment on each of the follow up&amp;nbsp;posts.&lt;/p&gt;</summary><category term="education"></category><category term="nesi's notes"></category><category term="rhode island"></category><category term="ri"></category><category term="tax policy"></category><category term="woonsocket"></category></entry><entry><title>Legal Context: Can Woonsocket Successfully Sue the State for Additional Aid?</title><link href="http://blog.jsonbecker.com/2012/07/legal-context-can-woonsocket-successfully-sue-the-state-for-additional-aid.html" rel="alternate"></link><updated>2012-07-12T09:00:00-04:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-07-12:2012/07/legal-context-can-woonsocket-successfully-sue-the-state-for-additional-aid.html</id><summary type="html">&lt;p&gt;My last post ended with an important question, &amp;#8220;Who is responsible for ensuring students are receiving a certain minimum quality&amp;nbsp;education?&amp;#8221;&lt;/p&gt;
&lt;p&gt;This is my attempt at answering that&amp;nbsp;question.&lt;/p&gt;
&lt;p&gt;Does the state have a legal obligation to fiscally ensure that Woonsocket students are receiving an equitable, adequate, and meaningful education? &lt;em&gt;&lt;a href="http://www.oyez.org/cases/1970-1979/1972/1972_71_1332"&gt;San Antonio v. Rodriquez&lt;/a&gt;&lt;/em&gt;, a landmark Supreme Court case decided in 1973 determined that there was no fundamental right to education guaranteed by the &lt;span class="caps"&gt;U.S.&lt;/span&gt; Constitution. Since that decision, advocates for fairer education funding have focused their efforts in state courts arguing over provisions in state constitutions that include some rights to&amp;nbsp;education.&lt;/p&gt;
&lt;p&gt;In Rhode Island, the &lt;a href="http://www.educationjustice.org/states/rhodeisland.html"&gt;&lt;em&gt;City of Pawtucket v. Sundlun&lt;/em&gt;&lt;/a&gt; in 1995 tested &lt;a href="http://www.rilin.state.ri.us/RiConstitution/C12.html"&gt;Article &lt;span class="caps"&gt;XII&lt;/span&gt;&lt;/a&gt; of the state constitution which stated &amp;#8220;it shall be the duty of the general assembly to promote public schools&amp;#8230;&amp;#8221;. In this case, East Greenwich, Pawtucket, and Woonsocket sued the state claiming that the duty to promote public schools amounted to a guarantee of equitable, adequate education funding from the state, a burden not met by the current General Assembly education aid&amp;nbsp;distribution.&lt;/p&gt;
&lt;p&gt;I am not a legal expert, but I find the &lt;a href="http://scholar.google.com/scholar_case?case=2372498001429988039&amp;amp;hl=en&amp;amp;as_sdt=2,40&amp;amp;as_vis=1"&gt;conclusions of the Supreme Court&lt;/a&gt; abundantly clear. In &lt;em&gt;Pawtucket&lt;/em&gt;, the court decides to overturn a Superior Court decision which had earlier ruled that the state constitution guaranteed each child, &amp;#8220;receive an equal, adequate, and meaningful education.&amp;#8221; &lt;em&gt;Pawtucket&lt;/em&gt; finds that the General Assembly&amp;#8217;s responsibility to &amp;#8220;promote&amp;#8221; as &amp;#8220;&lt;em&gt;it&lt;/em&gt; sees fit&amp;#8221; (emphasis added in the original decision) is quite narrow; the General Assembly clearly has the power to determine how to &amp;#8220;promote&amp;#8221; education, it has historically used that power in a way that relied on local appropriations to education, and the courts do not even have a judicable standard&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;to determine the General Assembly has failed to &amp;#8220;promote&amp;#8221;&amp;nbsp;education.&lt;/p&gt;
&lt;p&gt;The current lawsuit asserts two things have dramatically changed since &lt;em&gt;Pawtucket&lt;/em&gt; that justify a second look and new ruling&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;. First, one portion of the state constitution has recently been changed that was used in the prior ruling. The Supreme Court&amp;#8217;s decision&amp;nbsp;stated:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Moreover, in no measure did the 1986 Constitution alter the plenary and exclusive powers of the General Assembly. In fact, the 1986 Constitution provided&amp;nbsp;that:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;The general assembly shall continue to exercise the powers it has heretofore exercised, unless prohibited in this Constitution.&amp;#8221; Art. 6, sec.&amp;nbsp;10.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/blockquote&gt;
&lt;p&gt;Essentially, the judge stated that this section of the state constitution meant that the legislature was retaining the right to exercise its powers as it had historically. In the case of education, this means &amp;#8220;the power to promote public education through a statutory funding scheme and through reliance on local property taxation,&amp;#8221; in accordance with the findings in the decision. However, Article 6, section 10 of the state constitution has subsequently been repealed. It is worth repeating what I said previously, &lt;strong&gt;I am not a legal expert&lt;/strong&gt;. However, I find the argument to overturn &lt;em&gt;Pawtucket&lt;/em&gt; on the basis that the General Assembly is no longer expressly continuing to exercise their power as previously to be weak. My understanding of the &lt;em&gt;Pawtucket&lt;/em&gt; ruling is that the court had only strengthened importance of historical context in making this decision by leaning on this constitutional provision. The importance of historical context still remains, even without this provision. In the &lt;em&gt;Pawtucket&lt;/em&gt; decision, the &amp;#8220;exercise of powers it has heretofore exercised&amp;#8221; is interpreted to mean that unchanged constitutional language reflects unchanged powers. By maintaining the same language in 1986, despite amendments offered that would have more explicitly established a right to education, the General Assembly was, in effect, affirming its intent to continue to &lt;em&gt;promote&lt;/em&gt; education as it had in the past. The plaintiffs in the current case, presumably, will argue that without Article 6, section 10, the General Assembly is allowing the courts to reinterpret even the same language to imply a different set of rights and responsibilities than it has historically. I have to ask, if the General Assembly&amp;#8217;s intent was to signal that Article &lt;span class="caps"&gt;XII&lt;/span&gt; should now be interpreted as establishing a right to education, why wouldn&amp;#8217;t they have adopted new, clearer language as was proposed in 1986? Having full awareness of the decision in &lt;em&gt;Pawtucket&lt;/em&gt;, it is hard to see that the General Assembly would signal a change in its power and responsibility to promote education through a repeal of Article 6, section 10. I would assert this change simply shifts some of the burden to the finding that the General Assembly &lt;em&gt;sees fit&lt;/em&gt; the &lt;em&gt;promot[ion]&lt;/em&gt; of some judicable standard right to education that is the state&amp;#8217;s fiscal&amp;nbsp;responsibility.&lt;/p&gt;
&lt;p&gt;This is the critical piece that the plaintiffs will not find. Nowhere has the General Assembly exercised its power to &lt;em&gt;promote &lt;/em&gt;in this way. In fact, one only has to look at how the General Assembly has acted to establish a judicable right to education to observe precisely how &lt;em&gt;it sees fit&lt;/em&gt;. &lt;a href="http://www.rilin.state.ri.us/statutes/title16/16-7/16-7-24.htm"&gt;Rhode Island General Law 16-7-24&lt;/a&gt;, titled &amp;#8220;Minimum appropriation by a community for approved school expenses,&amp;#8221; is a provision that all school committees are quite familiar with. Here, the General Assembly do establish a judicable standard for education, set by the Board of Regents of Elementary and Secondary Education in regulations known as the &amp;#8220;basic education program&amp;#8221;. But where &lt;em&gt;Pawtucket&lt;/em&gt; fails to establish a &lt;strong&gt;constitutional guarantee for state funding&lt;/strong&gt; in a particular amount for education, Rhode Island &lt;strong&gt;statute&lt;/strong&gt; is quite clear on a minimum standard for &lt;strong&gt;local&lt;/strong&gt; support. The law states that &amp;#8220;Each community shall appropriate or otherwise make available&amp;#8230; an amount, which together with state education and federal aid&amp;#8230; shall be not less than the costs of the basic program&amp;#8230; The Board of Regents for Elementary and Secondary Education shall adopt regulations for determining the basic education program&amp;#8230;&amp;#8221; In other words, Rhode Island statute squarely places the burden for meeting the Basic Education Program on cities and towns raising the required revenue. &amp;#8220;A community that has a local appropriation insufficient to fund the basic education program … shall be required to increase its local&amp;nbsp;appropriation…&amp;#8221;&lt;/p&gt;
&lt;p&gt;It seems pretty clear to me. While the plaintiffs in the current case will presumably argue that state regulations and laws &lt;em&gt;do&lt;/em&gt; represent a judicable standard, they will be unable to find where the General Assembly, through action, has affirmed that it is the role of the state aid to meet this standard. Instead, the law directly states that &lt;strong&gt;local appropriations&lt;/strong&gt; are to be increased if the Basic Education Program cannot be met. I cannot imagine that the Supreme Court would exercise its power to assert that the General Assembly&amp;#8217;s inaction implies more about the purpose of &lt;em&gt;unchanged&lt;/em&gt; constitutional language than the General Assembly&amp;#8217;s&amp;nbsp;actions.&lt;/p&gt;
&lt;p&gt;In summary, although the city is again suing the state for additional education aid, it is clear in the last 15 years that the state has substantially increased its support for Woonsocket Schools&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;. Furthermore, previous Rhode Island Supreme Court decisions and Rhode Island law clearly places the burden of adequate school funding squarely on the shoulders of cities and towns, not the General Assembly. In my view, the changes in education law and policy since &lt;em&gt;Pawtucket&lt;/em&gt; do not imply a change that would impact the court&amp;#8217;s&amp;nbsp;ruling.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This post is the second post of a three-part follow up on my &lt;a href="http://blogs.wpri.com/category/nesis-notes/"&gt;guest post&lt;/a&gt; for Nesi&amp;#8217;s Notes. Parts I and &lt;span class="caps"&gt;III&lt;/span&gt; can be found &lt;a href="http://blog.jasonpbecker.com/?p=224"&gt;here&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;meaning measurable and enforceable by court room activities&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;Note: I have not read the complaint as I probably should have for this post. I ran out of time. However, I feel fairly certain from press coverage that I am correctly stating their main points&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;See my post on Nesi&amp;#8217;s Notes&amp;#160;&lt;a class="footnote-backref" href="#fnref:3" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="education"></category><category term="nesi's notes"></category><category term="Pawtucket v. Sundlun"></category><category term="politics"></category><category term="rhode island"></category><category term="ri"></category><category term="rigl"></category><category term="woonsocket"></category></entry><entry><title>Limitations of the Nesi’s Notes Analysis and Some Additional Questions</title><link href="http://blog.jsonbecker.com/2012/07/limitations-of-the-nesis-notes-analysis-and-some-additional-questions.html" rel="alternate"></link><updated>2012-07-12T09:00:00-04:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-07-12:2012/07/limitations-of-the-nesis-notes-analysis-and-some-additional-questions.html</id><summary type="html">&lt;p&gt;There are several questions that come to mind when looking over my analysis on &lt;a href="http://blogs.wpri.com/category/nesis-notes/"&gt;Nesi&amp;#8217;s Notes&lt;/a&gt;. The first thing I wondered was whether or not Woonsocket had raised local revenues by similar amounts to other communities but had chosen to spend this money on other municipal services. Ideally, I would use a chart that showed local education revenues compared to all other local revenues over the last 15 years by city in Rhode Island. Unfortunately, &lt;a href="http://www.muni-info.ri.gov/"&gt;Municipal Finance&lt;/a&gt; does not separate local, state, and federal revenue sources in the &lt;a href="http://www.muni-info.ri.gov/finances/municipal_budget_survey.php"&gt;Municipal Budget Survey&lt;/a&gt; so it is hard to know&lt;em&gt;how&lt;/em&gt; communities have funded different services. I am sure with a bit of finagling, I could come up with a fairly good guess as to whether or not Woonsocket has simply chosen to fund other municipal services with its taxes, but quite frankly it is not precise enough to make me feel like its worth the exercise of extracting data from &lt;span class="caps"&gt;PDF&lt;/span&gt; tables. I hope someone else will take up some form of this analysis, possibly by requesting the breakdowns from Municipal&amp;nbsp;Finance.&lt;/p&gt;
&lt;p&gt;Another consideration is whether there is any truth to Woonsocket&amp;#8217;s claims that it simply does not have the ability to generate enough local revenue for their schools. I am skeptical on this claim. Three pieces of evidence suggest to me that this may not be&amp;nbsp;true.&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;strong&gt;The magnitude of the shortfall between the rest of the state and Woonsocket over the last 15 years when it comes to local education revenue&lt;/strong&gt;. On its face, I don&amp;#8217;t find it credible that Woonsocket&amp;#8217;s tax base is so weak that it could not increase local revenues for schools even at the rate of inflation. Not increasing local revenue for schools seems to leave only two possibilities: 1) local revenues in general were not increased, meaning Woonsocket would have to argue that its taxation in &lt;span class="caps"&gt;FY95&lt;/span&gt; was so high relative to everyone else that it took nearly 15 years for the rest of the state to catch up, hence no additional revenues; or 2) Woonsocket did raise local revenues, and chose to spend the money elsewhere. Had Woonsocket&amp;#8217;s local education aid risen 65-75% versus a state average of around 100%, I probably would not have even written my post on Nesi&amp;#8217;s&amp;nbsp;Notes.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;a href="https://twitter.com/#!/candrewmorse"&gt;Andrew Morse&lt;/a&gt;&amp;#8216;s analysis presented on &lt;a href="http://www.anchorrising.com/barnacles/013927.html"&gt;Anchor Rising&lt;/a&gt;&lt;/strong&gt;.&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; Woonsocket appears to be on the low to typical end of revenues as a proportion of non-poverty income. It does not seem that they are anywhere near the &amp;#8220;most&amp;#8221; taxed city or town by this measure. I am not an expert on tax policy, but this measure seems fairly straightforward, fair, and&amp;nbsp;informative.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;The mammoth proportions of Woonsocket&amp;#8217;s budget being spent on pensions (through debt service) and other post-employment benefits&lt;/strong&gt;. [A full 15% or so of Woonsocket&amp;#8217;s local revenues are being spent in these areas][]. This suggests to me misappropriation and poor planning has led to the erosion of local support for schools, not a lack of revenue generating capacity. If this truly is the case, then Woonsocket residents are really in trouble. Their leaders have managed to generate all of the high costs and high taxes experienced in Rhode Island without providing the quality of service that should be expected given those&amp;nbsp;investments.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Of course, I failed to offer any recommendation for remedy in the Nesi&amp;#8217;s Note post. How should Woonsocket schools become &amp;#8220;whole&amp;#8221; again? How can this possibly be accomplished in the context of a city on the brink of financial failure? Who has the legal responsibility to ensure that Woonsocket&amp;#8217;s children get the education they deserve? I have no answers on the first two points. However, in the next section of this post I hope answer the last question, which is also the subject of a law suit filed by Pawtucket and Woonsocket against the state of Rhode&amp;nbsp;Island.&lt;/p&gt;
&lt;p&gt;Who is responsible for ensuring students are receiving a certain minimum quality&amp;nbsp;education?&lt;/p&gt;
&lt;p&gt;&lt;em&gt;This post is the first of a three-part follow up on my &lt;a href="http://blogs.wpri.com/category/nesis-notes/"&gt;guest post&lt;/a&gt; for Nesi&amp;#8217;s Notes. Parts &lt;span class="caps"&gt;II&lt;/span&gt; and &lt;span class="caps"&gt;III&lt;/span&gt; can be found
&lt;a href="http://blog.jasonpbecker.com/?p=224"&gt;here&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;[fourth lowest revenues from residential taxes as a proportion of
community wealth]: http://www.anchorrising.com/barnacles/014501.html
[A full 15% or so of Woonsocket&amp;#8217;s local revenues are being spent in
these areas]:&amp;nbsp;http://blogs.reuters.com/muniland/2012/06/20/conservative-ideologues-arent-bankrupting-rhode-island/&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Andrew has been writing quite a bit about Woonsocket. For his most recent post, Andrew demonstrates Woonsocket has the [fourth lowest revenues from residential taxes as a proportion of community wealth][]. A few things I&amp;#8217;d like to point out on that post. First, I think Andrew was right to adjust for poverty in previous posts in a way he was unable to due to the structure of the new data. I support progressive taxation, so I don&amp;#8217;t believe that it is fair to say that we should expect the same percentage of income tax from poorer communities that we do from wealthier ones. I also think that commercial taxes are very important revenue sources. I don&amp;#8217;t think they should be universally dismissed when used as a substitute from residential revenues. There are times where marginally the greatest benefit can be had by lowering residents&amp;#8217; taxes. However, I do think that commercial tax should not be used as a substitute when there isn&amp;#8217;t enough revenue in the pie. In Woonsocket&amp;#8217;s case, it seems pretty clear they needed both the residential and commercial taxes to have sufficient revenues. &amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="education"></category><category term="nesi's notes"></category><category term="poverty"></category><category term="rhode island"></category><category term="ri"></category><category term="tax policy"></category><category term="woonsocket"></category></entry><entry><title>Using the Common Core Data on NCES</title><link href="http://blog.jsonbecker.com/2012/07/using-the-common-core-data-on-nces.html" rel="alternate"></link><updated>2012-07-12T09:00:00-04:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-07-12:2012/07/using-the-common-core-data-on-nces.html</id><summary type="html">&lt;p&gt;My analysis on &lt;a href="http://blogs.wpri.com/?p=62059"&gt;Nesi&amp;#8217;s Notes&lt;/a&gt; depended entirely on the &lt;a href="http://nces.ed.gov/ccd/bat"&gt;National Center for Education Statistics&amp;#8217; Common Core Data&lt;/a&gt;. The per pupil amounts reported to &lt;span class="caps"&gt;NCES&lt;/span&gt; may look a bit different from state sources of this information. There are several explanations of this. First, the enrollment counts used to generate per pupil amounts are based on an October 1st headcount. In Rhode Island, we use something called &amp;#8220;average daily membership&amp;#8221; (&lt;span class="caps"&gt;ADM&lt;/span&gt;) as the denominator and not a headcount. The &lt;span class="caps"&gt;ADM&lt;/span&gt; of a district is calculated by taking all the students who attended the district at any point in the year and adding up the number of school days they were enrolled for. The total membership (i.e. all the student*days, for those who like to think about this in units) is divided by the number of school days per year, almost always 180 (so student*days / days/year = students/year). Additionally, &lt;span class="caps"&gt;NCES&lt;/span&gt; does not record the final three digits on most financial data. These rounding issues will also make the per pupil data seem different from state&amp;nbsp;reports.&lt;/p&gt;
&lt;p&gt;I wanted to use the &lt;span class="caps"&gt;NCES&lt;/span&gt; to make sure that the data in my post was easily reproducible by any member of the public. I also thought using &lt;span class="caps"&gt;NCES&lt;/span&gt; would serve as a great learning opportunity for the wonks and nerds out there who never even realized how much rich data about schools and school finance are available through the federal government. That being said, I do believe that the state reported numbers are far more accurate than those available from the federal government. That is not to say that the federal data is bad. On the contrary, that data is substantially vetted and validated and is very useful for research. My concern was only that some of the tiny differences in the &lt;span class="caps"&gt;NCES&lt;/span&gt; data that deviated from what I would consider to be ideal data might reach the level where they affected the validity of the conclusions I wanted to&amp;nbsp;draw.&lt;/p&gt;
&lt;p&gt;Although I was writing as a private citizen without the support of the Rhode Island Department of Education, I did use my access to &lt;span class="caps"&gt;RIDE&lt;/span&gt; data to ensure that differences in the federal reports were not significant enough to call into question my analysis. I found that both the direction and magnitude of all the trends that I describe in the Nesi&amp;#8217;s Notes post held up with the state data. While all of that information is publicly available, it is less easily accessible than &lt;span class="caps"&gt;NCES&lt;/span&gt; data and doesn&amp;#8217;t provide the same opportunity for analysis outside of financial data. For these reasons, I decided to stick with&amp;nbsp;&lt;span class="caps"&gt;NCES&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;So how do you reproduce the data I&amp;nbsp;used?&lt;/p&gt;
&lt;p&gt;First, go to  the &lt;a href="http://nces.ed.gov/ccd/bat"&gt;&lt;span class="caps"&gt;NCES&lt;/span&gt; Common Core Data Build a Table&lt;/a&gt; site. On the drop down, select &amp;#8220;District&amp;#8221; as the row variable and select the last fifteen years excluding 2009-10 (since there is no current financial data available for that&amp;nbsp;year).&lt;/p&gt;
&lt;p&gt;&lt;img alt="1" src="http://blog.jsonbecker.com/images/nces1.png" /&gt;&lt;/p&gt;
&lt;p&gt;After clicking next, hit &amp;#8220;I Agree&amp;#8221; on the&amp;nbsp;pop-up.&lt;/p&gt;
&lt;p&gt;&lt;img alt="2" src="http://blog.jsonbecker.com/images/nces2.png" /&gt;&lt;/p&gt;
&lt;p&gt;Now select &amp;#8220;Finance Per Pupil Ratios&amp;#8221; for the first&amp;nbsp;column.&lt;/p&gt;
&lt;p&gt;&lt;img alt="3" src="http://blog.jsonbecker.com/images/nces3.png" /&gt;&lt;/p&gt;
&lt;p&gt;Click the green arrow that selects all years for local sources per
student and state sources per&amp;nbsp;student.&lt;/p&gt;
&lt;p&gt;&lt;img alt="4" src="http://blog.jsonbecker.com/images/nces4.png" /&gt;&lt;/p&gt;
&lt;p&gt;Click &amp;#8220;Next&gt;&gt;&amp;#8221; on the top right. Now select only &lt;span class="caps"&gt;RI&lt;/span&gt;-Rhode Island for
your row&amp;nbsp;variable.&lt;/p&gt;
&lt;p&gt;&lt;img alt="5" src="http://blog.jsonbecker.com/images/nces5.png" /&gt;&lt;/p&gt;
&lt;p&gt;Finally, click view table to see the results. I recommend downloading
the Test (.csv) file to work&amp;nbsp;with.&lt;/p&gt;
&lt;p&gt;&lt;img alt="6" src="http://blog.jsonbecker.com/images/nces6.png" /&gt;&lt;/p&gt;
&lt;p&gt;And finally, here&amp;#8217;s the R code to reshape/rejigger the data I used and
produce the graphics from the Nesi&amp;#8217;s Notes&amp;nbsp;post.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c1"&gt;## Using &lt;span class="caps"&gt;NCES&lt;/span&gt; data to analyze education finances to Woonsocket over 15 years.&lt;/span&gt;
&lt;span class="c1"&gt;## Initialize required packages&lt;/span&gt;
require&lt;span class="p"&gt;(&lt;/span&gt;plyr&lt;span class="p"&gt;)&lt;/span&gt;
require&lt;span class="p"&gt;(&lt;/span&gt;reshape2&lt;span class="p"&gt;)&lt;/span&gt;
require&lt;span class="p"&gt;(&lt;/span&gt;ggplot2&lt;span class="p"&gt;)&lt;/span&gt;
require&lt;span class="p"&gt;(&lt;/span&gt;scales&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;## Best to ignore this function-- it&amp;#39;s mostly magic to me too. Essentially,&lt;/span&gt;
&lt;span class="c1"&gt;## multiplot takes in a bunch of plots and then puts them into one image&lt;/span&gt;
&lt;span class="c1"&gt;## arranging them by columns equal to a paramter cols. Credit to:&lt;/span&gt;
&lt;span class="c1"&gt;## http://wiki.stdout.org/rcookbook/Graphs/Multiple%20graphs%20on%20one%20page%20(    ggplot2)/&lt;/span&gt;
multiplot &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kc"&gt;...&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; plotlist&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;&lt;span class="caps"&gt;NULL&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; cols&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
  require&lt;span class="p"&gt;(&lt;/span&gt;grid&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="c1"&gt;# Make a list from the ... arguments and plotlist&lt;/span&gt;
  plots &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;list&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="kc"&gt;...&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; plotlist&lt;span class="p"&gt;)&lt;/span&gt;
  numPlots &lt;span class="o"&gt;=&lt;/span&gt; length&lt;span class="p"&gt;(&lt;/span&gt;plots&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="c1"&gt;# Make the panel&lt;/span&gt;
  plotCols &lt;span class="o"&gt;=&lt;/span&gt; cols                          &lt;span class="c1"&gt;# Number of columns of plots&lt;/span&gt;
  plotRows &lt;span class="o"&gt;=&lt;/span&gt; ceiling&lt;span class="p"&gt;(&lt;/span&gt;numPlots&lt;span class="o"&gt;/&lt;/span&gt;plotCols&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="c1"&gt;# Number of rows needed, calculated from #    of cols&lt;/span&gt;
  &lt;span class="c1"&gt;# Set up the page&lt;/span&gt;
  grid.newpage&lt;span class="p"&gt;()&lt;/span&gt;
  pushViewport&lt;span class="p"&gt;(&lt;/span&gt;viewport&lt;span class="p"&gt;(&lt;/span&gt;layout &lt;span class="o"&gt;=&lt;/span&gt; grid.layout&lt;span class="p"&gt;(&lt;/span&gt;plotRows&lt;span class="p"&gt;,&lt;/span&gt; plotCols&lt;span class="p"&gt;)))&lt;/span&gt;
  vplayout &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;,&lt;/span&gt; y&lt;span class="p"&gt;)&lt;/span&gt;
    viewport&lt;span class="p"&gt;(&lt;/span&gt;layout.pos.row &lt;span class="o"&gt;=&lt;/span&gt; x&lt;span class="p"&gt;,&lt;/span&gt; layout.pos.col &lt;span class="o"&gt;=&lt;/span&gt; y&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="c1"&gt;# Make each plot, in the correct location&lt;/span&gt;
  &lt;span class="kr"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;i &lt;span class="kr"&gt;in&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;numPlots&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    curRow &lt;span class="o"&gt;=&lt;/span&gt; ceiling&lt;span class="p"&gt;(&lt;/span&gt;i&lt;span class="o"&gt;/&lt;/span&gt;plotCols&lt;span class="p"&gt;)&lt;/span&gt;
    curCol &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;i&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%%&lt;/span&gt; plotCols &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;
    print&lt;span class="p"&gt;(&lt;/span&gt;plots&lt;span class="p"&gt;[[&lt;/span&gt;i&lt;span class="p"&gt;]],&lt;/span&gt; vp &lt;span class="o"&gt;=&lt;/span&gt; vplayout&lt;span class="p"&gt;(&lt;/span&gt;curRow&lt;span class="p"&gt;,&lt;/span&gt; curCol &lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="c1"&gt;## Load data from the modified &lt;span class="caps"&gt;CSV&lt;/span&gt;. I made the following changes from the &lt;span class="caps"&gt;NCES&lt;/span&gt;&lt;/span&gt;
&lt;span class="c1"&gt;## downloaded file: 1) I removed all of the description header so that row one&lt;/span&gt;
&lt;span class="c1"&gt;## of the &lt;span class="caps"&gt;CSV&lt;/span&gt; is the attribute names; 2) I pasted the transposed state values&lt;/span&gt;
&lt;span class="c1"&gt;## to the final observation so that I have a state observation row analogous to&lt;/span&gt;
&lt;span class="c1"&gt;## the other &lt;span class="caps"&gt;LEA&lt;/span&gt; rows.&lt;/span&gt;

raw_data &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; read.csv&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;rawdata.csv&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;## Change name of first column to make things easier for later.&lt;/span&gt;
names&lt;span class="p"&gt;(&lt;/span&gt;raw_data&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;distname&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;## Creating Time Series Data for each community of interest.&lt;/span&gt;
&lt;span class="c1"&gt;## I&amp;#39;m going to use a custom function to automate the steps required to create&lt;/span&gt;
&lt;span class="c1"&gt;## district level data in a time series.&lt;/span&gt;

create_ts &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;name&lt;span class="p"&gt;){&lt;/span&gt;
  &lt;span class="c1"&gt;# First create a column vector with the local funding&lt;/span&gt;
  &lt;span class="c1"&gt;# A few things to note: First, t() is the transpose function and helps to&lt;/span&gt;
  &lt;span class="c1"&gt;# make my &amp;quot;wide&amp;quot; data (lots of columns) &amp;quot;long&amp;quot; (lots of rows). Second, R&lt;/span&gt;
  &lt;span class="c1"&gt;# has a funny behavior that is very covenient for data anaylsts. It performs&lt;/span&gt;
  &lt;span class="c1"&gt;# many common mathematical operations element-wise, so the simple division&lt;/span&gt;
  &lt;span class="c1"&gt;# of two vectors below actually divides element by element through the&lt;/span&gt;
  &lt;span class="c1"&gt;# vector, e.g. column 17 is divided by column 2 to provide the first element&lt;/span&gt;
  &lt;span class="c1"&gt;# in the resulting vector. This makes calculating per pupil amounts very&lt;/span&gt;
  &lt;span class="c1"&gt;# convenient.&lt;/span&gt;
  local &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; t&lt;span class="p"&gt;(&lt;/span&gt;subset&lt;span class="p"&gt;(&lt;/span&gt;raw_data&lt;span class="p"&gt;,&lt;/span&gt;distname&lt;span class="o"&gt;==&lt;/span&gt;name&lt;span class="p"&gt;)[,&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;17&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;31&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;
             subset&lt;span class="p"&gt;(&lt;/span&gt;raw_data&lt;span class="p"&gt;,&lt;/span&gt;distname&lt;span class="o"&gt;==&lt;/span&gt;name&lt;span class="p"&gt;)[,&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;16&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;
  &lt;span class="c1"&gt;# Performing the same operation for state per pupil amounts.&lt;/span&gt;
  state &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; t&lt;span class="p"&gt;(&lt;/span&gt;subset&lt;span class="p"&gt;(&lt;/span&gt;raw_data&lt;span class="p"&gt;,&lt;/span&gt;distname&lt;span class="o"&gt;==&lt;/span&gt;name&lt;span class="p"&gt;)[,&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;32&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;46&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;
             subset&lt;span class="p"&gt;(&lt;/span&gt;raw_data&lt;span class="p"&gt;,&lt;/span&gt;distname&lt;span class="o"&gt;==&lt;/span&gt;name&lt;span class="p"&gt;)[,&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;16&lt;/span&gt;&lt;span class="p"&gt;)])&lt;/span&gt;
  &lt;span class="c1"&gt;# Putting state and local data together and getting rid of the nasty&lt;/span&gt;
  &lt;span class="c1"&gt;# attribute names from &lt;span class="caps"&gt;NCES&lt;/span&gt; by just naming the rows with a sequence&lt;/span&gt;
  &lt;span class="c1"&gt;# of integers.&lt;/span&gt;
  results &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; data.frame&lt;span class="p"&gt;(&lt;/span&gt;local&lt;span class="p"&gt;,&lt;/span&gt;state&lt;span class="p"&gt;,&lt;/span&gt;row.names&lt;span class="o"&gt;=&lt;/span&gt;seq&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;15&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="c1"&gt;# Naming my two attributes&lt;/span&gt;
  names&lt;span class="p"&gt;(&lt;/span&gt;results&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;local&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;state&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="c1"&gt;# Generating the year attribute&lt;/span&gt;
  results&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; seq&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1995&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;2009&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="c1"&gt;# This command is a bit funky, but basically it makes my data as long as&lt;/span&gt;
  &lt;span class="c1"&gt;# possible so that each line has an &lt;span class="caps"&gt;ID&lt;/span&gt; (year in this case) and one value&lt;/span&gt;
  &lt;span class="c1"&gt;# (the dollars in this case). I also have a label that describes that value,&lt;/span&gt;
  &lt;span class="c1"&gt;# which is local or state.&lt;/span&gt;
  results &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; melt&lt;span class="p"&gt;(&lt;/span&gt;results&lt;span class="p"&gt;,&lt;/span&gt; id.vars&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="c1"&gt;# Returning my &amp;quot;results&amp;quot; object&lt;/span&gt;
  results
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="c1"&gt;## Create the Woonsocket data-- note that R is case sensitive so I must use all&lt;/span&gt;
&lt;span class="c1"&gt;## capitals to match the &lt;span class="caps"&gt;NCES&lt;/span&gt; convention.&lt;/span&gt;
woonsocket &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; create_ts&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;span class="caps"&gt;WOONSOCKET&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
pawtucket &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; create_ts&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;span class="caps"&gt;PAWTUCKET&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
providence &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; create_ts&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;span class="caps"&gt;PROVIDENCE&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
westwarwick &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; create_ts&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;span class="caps"&gt;WEST&lt;/span&gt; &lt;span class="caps"&gt;WARWICK&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
state &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; create_ts&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;span class="caps"&gt;STATE&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;## Developing a plot of &lt;span class="caps"&gt;JUST&lt;/span&gt; local revenues for the selected communities&lt;/span&gt;
&lt;span class="c1"&gt;## First I create a percentage change data frame. I think that looking at&lt;/span&gt;
&lt;span class="c1"&gt;## percent change overtime is generally more fair. While the nominal dollar&lt;/span&gt;
&lt;span class="c1"&gt;## changes are revealing, my analysis is drawing attention to the trend rather&lt;/span&gt;
&lt;span class="c1"&gt;## than the initial values.&lt;/span&gt;

&lt;span class="c1"&gt;## First, I pull out just the local dollars.&lt;/span&gt;
perwoonlocal &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; subset&lt;span class="p"&gt;(&lt;/span&gt;woonsocket&lt;span class="p"&gt;,&lt;/span&gt;variable&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;local&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;## Now I modify the value to be divided by the starting value - 100%&lt;/span&gt;
perwoonlocal&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; with&lt;span class="p"&gt;(&lt;/span&gt;perwoonlocal&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;value&lt;span class="o"&gt;/&lt;/span&gt;value&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;## A little renaming for the combining step later&lt;/span&gt;
names&lt;span class="p"&gt;(&lt;/span&gt;perwoonlocal&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;disname&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
perwoonlocal&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;disname&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Woonsocket&amp;#39;&lt;/span&gt;

&lt;span class="c1"&gt;## I repeat this procedure for all the districts of interest.&lt;/span&gt;
perpawlocal &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; subset&lt;span class="p"&gt;(&lt;/span&gt;pawtucket&lt;span class="p"&gt;,&lt;/span&gt;variable&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;local&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
perpawlocal&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; with&lt;span class="p"&gt;(&lt;/span&gt;perpawlocal&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;value&lt;span class="o"&gt;/&lt;/span&gt;value&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
names&lt;span class="p"&gt;(&lt;/span&gt;perpawlocal&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;disname&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
perpawlocal&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;disname&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Pawtucket&amp;#39;&lt;/span&gt;

perprolocal &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; subset&lt;span class="p"&gt;(&lt;/span&gt;providence&lt;span class="p"&gt;,&lt;/span&gt;variable&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;local&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
perprolocal&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; with&lt;span class="p"&gt;(&lt;/span&gt;perprolocal&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;value&lt;span class="o"&gt;/&lt;/span&gt;value&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
names&lt;span class="p"&gt;(&lt;/span&gt;perprolocal&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;disname&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
perprolocal&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;disname&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Providence&amp;#39;&lt;/span&gt;

perwwlocal &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; subset&lt;span class="p"&gt;(&lt;/span&gt;westwarwick&lt;span class="p"&gt;,&lt;/span&gt; variable&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;local&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
perwwlocal&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; with&lt;span class="p"&gt;(&lt;/span&gt;perwwlocal&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;value&lt;span class="o"&gt;/&lt;/span&gt;value&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
names&lt;span class="p"&gt;(&lt;/span&gt;perwwlocal&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;disname&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
perwwlocal&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;disname&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;West Warwick&amp;#39;&lt;/span&gt;

perrilocal &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; subset&lt;span class="p"&gt;(&lt;/span&gt;state&lt;span class="p"&gt;,&lt;/span&gt;variable&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;local&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
perrilocal&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; with&lt;span class="p"&gt;(&lt;/span&gt;perrilocal&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;value&lt;span class="o"&gt;/&lt;/span&gt;value&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
names&lt;span class="p"&gt;(&lt;/span&gt;perrilocal&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;disname&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
perrilocal&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;disname&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;State Average&amp;#39;&lt;/span&gt;

&lt;span class="c1"&gt;## The same process can be used for state data&lt;/span&gt;
perwoonstate &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; subset&lt;span class="p"&gt;(&lt;/span&gt;woonsocket&lt;span class="p"&gt;,&lt;/span&gt;variable&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;state&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;## Now I modify the value to be divided by the starting value - 100%&lt;/span&gt;
perwoonstate&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; with&lt;span class="p"&gt;(&lt;/span&gt;perwoonstate&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;value&lt;span class="o"&gt;/&lt;/span&gt;value&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;## A little renaming for the combining step later&lt;/span&gt;
names&lt;span class="p"&gt;(&lt;/span&gt;perwoonstate&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;disname&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
perwoonstate&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;disname&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Woonsocket&amp;#39;&lt;/span&gt;

&lt;span class="c1"&gt;## I repeat this procedure for all the districts of interest.&lt;/span&gt;
perpawstate &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; subset&lt;span class="p"&gt;(&lt;/span&gt;pawtucket&lt;span class="p"&gt;,&lt;/span&gt;variable&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;state&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
perpawstate&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; with&lt;span class="p"&gt;(&lt;/span&gt;perpawstate&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;value&lt;span class="o"&gt;/&lt;/span&gt;value&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
names&lt;span class="p"&gt;(&lt;/span&gt;perpawstate&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;disname&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
perpawstate&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;disname&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Pawtucket&amp;#39;&lt;/span&gt;

perprostate &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; subset&lt;span class="p"&gt;(&lt;/span&gt;providence&lt;span class="p"&gt;,&lt;/span&gt;variable&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;state&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
perprostate&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; with&lt;span class="p"&gt;(&lt;/span&gt;perprostate&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;value&lt;span class="o"&gt;/&lt;/span&gt;value&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
names&lt;span class="p"&gt;(&lt;/span&gt;perprostate&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;disname&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
perprostate&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;disname&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Providence&amp;#39;&lt;/span&gt;

perwwstate &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; subset&lt;span class="p"&gt;(&lt;/span&gt;westwarwick&lt;span class="p"&gt;,&lt;/span&gt; variable&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;state&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
perwwstate&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; with&lt;span class="p"&gt;(&lt;/span&gt;perwwstate&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;value&lt;span class="o"&gt;/&lt;/span&gt;value&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
names&lt;span class="p"&gt;(&lt;/span&gt;perwwstate&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;disname&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
perwwstate&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;disname&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;West Warwick&amp;#39;&lt;/span&gt;

perristate &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; subset&lt;span class="p"&gt;(&lt;/span&gt;state&lt;span class="p"&gt;,&lt;/span&gt;variable&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;state&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
perristate&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; with&lt;span class="p"&gt;(&lt;/span&gt;perristate&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;value&lt;span class="o"&gt;/&lt;/span&gt;value&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
names&lt;span class="p"&gt;(&lt;/span&gt;perristate&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;disname&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;value&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
perristate&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;disname&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;State Average&amp;#39;&lt;/span&gt;

&lt;span class="c1"&gt;## Pull together the data sets for the overall picture.&lt;/span&gt;
localfunding &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; rbind&lt;span class="p"&gt;(&lt;/span&gt;perwoonlocal&lt;span class="p"&gt;,&lt;/span&gt; perpawlocal&lt;span class="p"&gt;,&lt;/span&gt;perprolocal&lt;span class="p"&gt;,&lt;/span&gt;perwwlocal&lt;span class="p"&gt;,&lt;/span&gt;perrilocal&lt;span class="p"&gt;)&lt;/span&gt;
statefunding &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; rbind&lt;span class="p"&gt;(&lt;/span&gt;perwoonstate&lt;span class="p"&gt;,&lt;/span&gt; perpawstate&lt;span class="p"&gt;,&lt;/span&gt;perprostate&lt;span class="p"&gt;,&lt;/span&gt;perwwstate&lt;span class="p"&gt;,&lt;/span&gt;perristate&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;## A little ggplot2 line plot magic...&lt;/span&gt;
localperplot &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; ggplot&lt;span class="p"&gt;(&lt;/span&gt;localfunding&lt;span class="p"&gt;,&lt;/span&gt;aes&lt;span class="p"&gt;(&lt;/span&gt;year&lt;span class="p"&gt;,&lt;/span&gt; value&lt;span class="p"&gt;,&lt;/span&gt; color&lt;span class="o"&gt;=&lt;/span&gt;disname&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                geom_line&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                geom_text&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="o"&gt;=&lt;/span&gt;subset&lt;span class="p"&gt;(&lt;/span&gt;localfunding&lt;span class="p"&gt;,&lt;/span&gt; year&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="m"&gt;2009&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                          mapping&lt;span class="o"&gt;=&lt;/span&gt;aes&lt;span class="p"&gt;(&lt;/span&gt;year&lt;span class="p"&gt;,&lt;/span&gt;value&lt;span class="p"&gt;,&lt;/span&gt;
                                      label&lt;span class="o"&gt;=&lt;/span&gt;paste&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;100&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;round&lt;span class="p"&gt;(&lt;/span&gt;value&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;%&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;sep&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;
                          vjust&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;-.4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                scale_y_continuous&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Percent Change from &lt;span class="caps"&gt;FY1995&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                   label&lt;span class="o"&gt;=&lt;/span&gt;percent&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                scale_x_continuous&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Year&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                opts&lt;span class="p"&gt;(&lt;/span&gt;title&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Percent Change in Local Per Pupil Revenue, &lt;span class="caps"&gt;FY1995&lt;/span&gt;-    &lt;span class="caps"&gt;FY2009&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                opts&lt;span class="p"&gt;(&lt;/span&gt;plot.title&lt;span class="o"&gt;=&lt;/span&gt;theme_text&lt;span class="p"&gt;(&lt;/span&gt;size&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;face&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;bold&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                opts&lt;span class="p"&gt;(&lt;/span&gt;legend.title&lt;span class="o"&gt;=&lt;/span&gt;theme_blank&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                opts&lt;span class="p"&gt;(&lt;/span&gt;legend.position&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;.08&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;.82&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
stateperplot &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; ggplot&lt;span class="p"&gt;(&lt;/span&gt;statefunding&lt;span class="p"&gt;,&lt;/span&gt;aes&lt;span class="p"&gt;(&lt;/span&gt;year&lt;span class="p"&gt;,&lt;/span&gt; value&lt;span class="p"&gt;,&lt;/span&gt; color&lt;span class="o"&gt;=&lt;/span&gt;disname&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                geom_line&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                geom_text&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="o"&gt;=&lt;/span&gt;subset&lt;span class="p"&gt;(&lt;/span&gt;statefunding&lt;span class="p"&gt;,&lt;/span&gt; year&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="m"&gt;2008&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; year&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="m"&gt;2009&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                          mapping&lt;span class="o"&gt;=&lt;/span&gt;aes&lt;span class="p"&gt;(&lt;/span&gt;year&lt;span class="p"&gt;,&lt;/span&gt;value&lt;span class="p"&gt;,&lt;/span&gt;
                          label&lt;span class="o"&gt;=&lt;/span&gt;paste&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;100&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;round&lt;span class="p"&gt;(&lt;/span&gt;value&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;%&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;sep&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;
                          vjust&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;-.4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                scale_y_continuous&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Percent Change from &lt;span class="caps"&gt;FY1995&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                   label&lt;span class="o"&gt;=&lt;/span&gt;percent&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                scale_x_continuous&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Year&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                opts&lt;span class="p"&gt;(&lt;/span&gt;title&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Percent Change in State Per Pupil Revenue, &lt;span class="caps"&gt;FY1995&lt;/span&gt;-    &lt;span class="caps"&gt;FY2009&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                opts&lt;span class="p"&gt;(&lt;/span&gt;plot.title&lt;span class="o"&gt;=&lt;/span&gt;theme_text&lt;span class="p"&gt;(&lt;/span&gt;size&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;face&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;bold&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                opts&lt;span class="p"&gt;(&lt;/span&gt;legend.title&lt;span class="o"&gt;=&lt;/span&gt;theme_blank&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                opts&lt;span class="p"&gt;(&lt;/span&gt;legend.position&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;.08&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;.82&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
ggsave&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;localperplot.png&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;localperplot&lt;span class="p"&gt;,&lt;/span&gt;width&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;height&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;units&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;in&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;dpi&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;72&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
ggsave&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;stateperplot.png&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;stateperplot&lt;span class="p"&gt;,&lt;/span&gt;width&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;height&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;units&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;in&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;dpi&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;72&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;## Proportion of Aid&lt;/span&gt;
proportion &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="p"&gt;){&lt;/span&gt;
  &lt;span class="c1"&gt;# This reshapes the data so that there is a year, local, and state column.&lt;/span&gt;
  &lt;span class="c1"&gt;# The mean function has no purpose, because this data is unique by year&lt;/span&gt;
  &lt;span class="c1"&gt;# variable combinations.&lt;/span&gt;
  prop &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; dcast&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="p"&gt;,&lt;/span&gt;year&lt;span class="o"&gt;~&lt;/span&gt;variable&lt;span class="p"&gt;,&lt;/span&gt;mean&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="c1"&gt;# Adding local and state get our total non-federal dollars&lt;/span&gt;
  prop&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;total&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; apply&lt;span class="p"&gt;(&lt;/span&gt;prop&lt;span class="p"&gt;[,&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;sum&lt;span class="p"&gt;)&lt;/span&gt;
  prop&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;perlocal&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; with&lt;span class="p"&gt;(&lt;/span&gt;prop&lt;span class="p"&gt;,&lt;/span&gt; local&lt;span class="o"&gt;/&lt;/span&gt;total&lt;span class="p"&gt;)&lt;/span&gt;
  prop
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;## Prepare new data frames for proportion graphs&lt;/span&gt;

propwoon &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; as.data.frame&lt;span class="p"&gt;(&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;disname&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Woonsocket&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                            proportion&lt;span class="p"&gt;(&lt;/span&gt;woonsocket&lt;span class="p"&gt;)))&lt;/span&gt;
proppaw &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; as.data.frame&lt;span class="p"&gt;(&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;disname&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Pawtucket&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                           proportion&lt;span class="p"&gt;(&lt;/span&gt;pawtucket&lt;span class="p"&gt;)))&lt;/span&gt;
propprov &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; as.data.frame&lt;span class="p"&gt;(&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;disname&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Providence&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                            proportion&lt;span class="p"&gt;(&lt;/span&gt;providence&lt;span class="p"&gt;)))&lt;/span&gt;
propww &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; as.data.frame&lt;span class="p"&gt;(&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;disname&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;West Warwick&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                          proportion&lt;span class="p"&gt;(&lt;/span&gt;westwarwick&lt;span class="p"&gt;)))&lt;/span&gt;
propri &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; as.data.frame&lt;span class="p"&gt;(&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;disname&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;State Average&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                          proportion&lt;span class="p"&gt;(&lt;/span&gt;state&lt;span class="p"&gt;)))&lt;/span&gt;

&lt;span class="c1"&gt;## Note, I could have called proportion() inside of the rbind(), but I wanted&lt;/span&gt;
&lt;span class="c1"&gt;## my code to be clearer and felt there may be some use for the independent&lt;/span&gt;
&lt;span class="c1"&gt;## proportion data frames in further analysis. Sometimes more lines of code&lt;/span&gt;
&lt;span class="c1"&gt;## and more objects is easier to maintain and more flexible for exploratory,&lt;/span&gt;
&lt;span class="c1"&gt;## non-production code. This is especially true when handling such small&lt;/span&gt;
&lt;span class="c1"&gt;## data sets that there is no impact on performance.&lt;/span&gt;

locprop &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; rbind&lt;span class="p"&gt;(&lt;/span&gt;propwoon&lt;span class="p"&gt;,&lt;/span&gt; proppaw&lt;span class="p"&gt;,&lt;/span&gt;propprov&lt;span class="p"&gt;,&lt;/span&gt;propww&lt;span class="p"&gt;,&lt;/span&gt;propri&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c1"&gt;## Some ggplot2 magic time!&lt;/span&gt;

localpropplot &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; ggplot&lt;span class="p"&gt;(&lt;/span&gt;locprop&lt;span class="p"&gt;,&lt;/span&gt;aes&lt;span class="p"&gt;(&lt;/span&gt;year&lt;span class="p"&gt;,&lt;/span&gt; perlocal&lt;span class="p"&gt;,&lt;/span&gt; color&lt;span class="o"&gt;=&lt;/span&gt;disname&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                 geom_line&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                 geom_text&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="o"&gt;=&lt;/span&gt;subset&lt;span class="p"&gt;(&lt;/span&gt;locprop&lt;span class="p"&gt;,&lt;/span&gt; year&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="m"&gt;1995&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt; year&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="m"&gt;2008&lt;/span&gt; &lt;span class="o"&gt;|&lt;/span&gt;     year&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="m"&gt;2009&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                           mapping&lt;span class="o"&gt;=&lt;/span&gt;aes&lt;span class="p"&gt;(&lt;/span&gt;year&lt;span class="p"&gt;,&lt;/span&gt;perlocal&lt;span class="p"&gt;,&lt;/span&gt;
                           label&lt;span class="o"&gt;=&lt;/span&gt;paste&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;100&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;round&lt;span class="p"&gt;(&lt;/span&gt;perlocal&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;%&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;sep&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)),&lt;/span&gt;
                           vjust&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;-.4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                 scale_y_continuous&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Percent Change from &lt;span class="caps"&gt;FY1995&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                     label&lt;span class="o"&gt;=&lt;/span&gt;percent&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                 scale_x_continuous&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Year&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                 opts&lt;span class="p"&gt;(&lt;/span&gt;title&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Percent Change in Local Proportion of Per Pupil    Revenue\n Excluding Federal Funding, &lt;span class="caps"&gt;FY1995&lt;/span&gt;-&lt;span class="caps"&gt;FY2009&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                 opts&lt;span class="p"&gt;(&lt;/span&gt;plot.title&lt;span class="o"&gt;=&lt;/span&gt;theme_text&lt;span class="p"&gt;(&lt;/span&gt;size&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;16&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;face&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;bold&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                 opts&lt;span class="p"&gt;(&lt;/span&gt;legend.title&lt;span class="o"&gt;=&lt;/span&gt;theme_blank&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                 opts&lt;span class="p"&gt;(&lt;/span&gt;legend.position&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;.9&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;.65&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
ggsave&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;localpropplot.png&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;localpropplot&lt;span class="p"&gt;,&lt;/span&gt;width&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;10&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;height&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;units&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;in&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;dpi&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;72&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;em&gt;This post is the third of a three-part follow up on my &lt;a href="http://blogs.wpri.com/category/nesis-notes/"&gt;guest post&lt;/a&gt; for Nesi&amp;#8217;s Notes. Parts I and &lt;span class="caps"&gt;II&lt;/span&gt; can be found &lt;a href="http://blog.jsonbecker.com/2012/07/follow-up-to-nesis-notes-guest-post-woonsocket-school-funding.html"&gt;here&lt;/a&gt;.&lt;/em&gt;&lt;/p&gt;</summary><category term="ccd"></category><category term="data"></category><category term="education"></category><category term="education policy"></category><category term="ggplot2"></category><category term="nces"></category><category term="nesi's notes"></category><category term="politics"></category><category term="rhode island"></category><category term="ri"></category><category term="rstats"></category><category term="woonsocket"></category></entry><entry><title>Update on Social Promotion</title><link href="http://blog.jsonbecker.com/2012/07/update-on-social-promotion.html" rel="alternate"></link><updated>2012-07-10T09:45:00-04:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-07-10:2012/07/update-on-social-promotion.html</id><summary type="html">&lt;p&gt;This &lt;a href="http://www.startinganedschool.org/2012/07/09/letter-from-an-8th-grader/"&gt;poignant post&lt;/a&gt; from &lt;a href="http://www.startinganedschool.org/author/mike/"&gt;Michael Goldstein&lt;/a&gt; ends with a few policy thoughts that largely support my &lt;a href="http://blog.jasonpbecker.com/2012/02/15/social-promotion-tutoring-and-funding/"&gt;previous post&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Goldstein&amp;#8217;s second point is worth&amp;nbsp;highlighting:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Anyway, in a small school, large-scale research isn’t the key
determinant anyway. The team’s implementation&amp;nbsp;is.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;On the same day that &lt;a href="http://shankerblog.org"&gt;Shanker Blog&lt;/a&gt; is assuring us that &lt;a href="http://shankerblog.org/?p=6180"&gt;rigorous social science is worth it&lt;/a&gt;, Goldstein delivers researchers a healthy dose of humility. Rigorous research is all about doing the best we can to remove all the confounding explanatory factors that have an impact on our observed outcomes to isolate an intervention. But even in the most rigorous studies social scientists are often measuring the &lt;a href="http://en.wikipedia.org/wiki/Average_treatment_effect"&gt;&lt;strong&gt;A&lt;/strong&gt;verage &lt;strong&gt;T&lt;/strong&gt;reatment &lt;strong&gt;E&lt;/strong&gt;ffect&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;How rarely do we truly encounter a completely average situation? The real impact in any particular school or organization can be dramatically different in magnitude and even direction because of all the pesky observed and &lt;a href="http://en.wikipedia.org/wiki/Omitted-variable_bias"&gt;unobserved&lt;/a&gt; confounding factors that researchers work so hard to be able to &lt;a href="http://en.wikipedia.org/wiki/Validity_(statistics)"&gt;ignore&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So my advice? If you are down on the ground keep close to the research but keep closer to your intuition, provided you are ready, willing, and able to monitor, evaluate, and&amp;nbsp;adjust.&lt;/p&gt;</summary><category term="education"></category><category term="education policy"></category><category term="education reform"></category><category term="intervention"></category><category term="MATCH"></category><category term="research"></category><category term="social promotion"></category><category term="Starting an Ed School"></category></entry><entry><title>Ranked Likert-Scale Visualization</title><link href="http://blog.jsonbecker.com/2012/07/ranked-likert-scale-visualization.html" rel="alternate"></link><updated>2012-07-10T00:24:00-04:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-07-10:2012/07/ranked-likert-scale-visualization.html</id><summary type="html">&lt;h2&gt;Update&lt;/h2&gt;
&lt;p&gt;See below for more information now that Ethan Brown has &lt;a href="http://statisfactions.com/2012/improved-net-stacked-distribution-graphs-via-ggplot2-trickery/"&gt;weighed in with some great code&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;A &lt;a href="http://blog.ouseful.info/2012/07/09/fumblings-with-ranked-likert-scale-data-in-r/"&gt;recent post&lt;/a&gt; I came across on &lt;a href="http://www.r-bloggers.com/"&gt;r-bloggers&lt;/a&gt; asked for input on visualizing ranked &lt;a href="http://en.wikipedia.org/wiki/Likert_scale"&gt;Likert-scale data&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I happen to be working on a substantial project using very similarly structured data so I thought I would share some code. In my efforts to be generic as possible, I decided to generate some fake data from scratch. As I peeled away the layers of context-specific aspects of my nearing-production level code, I ran into all kinds of trouble. So I apologize for the somewhat sloppy and unfinished code&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Greaterthan" src="http://blog.jsonbecker.com/images/rankedlikert.png" title="Example of a Net Stacked Likert" /&gt; &lt;sup id="fnref:netstacked"&gt;&lt;a class="footnote-ref" href="#fn:netstacked" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;My preferred method for visualizing Likert-scale data from surveys is using &lt;a href="http://www.organizationview.com/net-stacked-distribution-a-better-way-to-visualize-likert-data"&gt;net stacked distribution graphs&lt;/a&gt;. There are two major benefits of these kinds of graphs. First, they immediately draw attention to &lt;em&gt;how strongly&lt;/em&gt; respondents feel about a question, particularly when multiple questions are visualized at once. The total width of any bar is equal to the total number of responded who had a non-neutral answer. Second, these graphs make it very easy to distinguish between positive and negative responses. In some cases, it is critical to view the distribution of data to visualize the differences in responses to one question or another. However, most of the time it is informative enough to simply know how positive or negative responses are. I find this is particularly true with 3, 4, and 5-point Likert scales, the most common I come across in education&amp;nbsp;research.&lt;/p&gt;
&lt;p&gt;Anyway, without further ado, some starter code for producing net stacked distribution&amp;nbsp;graphs.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;require&lt;span class="p"&gt;(&lt;/span&gt;ggplot2&lt;span class="p"&gt;)&lt;/span&gt;
require&lt;span class="p"&gt;(&lt;/span&gt;scales&lt;span class="p"&gt;)&lt;/span&gt;
require&lt;span class="p"&gt;(&lt;/span&gt;plyr&lt;span class="p"&gt;)&lt;/span&gt;
dataSet &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; data.frame&lt;span class="p"&gt;(&lt;/span&gt;
  q1&lt;span class="o"&gt;=&lt;/span&gt;as.ordered&lt;span class="p"&gt;(&lt;/span&gt;round&lt;span class="p"&gt;(&lt;/span&gt;runif&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; runif&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;15&lt;/span&gt;&lt;span class="p"&gt;))),&lt;/span&gt;
  q2&lt;span class="o"&gt;=&lt;/span&gt;as.ordered&lt;span class="p"&gt;(&lt;/span&gt;round&lt;span class="p"&gt;(&lt;/span&gt;runif&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;15&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; runif&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1500&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;15&lt;/span&gt;&lt;span class="p"&gt;))))&lt;/span&gt;
dataSet&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;q1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; with&lt;span class="p"&gt;(&lt;/span&gt;dataSet&lt;span class="p"&gt;,&lt;/span&gt; ifelse&lt;span class="p"&gt;(&lt;/span&gt;q1&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                       ifelse&lt;span class="p"&gt;(&lt;/span&gt;q1&lt;span class="o"&gt;&amp;gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; q1&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="m"&gt;13&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                             ifelse&lt;span class="p"&gt;(&lt;/span&gt;q1&lt;span class="o"&gt;&amp;gt;=&lt;/span&gt;&lt;span class="m"&gt;13&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; q1&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="m"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                   ifelse&lt;span class="p"&gt;(&lt;/span&gt;q1&lt;span class="o"&gt;&amp;gt;=&lt;/span&gt;&lt;span class="m"&gt;20&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; q1&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="m"&gt;26&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)))))&lt;/span&gt;
dataSet&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;q2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; with&lt;span class="p"&gt;(&lt;/span&gt;dataSet&lt;span class="p"&gt;,&lt;/span&gt; ifelse&lt;span class="p"&gt;(&lt;/span&gt;q2&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                       ifelse&lt;span class="p"&gt;(&lt;/span&gt;q2&lt;span class="o"&gt;&amp;gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; q2&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="m"&gt;14&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                             ifelse&lt;span class="p"&gt;(&lt;/span&gt;q2&lt;span class="o"&gt;&amp;gt;=&lt;/span&gt;&lt;span class="m"&gt;14&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; q2&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="m"&gt;26&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                                   ifelse&lt;span class="p"&gt;(&lt;/span&gt;q2&lt;span class="o"&gt;&amp;gt;=&lt;/span&gt;&lt;span class="m"&gt;26&lt;/span&gt; &lt;span class="o"&gt;&amp;amp;&lt;/span&gt; q2&lt;span class="o"&gt;&amp;lt;&lt;/span&gt;&lt;span class="m"&gt;28&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;5&lt;/span&gt;&lt;span class="p"&gt;)))))&lt;/span&gt;
dataSet&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;q1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; as.ordered&lt;span class="p"&gt;(&lt;/span&gt;dataSet&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;q1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
dataSet&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;q2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; as.ordered&lt;span class="p"&gt;(&lt;/span&gt;dataSet&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;q2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt;
levels&lt;span class="p"&gt;(&lt;/span&gt;dataSet&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;q1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Strongly Disagree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                             &lt;span class="s"&gt;&amp;#39;Disagree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                             &lt;span class="s"&gt;&amp;#39;Neither Agree or Disagree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                             &lt;span class="s"&gt;&amp;#39;Agree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                             &lt;span class="s"&gt;&amp;#39;Strongly Agree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
levels&lt;span class="p"&gt;(&lt;/span&gt;dataSet&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;q2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]])&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Strongly Disagree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                             &lt;span class="s"&gt;&amp;#39;Disagree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                             &lt;span class="s"&gt;&amp;#39;Neither Agree or Disagree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                             &lt;span class="s"&gt;&amp;#39;Agree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                             &lt;span class="s"&gt;&amp;#39;Strongly Agree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Convert the integer levels to have meaning.&lt;/span&gt;
q1Proportions &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; data.frame&lt;span class="p"&gt;(&lt;/span&gt;Name&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;q1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; prop.table&lt;span class="p"&gt;(&lt;/span&gt;table&lt;span class="p"&gt;(&lt;/span&gt;dataSet&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;q1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]])))&lt;/span&gt;
q2Proportions &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; data.frame&lt;span class="p"&gt;(&lt;/span&gt;Name&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;q2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; prop.table&lt;span class="p"&gt;(&lt;/span&gt;table&lt;span class="p"&gt;(&lt;/span&gt;dataSet&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;q2&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]])))&lt;/span&gt;
&lt;span class="c1"&gt;# Produces a data frame with the proportions of respondents in each level.&lt;/span&gt;

&lt;span class="c1"&gt;# ggplot2 function for graphs&lt;/span&gt;
visualize &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="p"&gt;,&lt;/span&gt;
                      responses&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Strongly Disagree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                  &lt;span class="s"&gt;&amp;#39;Disagree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                  &lt;span class="s"&gt;&amp;#39;Neither Agree or Disagree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                  &lt;span class="s"&gt;&amp;#39;Agree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                  &lt;span class="s"&gt;&amp;#39;Strongly Agree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                      desc&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Title&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                      rm.neutral&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;&lt;span class="caps"&gt;TRUE&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
  &lt;span class="c1"&gt;# This function will create net stacked distribution graphs. These are&lt;/span&gt;
  &lt;span class="c1"&gt;# a particularly useful visualization of Likert data when there is a neutral&lt;/span&gt;
  &lt;span class="c1"&gt;# option available and/or when emphasizing the difference between positive and&lt;/span&gt;
  &lt;span class="c1"&gt;# negative responses is a goal.&lt;/span&gt;
  &lt;span class="c1"&gt;# Args:&lt;/span&gt;
  &lt;span class="c1"&gt;#   data: This is a dataframe with percentages labeled with responses.&lt;/span&gt;
  &lt;span class="c1"&gt;#   responses: This is a vector with the response labels.&lt;/span&gt;
  &lt;span class="c1"&gt;#   desc: This is the title of the output ggplot2 graphic, typically the&lt;/span&gt;
  &lt;span class="c1"&gt;#         question text.&lt;/span&gt;
  &lt;span class="c1"&gt;#   rm.neutral: This is a single element logical vector that determines if the&lt;/span&gt;
  &lt;span class="c1"&gt;#               neutral response should be removed from the data. The default&lt;/span&gt;
  &lt;span class="c1"&gt;#               value is &lt;span class="caps"&gt;TRUE&lt;/span&gt;.&lt;/span&gt;
  &lt;span class="kr"&gt;for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;i &lt;span class="kr"&gt;in&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;ceiling&lt;span class="p"&gt;(&lt;/span&gt;length&lt;span class="p"&gt;(&lt;/span&gt;responses&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
      &lt;span class="c1"&gt;# This loop negates all the negative, non-neutral responses regardless of&lt;/span&gt;
      &lt;span class="c1"&gt;# the number of possible responses. This will center the non-neutral&lt;/span&gt;
      &lt;span class="c1"&gt;# responses around 0.&lt;/span&gt;
      data&lt;span class="p"&gt;[&lt;/span&gt;i&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;data&lt;span class="p"&gt;[&lt;/span&gt;i&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;rm.neutral&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="k-Variable"&gt;T&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    data &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; ddply&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="p"&gt;,&lt;/span&gt;.&lt;span class="p"&gt;(&lt;/span&gt;Name&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;)&lt;/span&gt; x&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;ceiling&lt;span class="p"&gt;(&lt;/span&gt;length&lt;span class="p"&gt;(&lt;/span&gt;responses&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)),])&lt;/span&gt;
    responses &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; responses&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;ceiling&lt;span class="p"&gt;(&lt;/span&gt;length&lt;span class="p"&gt;(&lt;/span&gt;responses&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;))]&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="kr"&gt;else&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;

  &lt;span class="p"&gt;}&lt;/span&gt;
  print&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="p"&gt;)&lt;/span&gt;
  stackedchart &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; ggplot&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                  layer&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="o"&gt;=&lt;/span&gt;data&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,],&lt;/span&gt;
                        mapping&lt;span class="o"&gt;=&lt;/span&gt;aes&lt;span class="p"&gt;(&lt;/span&gt;Name&lt;span class="p"&gt;,&lt;/span&gt;Freq&lt;span class="p"&gt;,&lt;/span&gt;fill&lt;span class="o"&gt;=&lt;/span&gt;Var1&lt;span class="p"&gt;,&lt;/span&gt;order&lt;span class="o"&gt;=-&lt;/span&gt;as.numeric&lt;span class="p"&gt;(&lt;/span&gt;Var1&lt;span class="p"&gt;)),&lt;/span&gt;
                        geom&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;bar&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        position&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;stack&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        stat&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;identity&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  stackedchart &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; stackedchart &lt;span class="o"&gt;+&lt;/span&gt;
                  layer&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="o"&gt;=&lt;/span&gt;data&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,],&lt;/span&gt;
                        mapping&lt;span class="o"&gt;=&lt;/span&gt;aes&lt;span class="p"&gt;(&lt;/span&gt;Name&lt;span class="p"&gt;,&lt;/span&gt;Freq&lt;span class="p"&gt;,&lt;/span&gt;fill&lt;span class="o"&gt;=&lt;/span&gt;Var1&lt;span class="p"&gt;,&lt;/span&gt;order&lt;span class="o"&gt;=&lt;/span&gt;Var1&lt;span class="p"&gt;),&lt;/span&gt;
                        geom&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;bar&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        position&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;stack&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                        stat&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;identity&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  stackedchart &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; stackedchart &lt;span class="o"&gt;+&lt;/span&gt;
                  geom_hline&lt;span class="p"&gt;(&lt;/span&gt;yintercept&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                  opts&lt;span class="p"&gt;(&lt;/span&gt;legend.title&lt;span class="o"&gt;=&lt;/span&gt;theme_blank&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                  opts&lt;span class="p"&gt;(&lt;/span&gt;axis.title.x&lt;span class="o"&gt;=&lt;/span&gt;theme_blank&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                  opts&lt;span class="p"&gt;(&lt;/span&gt;axis.title.y&lt;span class="o"&gt;=&lt;/span&gt;theme_blank&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                  opts&lt;span class="p"&gt;(&lt;/span&gt;title&lt;span class="o"&gt;=&lt;/span&gt;desc&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                  scale_y_continuous&lt;span class="p"&gt;(&lt;/span&gt;labels&lt;span class="o"&gt;=&lt;/span&gt;percent&lt;span class="p"&gt;,&lt;/span&gt;
                                     limits&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                                     breaks&lt;span class="o"&gt;=&lt;/span&gt;seq&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;.2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                  scale_fill_manual&lt;span class="p"&gt;(&lt;/span&gt;limits&lt;span class="o"&gt;=&lt;/span&gt;responses&lt;span class="p"&gt;,&lt;/span&gt;
                                    values&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;#&lt;span class="caps"&gt;AA1111&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                             &lt;span class="s"&gt;&amp;#39;#&lt;span class="caps"&gt;BB6666&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                             &lt;span class="s"&gt;&amp;#39;#&lt;span class="caps"&gt;66BB66&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                             &lt;span class="s"&gt;&amp;#39;#&lt;span class="caps"&gt;11AA11&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                  coord_flip&lt;span class="p"&gt;()&lt;/span&gt;
  stackedchart
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And the results of all&amp;nbsp;that?&lt;/p&gt;
&lt;p&gt;&lt;img alt="I wish it were prettier, but this is where I got." src="http://blog.jsonbecker.com/images/fakeexample.png" /&gt;&lt;/p&gt;
&lt;h2&gt;&lt;span class="caps"&gt;UPDATE&lt;/span&gt;:&lt;/h2&gt;
&lt;p&gt;So now that Ethan has weighed in with his code I thought I would add some things to make this post better reflect my production code. Below, I have included my comment on his blog as well as an actual copy of my current production code (which definitely is not sufficiently refactored for easy use across multiple projects). Again, excuse what I consider to be incomplete work on my part. I do intend on refactoring this code and eventually including it in my broader set of custom functions available across all of my projects. I suspect along that path that I will be &amp;#8220;stealing&amp;#8221; some of Ethan&amp;#8217;s&amp;nbsp;ideas.&lt;/p&gt;
&lt;h3&gt;Comment&lt;/h3&gt;
&lt;p&gt;Hi Ethan! Super excited to see this post. This is exactly why I put up my code&amp;#8212; so others could run with it. There are a few things that you do here that I actually already had implemented into my code and removed in an attempt to be more neutral to scale that I really&amp;nbsp;like.&lt;/p&gt;
&lt;p&gt;For starters, in my actual production code I also separate out the positive and negative responses. In my code, I have a parameter called &lt;code&gt;scaleName&lt;/code&gt; that allows me to switch between all of the scales that are available in my survey data. This includes Strongly Disagree to Strongly Agree (&lt;code&gt;scaleName=='sdsa'&lt;/code&gt;), Never -&gt; Always (&lt;code&gt;scaleName=='sdsa'&lt;/code&gt;) and even simple yes/no (&lt;code&gt;scaleName=='ny'&lt;/code&gt;). This is not ideal because it does require 1) knowing all possible scales and including some work in the function to treat them differently 2) including an additional parameter. However, because I use this work to analyze just a few surveys, the upfront work of including this as a parameter has made this very flexible in dealing with multiple scales. As a result, I do not need to require that the columns are ordered in any particular way, just that the titles match existing scales. So I have a long set of if elseif statements that look something like&amp;nbsp;this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;scaleName&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;sdsa&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
scale &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Strongly Disagree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Disagree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Agree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Strongly Agree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
pos &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Agree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Strongly Agree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
neg &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Strongly Disagree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Disagree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This is actually really helpful for producing negative values and including some scales in my function which do not have values that are negative (so that it can be used for general stacked charts instead of just&amp;nbsp;net-stacked):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;length&lt;span class="p"&gt;(&lt;/span&gt;neg&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
quest&lt;span class="p"&gt;[,&lt;/span&gt;names&lt;span class="p"&gt;(&lt;/span&gt;quest&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%in%&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;neg&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;quest&lt;span class="p"&gt;[,&lt;/span&gt;names&lt;span class="p"&gt;(&lt;/span&gt;quest&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%in%&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;neg&lt;span class="p"&gt;)])&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;(Recall that quest is what I call the dataframe and is equivalent to x in your&amp;nbsp;code)&lt;/p&gt;
&lt;p&gt;Another neat trick that I have instituted is having dynamic x-axis limits rather than always going from -100 to 100. I generally like to keep my scales representing the full logical range of data (0 - 100 for percentages, etc) so I might consider this a manipulation. However, after getting many charts with stubby centers, I found I was not really seeing sufficient variation by sticking to my -100 to 100 setup. So I added&amp;nbsp;this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;pos_lims &lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="m"&gt;+1&lt;/span&gt;&lt;span class="p"&gt;))[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,]),&lt;/span&gt;
sum&lt;span class="p"&gt;(&lt;/span&gt;subset&lt;span class="p"&gt;(&lt;/span&gt;quest&lt;span class="p"&gt;,&lt;/span&gt;select&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;which&lt;span class="p"&gt;(&lt;/span&gt;quest&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="m"&gt;+1&lt;/span&gt;&lt;span class="p"&gt;))[&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,])))&lt;/span&gt;
neg_lims &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; max&lt;span class="p"&gt;(&lt;/span&gt;abs&lt;span class="p"&gt;(&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;sum&lt;span class="p"&gt;(&lt;/span&gt;subset&lt;span class="p"&gt;(&lt;/span&gt;quest&lt;span class="p"&gt;,&lt;/span&gt; 
                                 select&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;which&lt;span class="p"&gt;(&lt;/span&gt;quest&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;))[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,]),&lt;/span&gt;
sum&lt;span class="p"&gt;(&lt;/span&gt;subset&lt;span class="p"&gt;(&lt;/span&gt;quest&lt;span class="p"&gt;,&lt;/span&gt;select&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;which&lt;span class="p"&gt;(&lt;/span&gt;quest&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="m"&gt;+1&lt;/span&gt;&lt;span class="p"&gt;))[&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,]))))&lt;/span&gt;
x_axis_lims &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; max&lt;span class="p"&gt;(&lt;/span&gt;pos_lims&lt;span class="p"&gt;,&lt;/span&gt;neg_lims&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Which helps to determine the value furthest from 0 in either direction across the data frame (I have to admit, this code looks a bit like magic reading it back. My comments actually are quite&amp;nbsp;helpful:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c1"&gt;# pos_lims and neg_lims subset each row of the data based on sign, then&lt;/span&gt;
&lt;span class="c1"&gt;# sums the values that remain (gettting the total positive or negative&lt;/span&gt;
&lt;span class="c1"&gt;# percentage for each row). Then, the max of the rows is saved as a candidate&lt;/span&gt;
&lt;span class="c1"&gt;# for the magnitude of the axis.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;To make this more generalizable (my production code always compares two bars at once) , it would be fairly trivial to loop over all the rows (or use the apply functions which I&amp;#8217;m still trying to get a hang&amp;nbsp;of).&lt;/p&gt;
&lt;p&gt;I then pad the &lt;code&gt;x_limits&lt;/code&gt; value by some percent inside the &lt;code&gt;limits&lt;/code&gt; attribute.&lt;/p&gt;
&lt;p&gt;In my production code I also have the &lt;code&gt;scale_fill_manual&lt;/code&gt; attribute
added separately to the ggplot object. However, rather than add this
after the fact like at the point of rendering, I include this in my
function again set by &lt;code&gt;scaleName&lt;/code&gt;. However, I think the best organization
is probably to have a separate function that makes it easy to select the
color scheme you want and apply it so that your final call could be
something like &lt;code&gt;colorNetStacked(net_stacked(x), 'blues')&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;My actual final return looks like&amp;nbsp;this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="kr"&gt;return&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;stackedchart &lt;span class="o"&gt;+&lt;/span&gt; scale_fill_manual&lt;span class="p"&gt;(&lt;/span&gt;limits&lt;span class="o"&gt;=&lt;/span&gt;scale&lt;span class="p"&gt;,&lt;/span&gt;
values&lt;span class="o"&gt;=&lt;/span&gt;colors&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
coord_flip&lt;span class="p"&gt;())&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Where colors is set by a line like: &lt;code&gt;colors &amp;lt;- brewer.pal(name='Blues',n=7)[3:7]&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Seriously though, I am super excited you found my post and thought it was useful and improved what I&amp;nbsp;presented!&lt;/p&gt;
&lt;h3&gt;Current production&amp;nbsp;code:&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;visualize &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;quest&lt;span class="p"&gt;,&lt;/span&gt;scaleName&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;sdsa&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;desc&lt;span class="p"&gt;){&lt;/span&gt;
  &lt;span class="c1"&gt;# Produces the main net-stacked Likert graphic used for survey data in the&lt;/span&gt;
  &lt;span class="c1"&gt;# diagnostic tool&lt;/span&gt;
  &lt;span class="c1"&gt;# Args:&lt;/span&gt;
  &lt;span class="c1"&gt;#  quest: data.frame from pull() or pullByLevel() output&lt;/span&gt;
  &lt;span class="c1"&gt;#  scaleName: string code for the type of scale that is used for the question.&lt;/span&gt;
  &lt;span class="c1"&gt;#  desc: string for the title that will be displayed on the graphic.&lt;/span&gt;
  &lt;span class="c1"&gt;# Returns:&lt;/span&gt;
  &lt;span class="c1"&gt;# Net-Stacked Likert chart with a bar/row for each row in quest. Most scales&lt;/span&gt;
  &lt;span class="c1"&gt;# center around 0 with a distinct positive and negative set of responses.&lt;/span&gt;
  &lt;span class="c1"&gt;# The graphs are custom colored based on what best reflects the scale.&lt;/span&gt;
  &lt;span class="c1"&gt;# The x-axis limits are set dynamically based on a 10% buffer of the largest&lt;/span&gt;
  &lt;span class="c1"&gt;# magnitude to either the positive or negative responses.&lt;/span&gt;

  &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;scaleName&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;sdsa&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    scale &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Strongly Disagree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Disagree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Agree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Strongly Agree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    pos   &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Agree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Strongly Agree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    neg   &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Strongly Disagree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Disagree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="kr"&gt;else&lt;/span&gt; &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;scaleName&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;da&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    scale &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Disagree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Agree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    pos   &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Agree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    neg   &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Disagree&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="kr"&gt;else&lt;/span&gt; &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;scaleName&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;neal&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    scale &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Never&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Sometimes&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Usually&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Always&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    pos   &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Usually&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Always&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    neg   &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Never&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Sometimes&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="kr"&gt;else&lt;/span&gt; &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;scaleName&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;noalot&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    scale &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;None&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;A Little&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Some&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;A Lot&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    pos   &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;None&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;A Little&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Some&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;A Lot&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    neg   &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;()&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="kr"&gt;else&lt;/span&gt; &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;scaleName&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;noall&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    scale &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;None of them&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Some&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Most&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;All of them&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    pos   &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;None of them&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Some&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Most&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;All of them&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    neg   &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;()&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="kr"&gt;else&lt;/span&gt; &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;scaleName&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;neda&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    scale &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Never&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;A Few Times a Year&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Monthly&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Weekly&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Daily&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    pos   &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Never&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;A Few Times a Year&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Monthly&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Weekly&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Daily&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    neg   &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;()&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="kr"&gt;else&lt;/span&gt; &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;scaleName&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ny&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    scale &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;No&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Yes&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    pos   &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Yes&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    neg   &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;No&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="kr"&gt;else&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
    print&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Unrecognized Scale Name&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="c1"&gt;# Remove neutral and non-response based values in the pull tables like&lt;/span&gt;
  &lt;span class="c1"&gt;# n-size, Not Applicable, etc.&lt;/span&gt;
  quest &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; quest&lt;span class="p"&gt;[,&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;names&lt;span class="p"&gt;(&lt;/span&gt;quest&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%in%&lt;/span&gt;
    c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;n&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Not Applicable&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;I don&amp;#39;t know&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)]&lt;/span&gt;

  &lt;span class="c1"&gt;# Produce values less than 0 for negative responses&lt;/span&gt;
  &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;length&lt;span class="p"&gt;(&lt;/span&gt;neg&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
  quest&lt;span class="p"&gt;[,&lt;/span&gt;names&lt;span class="p"&gt;(&lt;/span&gt;quest&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%in%&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;neg&lt;span class="p"&gt;)]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;
    &lt;span class="o"&gt;-&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;quest&lt;span class="p"&gt;[,&lt;/span&gt;names&lt;span class="p"&gt;(&lt;/span&gt;quest&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;%in%&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;neg&lt;span class="p"&gt;)])&lt;/span&gt;
  &lt;span class="c1"&gt;# pos_lims and neg_lims subset each row of the data based on sign, then&lt;/span&gt;
  &lt;span class="c1"&gt;# sums the values that remain (gettting the total positive or negative&lt;/span&gt;
  &lt;span class="c1"&gt;# percentage for each row). Then, the max of the rows is saved as a candidate&lt;/span&gt;
  &lt;span class="c1"&gt;# for the magnitude of the axis.&lt;/span&gt;
  pos_lims &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; max&lt;span class="p"&gt;(&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;sum&lt;span class="p"&gt;(&lt;/span&gt;subset&lt;span class="p"&gt;(&lt;/span&gt;quest&lt;span class="p"&gt;,&lt;/span&gt;select&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;which&lt;span class="p"&gt;(&lt;/span&gt;quest&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="m"&gt;+1&lt;/span&gt;&lt;span class="p"&gt;))[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,]),&lt;/span&gt;
                    sum&lt;span class="p"&gt;(&lt;/span&gt;subset&lt;span class="p"&gt;(&lt;/span&gt;quest&lt;span class="p"&gt;,&lt;/span&gt;select&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;which&lt;span class="p"&gt;(&lt;/span&gt;quest&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="m"&gt;+1&lt;/span&gt;&lt;span class="p"&gt;))[&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,])))&lt;/span&gt;
  neg_lims &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; max&lt;span class="p"&gt;(&lt;/span&gt;abs&lt;span class="p"&gt;(&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;sum&lt;span class="p"&gt;(&lt;/span&gt;subset&lt;span class="p"&gt;(&lt;/span&gt;quest&lt;span class="p"&gt;,&lt;/span&gt;select&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;which&lt;span class="p"&gt;(&lt;/span&gt;quest&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="m"&gt;+1&lt;/span&gt;&lt;span class="p"&gt;))[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,]),&lt;/span&gt;
                        sum&lt;span class="p"&gt;(&lt;/span&gt;subset&lt;span class="p"&gt;(&lt;/span&gt;quest&lt;span class="p"&gt;,&lt;/span&gt;select&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;which&lt;span class="p"&gt;(&lt;/span&gt;quest&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="m"&gt;+1&lt;/span&gt;&lt;span class="p"&gt;))[&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,]))))&lt;/span&gt;

  &lt;span class="c1"&gt;# The actual magnitude of the axis is the largest magnitude listed in pos_lims&lt;/span&gt;
  &lt;span class="c1"&gt;# or neg_lims, and will be inflated by .1 in each direction in the scale later&lt;/span&gt;
  x_axis_lims &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; max&lt;span class="p"&gt;(&lt;/span&gt;pos_lims&lt;span class="p"&gt;,&lt;/span&gt;neg_lims&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="kr"&gt;else&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;

  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="c1"&gt;# Reshape the data so that each row has one value with a variable label.&lt;/span&gt;
  quest &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; melt&lt;span class="p"&gt;(&lt;/span&gt;quest&lt;span class="p"&gt;,&lt;/span&gt;id.vars&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Var1&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="c1"&gt;# Factoring and ordering the response label ensures they are listed in the&lt;/span&gt;
  &lt;span class="c1"&gt;# proper order in the legend and on the stacked chart, i.e. strongly disagree&lt;/span&gt;
  &lt;span class="c1"&gt;# is furthest left and strongly agree is furthest right.&lt;/span&gt;
  quest&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;variable&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; factor&lt;span class="p"&gt;(&lt;/span&gt;quest&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;variable&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]],&lt;/span&gt;
                                levels&lt;span class="o"&gt;=&lt;/span&gt;scale&lt;span class="p"&gt;,&lt;/span&gt;
                                ordered&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;&lt;span class="caps"&gt;TRUE&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

  &lt;span class="c1"&gt;# Build the plot using ggplot(). Layers are used so that positive and negative&lt;/span&gt;
  &lt;span class="c1"&gt;# can be drawn separately. This is important because the order of the negative&lt;/span&gt;
  &lt;span class="c1"&gt;# values needs to be switched.&lt;/span&gt;

  &lt;span class="c1"&gt;##### Control flow required to change the behavior for the questions that&lt;/span&gt;
  &lt;span class="c1"&gt;##### business requirements call for 0-100 scale with no indication of&lt;/span&gt;
  &lt;span class="c1"&gt;##### positive or negative, i.e. the neda, noalot, and noall scaleName.&lt;/span&gt;
  stackedchart &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; ggplot&lt;span class="p"&gt;()&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
    layer&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="o"&gt;=&lt;/span&gt;subset&lt;span class="p"&gt;(&lt;/span&gt;quest&lt;span class="p"&gt;,&lt;/span&gt;
                      variable &lt;span class="o"&gt;%in%&lt;/span&gt; pos&lt;span class="p"&gt;),&lt;/span&gt;
          mapping&lt;span class="o"&gt;=&lt;/span&gt;aes&lt;span class="p"&gt;(&lt;/span&gt;Var1&lt;span class="p"&gt;,&lt;/span&gt;
                      value&lt;span class="p"&gt;,&lt;/span&gt;
                      fill&lt;span class="o"&gt;=&lt;/span&gt;factor&lt;span class="p"&gt;(&lt;/span&gt;variable&lt;span class="p"&gt;)),&lt;/span&gt;
          geom&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;bar&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
          stat&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;identity&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
          position&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;stack&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
    geom_hline&lt;span class="p"&gt;(&lt;/span&gt;yintercept&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
    opts&lt;span class="p"&gt;(&lt;/span&gt;legend.title&lt;span class="o"&gt;=&lt;/span&gt;theme_blank&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
    opts&lt;span class="p"&gt;(&lt;/span&gt;axis.title.x&lt;span class="o"&gt;=&lt;/span&gt;theme_blank&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
    opts&lt;span class="p"&gt;(&lt;/span&gt;axis.title.y&lt;span class="o"&gt;=&lt;/span&gt;theme_blank&lt;span class="p"&gt;())&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
    opts&lt;span class="p"&gt;(&lt;/span&gt;title&lt;span class="o"&gt;=&lt;/span&gt;desc&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;length&lt;span class="p"&gt;(&lt;/span&gt;neg&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
    stackedchart &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; stackedchart &lt;span class="o"&gt;+&lt;/span&gt;
      layer&lt;span class="p"&gt;(&lt;/span&gt;data&lt;span class="o"&gt;=&lt;/span&gt;subset&lt;span class="p"&gt;(&lt;/span&gt;quest&lt;span class="p"&gt;,&lt;/span&gt;
                        variable &lt;span class="o"&gt;%in%&lt;/span&gt; neg&lt;span class="p"&gt;),&lt;/span&gt;
            mapping&lt;span class="o"&gt;=&lt;/span&gt;aes&lt;span class="p"&gt;(&lt;/span&gt;Var1&lt;span class="p"&gt;,&lt;/span&gt;
                        value&lt;span class="p"&gt;,&lt;/span&gt;
                        fill&lt;span class="o"&gt;=&lt;/span&gt;factor&lt;span class="p"&gt;(&lt;/span&gt;variable&lt;span class="p"&gt;),&lt;/span&gt;
                        order&lt;span class="o"&gt;=-&lt;/span&gt;as.numeric&lt;span class="p"&gt;(&lt;/span&gt;variable&lt;span class="p"&gt;)),&lt;/span&gt;
            geom&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;bar&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            stat&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;identity&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
            position&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;stack&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="kr"&gt;else&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;

  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;scaleName &lt;span class="o"&gt;%in%&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;sdsa&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;neal&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)){&lt;/span&gt;
    colors &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;#&lt;span class="caps"&gt;AA1111&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;#&lt;span class="caps"&gt;BB6666&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;#&lt;span class="caps"&gt;66BB66&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;#&lt;span class="caps"&gt;11AA11&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    stackedchart &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;  stackedchart &lt;span class="o"&gt;+&lt;/span&gt;
      scale_y_continuous&lt;span class="p"&gt;(&lt;/span&gt;labels&lt;span class="o"&gt;=&lt;/span&gt;percent&lt;span class="p"&gt;,&lt;/span&gt;
                         limits&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;x_axis_lims&lt;span class="m"&gt;-.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; x_axis_lims&lt;span class="m"&gt;+.1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                         breaks&lt;span class="o"&gt;=&lt;/span&gt;seq&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;round&lt;span class="p"&gt;(&lt;/span&gt;x_axis_lims&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="m"&gt;-.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                    round&lt;span class="p"&gt;(&lt;/span&gt;x_axis_lims&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="m"&gt;+.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                    &lt;span class="m"&gt;.2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="kr"&gt;else&lt;/span&gt; &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;scaleName &lt;span class="o"&gt;%in%&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ny&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;da&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)){&lt;/span&gt;
    colors &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;#&lt;span class="caps"&gt;BB6666&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;#&lt;span class="caps"&gt;66BB66&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    stackedchart &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;  stackedchart &lt;span class="o"&gt;+&lt;/span&gt;
      scale_y_continuous&lt;span class="p"&gt;(&lt;/span&gt;labels&lt;span class="o"&gt;=&lt;/span&gt;percent&lt;span class="p"&gt;,&lt;/span&gt;
                         limits&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;x_axis_lims&lt;span class="m"&gt;-.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; x_axis_lims&lt;span class="m"&gt;+.1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                         breaks&lt;span class="o"&gt;=&lt;/span&gt;seq&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="o"&gt;-&lt;/span&gt;round&lt;span class="p"&gt;(&lt;/span&gt;x_axis_lims&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="m"&gt;-.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                    round&lt;span class="p"&gt;(&lt;/span&gt;x_axis_lims&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="m"&gt;+.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                    &lt;span class="m"&gt;.2&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="kr"&gt;else&lt;/span&gt; &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;scaleName &lt;span class="o"&gt;%in%&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;noalot&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;noall&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)){&lt;/span&gt;
    colors &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; brewer.pal&lt;span class="p"&gt;(&lt;/span&gt;name&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Blues&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;n&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    stackedchart &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;  stackedchart &lt;span class="o"&gt;+&lt;/span&gt;
      scale_y_continuous&lt;span class="p"&gt;(&lt;/span&gt;labels&lt;span class="o"&gt;=&lt;/span&gt;percent&lt;span class="p"&gt;,&lt;/span&gt;
                         limits&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;1.05&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                         breaks&lt;span class="o"&gt;=&lt;/span&gt;seq&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;.1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="kr"&gt;else&lt;/span&gt; &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;scaleName &lt;span class="o"&gt;%in%&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;neda&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)){&lt;/span&gt;
    colors &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; brewer.pal&lt;span class="p"&gt;(&lt;/span&gt;name&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Blues&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;n&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;7&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    stackedchart &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;  stackedchart &lt;span class="o"&gt;+&lt;/span&gt;
      scale_y_continuous&lt;span class="p"&gt;(&lt;/span&gt;labels&lt;span class="o"&gt;=&lt;/span&gt;percent&lt;span class="p"&gt;,&lt;/span&gt;
                         limits&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;1.05&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
                         breaks&lt;span class="o"&gt;=&lt;/span&gt;seq&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;.1&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;&lt;span class="kr"&gt;else&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
    print&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Unrecognized scaleName&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="kr"&gt;return&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;stackedchart &lt;span class="o"&gt;+&lt;/span&gt; scale_fill_manual&lt;span class="p"&gt;(&lt;/span&gt;limits&lt;span class="o"&gt;=&lt;/span&gt;scale&lt;span class="p"&gt;,&lt;/span&gt;
                                          values&lt;span class="o"&gt;=&lt;/span&gt;colors&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
                        coord_flip&lt;span class="p"&gt;())&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:netstacked"&gt;
&lt;p&gt;Net Stacked Likert graphs are excellent for comparing how different groups responded to the same question. There is both high information density and clarity.&amp;#160;&lt;a class="footnote-backref" href="#fnref:netstacked" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Mainly, I would like to abstract this code further. I am only about halfway there to assuring that I can use Likert-scale data of any size. I also would like to take in more than one question simultaneously with the visualize function. The latter is already possible in my production code and is particularly high impact for these kinds of graphics&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="data"></category><category term="data analysis"></category><category term="ggplot2"></category><category term="likert-scale"></category><category term="plyr"></category><category term="r-bloggers"></category><category term="rstats"></category><category term="survey analysis"></category></entry><entry><title>Work Place Liberty in the Context of Education</title><link href="http://blog.jsonbecker.com/2012/07/work-place-liberty-in-the-context-of-education.html" rel="alternate"></link><updated>2012-07-09T09:40:00-04:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-07-09:2012/07/work-place-liberty-in-the-context-of-education.html</id><summary type="html">&lt;p&gt;How can we tell if principal directives are fair to&amp;nbsp;teachers?&lt;/p&gt;
&lt;p&gt;There has been a great conversation circling some blogs I read over the last week about liberty in the work place.&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;
Issues of fairness in the work place are a constant in today&amp;#8217;s education conversation. Whether some view it as a form of metaphoric violence on teachers and their profession, while others see a concerted effort to change rigid, bureaucratic systems that prevent effective change&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;, at the heart of education reform &lt;em&gt;du jour&lt;/em&gt; are changes to workplace freedom. Improving human capital systems has meant dismantling questionable licensing requirements&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;, dramatic changes in &lt;a href="http://www.ride.ri.gov/EducatorQuality/EducatorEvaluation/Default.aspx"&gt;teacher&lt;/a&gt; &lt;a href="http://dcps.dc.gov/DCPS/In+the+Classroom/Ensuring+Teacher+Success/IMPACT+(Performance+Assessment)/An+Overview+of+IMPACT"&gt;evaluation&lt;/a&gt;, and other dramatic changes to who gets &lt;a href="http://www.commercialappeal.com/news/2012/may/11/reviews-to-favor-effective-teachers/?print=1"&gt;hired&lt;/a&gt; or &lt;a href="http://en.wikipedia.org/wiki/LIFO_(education)"&gt;fired&lt;/a&gt;. Using extended learning time, either through additional instructional days and/or longer school days, to increase student achievement is often considered too costly, because teachers demand more pay for more work. Additional professional development days are similarly costly; teachers are loath to give up additional days in the summer or during school vacations without receiving additional pay. I could go&amp;nbsp;on.&lt;/p&gt;
&lt;p&gt;All of these reforms seek to radically change terms and benefits in teacher contracts and state law that represent a string of hard-fought (and won) battles that teachers and their unions pursued for years. The political left, and more specifically the progressive movement, has generally picked up on these attempts as anti-union, anti-collective bargaining, anti-democratic, anti-teacher, and anti-education. There are even a host of conspiracy theories decrying the &amp;#8220;corporate reformers&amp;#8221; who are coming into the education realm to break down good, public, democratic systems that are good for Democrats, largely to hurt poor kids and make profits&lt;sup id="fnref:4"&gt;&lt;a class="footnote-ref" href="#fn:4" rel="footnote"&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;Fundamentally, most of this argument is about what individuals ideologies have led them to believe about employee rights and employer rights. I find it increasingly frustrating that these conversations do not address the deeper philosophical differences. This is why I have really enjoyed observing the current conversation between &lt;a href="http://crookedtimber.org/"&gt;Crooked Timber&lt;/a&gt;, &lt;a href="http://bleedingheartlibertarians.com/"&gt;Bleeding Heart Libertarians&lt;/a&gt;, and&amp;nbsp;others.&lt;/p&gt;
&lt;p&gt;One of the key aspects of the &lt;span class="caps"&gt;BRG&lt;/span&gt; argument&lt;sup id="fnref:5"&gt;&lt;a class="footnote-ref" href="#fn:5" rel="footnote"&gt;5&lt;/a&gt;&lt;/sup&gt;is that worker contracts are unique because many of the terms of employment are ambiguous. Employers should only be permitted to demand that employees partake in activities to which they have consented. The contract is supposedly a signal of this consent, however, because the terms are so often ambiguous, disputes over whether or not it covers an activity are practically a guarantee. So how should these disputes be settled and by whom? &lt;span class="caps"&gt;BRG&lt;/span&gt; would argue that there should be strong worker freedom to make sure that their consent is truly given. They consider the relationship between employer and employee to be naturally coercive, at least in part because they assume the right to end employment has very asymmetric benefits since employees have, presumably, much more to lose than employers when the contract ends. &lt;span class="caps"&gt;BRG&lt;/span&gt; assumes that freedom is best served through a democratic workplace with very powerful employees who have few, if any of their rights restricted in the workplace. On the other hand, BHLers believe that it is possible to consent to restrict ones rights within a contractual relationship, they do not tend to accept that the right to exit affords highly asymmetric freedoms&lt;sup id="fnref:6"&gt;&lt;a class="footnote-ref" href="#fn:6" rel="footnote"&gt;6&lt;/a&gt;&lt;/sup&gt;, and they feel that freedom is maximized by abstaining from limiting private contracts while maximizing the rights to freely enter and exit&amp;nbsp;contracts.&lt;/p&gt;
&lt;p&gt;However, it is macroeconomist Miles Kimball, a recent entrant into the &lt;a href="http://blog.supplysideliberal.com/"&gt;blogosphere&lt;/a&gt;, whose &lt;a href="http://blog.supplysideliberal.com/post/26531357710/jobs"&gt;comments&lt;/a&gt; I felt could most directly be applied to education. If I were to summarize his post, it would&amp;nbsp;be:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;There are significant pressures against to eliminating freedoms of
    your workers that end up making them worse at their jobs or lead to
    attracting bad&amp;nbsp;talent.&lt;/li&gt;
&lt;li&gt;Although these pressures exist for &amp;#8220;The Firm&amp;#8221;, it is true that
    &amp;#8220;underbosses&amp;#8221; with significant power can act in ways that maximize
    their personal gain instead of what&amp;#8217;s good for &amp;#8220;The Firm&amp;#8221; and the
    pressures are less strong against eliminating freedoms for them than
    the organization as a&amp;nbsp;whole.&lt;/li&gt;
&lt;li&gt;Nevertheless, they should have the rights to limit/remove freedoms,
    and these limitations should be based on whether they are relevant
    to achieving the organizations pre-stated&amp;nbsp;mission.&lt;/li&gt;
&lt;li&gt;Ultimately, the right outside force to judge whether this was a
    proper imposition to make on employees should be people who have
    successfully navigated the same challenges as The Firm but have no
    direct interest in The Firms current&amp;nbsp;activities.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Each of these four points, if they are accepted as true, has some interesting applications to education. My translation for education colleagues would&amp;nbsp;be:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Districts and states have little reason to make lives shitty for
    teachers. &lt;sup id="fnref:7"&gt;&lt;a class="footnote-ref" href="#fn:7" rel="footnote"&gt;7&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;But some principals, department heads, and others may have the ability to act in ways that are less than proper. &lt;sup id="fnref:8"&gt;&lt;a class="footnote-ref" href="#fn:8" rel="footnote"&gt;8&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Actions that restrict teacher rights should be judged on whether they help the school achieve the district or school&amp;#8217;s pre-stated&amp;nbsp;mission.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Disputes between teachers and their bosses, should not be adjudicated by a typical jury or judge. Instead, the actions of the principal should be judged by other principals who have been successful, preferably with some distance from the actual organization (i.e. not principals who might compete for the offending principals job or may want to hire or be stuck with that teacher based on the&amp;nbsp;proceedings).&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;I think that points 1 and 2 are fairly obvious. Points 3 and 4, however, are far more&amp;nbsp;interesting.&lt;/p&gt;
&lt;p&gt;Kimball is attempting to split the difference a fascinating way. I believe he would accept that employment contracts are, by necessity, &amp;#8220;ambiguous&amp;#8221; in the way that &lt;span class="caps"&gt;BRG&lt;/span&gt; defines that term. His argument is, therefore, that the mission and purpose of the organization &lt;strong&gt;should not&lt;/strong&gt;be ambiguous. So long as the organization&amp;#8217;s mission is clear, an employment contract becomes consent to do whatever has a rational basis for furthering those goals. In this way, there is an ethical standard by which we can judge new situations that could never have been anticipated directly at the contracting stage. For example, it may be perfectly reasonable for a principal to require a teacher to spend lunch in the student cafeteria so long as their is a rational basis for believing this would further the mission of the&amp;nbsp;school.&lt;/p&gt;
&lt;p&gt;In highly unionized workplaces, work rules are so specific that they remove a substantial portion of the ambiguity in contracting. This is generally seen by the left, union members, and other &lt;span class="caps"&gt;BRG&lt;/span&gt;-like thinkers as a huge victory. It implies full consent to the terms of employment and substantial restriction of an employer&amp;#8217;s ability to abuse their position and abridge the freedoms of their employees in unethical ways. Schools are generally like this. Practically everything is spelled out about a teacher&amp;#8217;s position, often to the minute. How long they get to eat lunch, how much unstructured time they get during the day, how long they have to spend time working with other teachers, how long they are allowed to be placed in front of kids, how many kids can be placed in front of a teacher at any given time, these conditions and more are detailed in teacher&amp;nbsp;contracts.&lt;/p&gt;
&lt;p&gt;In my experience, when I ask a union supporter why they think unions are good, they almost always point out &amp;#8220;abuses&amp;#8221; of employers that occurred often before the union wrestled power from the grips of the few and the privileged back to the laborers. I have to wonder how much of their support comes from a lack of common, clear definition of unethical abridgments of freedom in the workplace. The solution to this ambiguity is requiring that all actions be consented to through negotiation and contracting, which also determines that dispute resolution is a matter of contract law. I have to wonder if both workers and their employers would be better off if there was a universal ethical standard like Kimball proposes. This way consent can be given while allowing more ambiguity in the contract itself. Right now employers fight for this ambiguity depending solely on appeals to trust and cooperation, two things that are rarely earned before working with someone as would be&amp;nbsp;required.&lt;/p&gt;
&lt;p&gt;I can&amp;#8217;t say that I understand labor dispute resolution well enough to comment on the differences between Kimball&amp;#8217;s fourth suggestion and current practice. However, it is pretty clear to me that enforcement through contract law is costly and inefficient, regardless whether it is effective in adjudicating disputes in an ethical matter. Labor relations boards, as far as I can tell, seem to be a political tool swaying between dramatically increasing worker power, especially when members are current or former full-time employees and members of a union, and increasing employer power when more corporate representation is assured. If only I believed it were possible to have an apolitical, disinterested board, with sector-specific expertise, determine whether there is a &amp;#8220;rational basis&amp;#8221; for employer actions that Kimball&amp;nbsp;envisions.&lt;/p&gt;
&lt;p&gt;I am left with more questions than answers, but, for me, there is a rich appeal to utilizing the mission of an organization to determine whether the actions of both it and its employees are&amp;nbsp;just.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;&lt;a href="http://crookedtimber.org/2012/07/01/let-it-bleed-libertarianism-and-the-workplace/"&gt;Here&lt;/a&gt; is the (socialist?) critique of libertarians and right to work that sparked the discussion. Then &lt;a href="http://marginalrevolution.com/marginalrevolution/2012/07/libertarianism-and-the-workplace.html"&gt;two&lt;/a&gt; economists &lt;a href="http://marginalrevolution.com/marginalrevolution/2012/07/libertarianism-and-the-workplace-ii.html"&gt;jumped&lt;/a&gt; in. The &lt;a href="http://bleedingheartlibertarians.com/2012/07/freedom-and-work/"&gt;response&lt;/a&gt; from Bleeding Heart Libertarians, meanwhile, &lt;a href="http://bleedingheartlibertarians.com/2012/07/libertarianism-the-workplace-and-the-reconciling-power-of-the-social-moral-order/"&gt;continues&lt;/a&gt; &lt;a href="http://bleedingheartlibertarians.com/2012/07/denmark-vs-france/"&gt;to&lt;/a&gt; &lt;a href="http://bleedingheartlibertarians.com/2012/07/why-are-employers-so-mean/"&gt;pour&lt;/a&gt; &lt;a href="http://bleedingheartlibertarians.com/2012/07/my-bottom-line-on-worker-freedom/"&gt;in&lt;/a&gt; &lt;a href="http://bleedingheartlibertarians.com/2012/07/cruelty-and-power/"&gt;rapidly&lt;/a&gt;. &amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;I lean toward the latter, even if I disagree sometimes both with the means and ends of the current reform movement.&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;I am skeptical about &lt;a href="http://conversableeconomist.blogspot.com/2012/05/occupational-licensing-and-low-income.html"&gt;licensing in general&lt;/a&gt;. I&amp;#8217;ve seen substantially more &lt;a href="http://www0.gsb.columbia.edu/faculty/jrockoff/certification-final.pdf"&gt;research&lt;/a&gt; to support experience than licensing requirements in education and/or additional education. Various &lt;a href="http://tntp.org/"&gt;alternative&lt;/a&gt; &lt;a href="http://www.teachforamerica.org/"&gt;teacher&lt;/a&gt; &lt;a href="http://www.bostonteacherresidency.org/"&gt;pathways&lt;/a&gt; now exist. &amp;#160;&lt;a class="footnote-backref" href="#fnref:3" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:4"&gt;
&lt;p&gt;Whereas I find some of the &amp;#8220;anti-s&amp;#8221; in the previous sentence worthy of discussion, I find the massive, corporate, right-wing conspiracy stuff to be 98% bullocks. &amp;#160;&lt;a class="footnote-backref" href="#fnref:4" rev="footnote" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:5"&gt;
&lt;p&gt;&lt;span class="caps"&gt;BRG&lt;/span&gt;= Bertram, Robin, and Gourevitch, authors of the Crooked Timber post. This acronym has been used in contrast with &lt;span class="caps"&gt;BHL&lt;/span&gt;, Bleeding Heart Libertarians, during this debate &amp;#160;&lt;a class="footnote-backref" href="#fnref:5" rev="footnote" title="Jump back to footnote 5 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:6"&gt;
&lt;p&gt;or perhaps, if they do they feel that this would not be the case in a world that more generally matched BHLs principles &amp;#160;&lt;a class="footnote-backref" href="#fnref:6" rev="footnote" title="Jump back to footnote 6 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:7"&gt;
&lt;p&gt;Here I assume that the proper size unit for &amp;#8220;The Firm&amp;#8221; is above the school. I think this generally holds because district boards and state policy makers tend to be more directly accountable to citizens than schools. The relationship here is much more like shareholders and/or customers to business than the citizen to school relationship. &amp;#160;&lt;a class="footnote-backref" href="#fnref:7" rev="footnote" title="Jump back to footnote 7 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:8"&gt;
&lt;p&gt;Here, the school-level administration represents the &amp;#8220;underbosses&amp;#8221;. Given that much of the debate over teacher evaluation and rules on hiring and firing stem from debates about both principal quality and principal power, I think this is the right assignment. &amp;#160;&lt;a class="footnote-backref" href="#fnref:8" rev="footnote" title="Jump back to footnote 8 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="bleeding heart libertarians"></category><category term="economics"></category><category term="education"></category><category term="libertarianism"></category><category term="liberty"></category><category term="political philosophy"></category><category term="public-sector unions"></category><category term="teacher evaluation"></category><category term="union"></category></entry><entry><title>Algorithms: Design and Analysis Part I</title><link href="http://blog.jsonbecker.com/2012/06/algorithms-design-and-analysis-part-i.html" rel="alternate"></link><updated>2012-06-13T09:30:00-04:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-06-13:2012/06/algorithms-design-and-analysis-part-i.html</id><summary type="html">&lt;p&gt;Tonight I started Coursera.org&amp;#8217;s &lt;a href="http://www.algo-class.org"&gt;Algorithms: Design and Analysis Part I&lt;/a&gt;. This class should pick up right about where I left off my computer science education. I took &lt;a href="http://www.cs.brown.edu/courses/csci0150.html"&gt;&lt;span class="caps"&gt;CS15&lt;/span&gt;&lt;/a&gt; as a sophomore in college but didn&amp;#8217;t have the time to take &lt;a href="http://www.cs.brown.du/courses/csci0160html"&gt;&lt;span class="caps"&gt;CS16&lt;/span&gt;: Introduction to Algorithms and Data Structures&lt;/a&gt;. So, while it&amp;#8217;s been almost 6 years since I have formally taken a computer science class, it is time to continue my&amp;nbsp;education.&lt;/p&gt;
&lt;p&gt;I plan to write about once a week about my experience. This will serve both as an opportunity to work out ideas spurred by the course as well as a review of the growing area of free, online courses that started way back in 2002 with &lt;span class="caps"&gt;MIT&lt;/span&gt;&amp;#8217;s &lt;a href="http://ocw.mit.edu/index.htm"&gt;OpenCourseWare&lt;/a&gt; and continues today with upshots &lt;a href="http://udacity.com/"&gt;Udacity&lt;/a&gt; and &lt;a href="http://www.coursera.org"&gt;Coursera&lt;/a&gt;, among &lt;a href="http://www.codeacademy.com"&gt;other players&lt;/a&gt;. Given the emphasis being placed on the potential for technology as disruptive to classroom teaching over the last 50 years, the topic seems worthy of some experiential learning by a budding young education&amp;nbsp;researcher/wonk.&lt;/p&gt;
&lt;h2&gt;Introduction and About the&amp;nbsp;Course&lt;/h2&gt;
&lt;p&gt;The Introduction video was a bit scary. Although the content was simple, Professor Tim Roughgarden is a fast talker and he does seem to skip some of the small steps that really trip me up when learning math from lectures. For example, in discussing the first recursive method to $n$-digit multiplication, Professor Roughgarden suddenly throws in a $10^n$ and $10^{n/2}$ term that I just couldn&amp;#8217;t trace. I kept watching the video waiting for an explanation and pondering it in
my mind when a few minutes later it hit me; the two terms kept the place information lost when a number is split into its constituent digits &lt;sup id="fnref:constituent"&gt;&lt;a class="footnote-ref" href="#fn:constituent" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;The About this Course video, however, provided some good advice I intend on following; although there will be no code written as a part of this course to be language neutral, I will be attempting to code each of the described algorithms on my own. Professor Roughgarden&amp;#8217;s assumption is that this is within the skills of students taking this class. Generally, I believe I am capable of achieving this in at least &lt;em&gt;some&lt;/em&gt; language. Currently, I prefer to use R. This is not because R is best suited to this kind of work. Rather, it is because I am relatively new to R, and I think that learning to program some fundamental computational tasks will be good for learning the ins and outs of the&amp;nbsp;language.&lt;/p&gt;
&lt;p&gt;However, I think I may switch over to using Python later in the course. Why? Because I feel like learning Python and Udacity happens to have a &lt;a href="http://www.udacity.com/view#Course/cs101/"&gt;course up already to do just that&lt;/a&gt;. My hope is to incorporate free online learning into my routine just like I include reading dead-tree books, Google Reader, and mess around on Twitter. So while I can&amp;#8217;t swear that I&amp;#8217;ll actually start moving through these two courses (and two more I&amp;#8217;m interested in starting June 25), I feel having complimentary, simultaneous course work will push me. Each class should reinforce the other and I should see the most benefit if I keep up with&amp;nbsp;both.&lt;/p&gt;
&lt;p&gt;Finally, this class is a big time commitment. The first week has 3.5 hours of lecture time allotted. A typical Brown class would meet for only about 2.5 hours a week (three 50 minute classes or two 80 minute classes). That means a lot of time, not including homework or spending time actually coding and implementing the introduced algorithms. Although some of this material is &amp;#8220;optional&amp;#8221; (about an hour), that&amp;#8217;s still pretty intimidating for a free, online, spare time class. Make no mistake, if time commitment is any indicator, this will be every bit as challenging (to actually learn) as a real college course that last this many&amp;nbsp;weeks.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:constituent"&gt;
&lt;p&gt;The algorithm called to split an $n$ digit number $x$ into two, $n/2$ digit numbers. What was unstated, but of course true, is that this transformation must result in an expression that was equal to $x$. Of course, $x=10^n * a+10^\frac{n}{2} * b$ , because the leading digit of $a$ must be in the $n^{th}$ place and the leading digit of $b$ must be in the $\frac{n}{2}^{th}$ place. Nothing about this is complex to me, but it was not obvious at the speed of conversation. I think working out an actual example of a 4-digit number multiplication, as Professor Roughgarden had with the &amp;#8220;primitive&amp;#8221; multiplication algorithm, would have made this far clearer.&amp;#160;&lt;a class="footnote-backref" href="#fnref:constituent" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary></entry><entry><title>Fixing Dyer Street</title><link href="http://blog.jsonbecker.com/2012/06/fixing-dyer-street.html" rel="alternate"></link><updated>2012-06-07T09:00:00-04:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-06-07:2012/06/fixing-dyer-street.html</id><summary type="html">&lt;p&gt;The removal of I-195 from the Jewelry District is supposed to help spur Providence&amp;#8217;s second renaissance by providing ample green- and brown-field development sites for a whole host of biomedical companies apparently dying to move to a state and city in fiscal crisis whose current population does not have the required skills to serve as an employment&amp;nbsp;base.&lt;/p&gt;
&lt;p&gt;Seriously, I am quite optimistic about the once-in-a-generation to develop a massive part of what should be an integral part of Providence&amp;#8217;s downtown core &lt;sup id="fnref:core"&gt;&lt;a class="footnote-ref" href="#fn:core" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;. Buildings will come, even if it is a slow, grueling process. Hopefully jobs will follow. But a key first step the incredibly busy &lt;sup id="fnref:busy"&gt;&lt;a class="footnote-ref" href="#fn:busy" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt; I-195 commission must take is elevating Dyer Street to a new hub of&amp;nbsp;activity.&lt;/p&gt;
&lt;h2&gt;Why Dyer&amp;nbsp;Street&lt;/h2&gt;
&lt;p&gt;This is a particularly important site for the redevelopment of Providence. One of the highest profile completed development projects in the Jewelry District has been &lt;a href="http://brown.edu/academics/medical/"&gt;Brown University&amp;#8217;s Alpert Medical School&lt;/a&gt; at &lt;a href="http://med.brown.edu/newbuilding/"&gt;Ship Street and Eddy Street&lt;/a&gt; &lt;sup id="fnref:dyertoeddy"&gt;&lt;a class="footnote-ref" href="#fn:dyertoeddy" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;. Further down Eddy Street, we find one of the tragic
failures of the Jewelry District, &lt;a href="http://www.flickr.com/photos/woneffe/4371630714/sizes/l/in/photostream/"&gt;Narragansett Electric Lighting&lt;/a&gt; (Dynamo House), a hulking brick site left open to the elements that was set at one point to become a museum. &lt;a href="https://maps.google.com/?ll=41.816875,-71.40651&amp;amp;spn=100.50313,204.433594&amp;amp;hnear=385+Westminster+St,+Providence,+Rhode+Island+02903&amp;amp;t=v&amp;amp;z=3&amp;amp;layer=c&amp;amp;panoid=iH5omOmwEwV_aAhyccIScQ&amp;amp;cbll=41.816875,-71.40651&amp;amp;cbp=13,28.53329819751501,,0,-6.703606203030631"&gt;One Davol Square&lt;/a&gt;, a &lt;a href="http://www.ri-cie.org/start-incubator/start-incubator"&gt;popular site for entrepreneurs&lt;/a&gt; in Providence is found where Eddy meets Point&amp;nbsp;Street.&lt;/p&gt;
&lt;p&gt;Brown University has already purchased 200 Dyer Street, which sits to the north at the &amp;#8220;start&amp;#8221; of Dyer Street between Clinton and Dorrance. This site was recently renovated and is now home to &lt;a href="http://brown.edu/ce/"&gt;Brown University&amp;#8217;s Continuing Education&lt;/a&gt;, an adult education site primarily mid-career professionals and adults. Already 200 Dyer hosts forums intended for the Providence community and, along with expanding &lt;span class="caps"&gt;CE&lt;/span&gt; into so-called &amp;#8220;&lt;a href="http://www.browndailyherald.com/proposed-executive-master-s-program-would-diversify-revenue-streams-1.2718694"&gt;executive master&amp;#8217;s programs&lt;/a&gt;&amp;#8220;, this site is likely to be a hub of substantial interaction between Brown and Providence&amp;nbsp;residents.&lt;/p&gt;
&lt;p&gt;It is easy to see that Eddy Street, from Ship Street to Point Street, is already an important hub of job-related activity in the Jewelry District. The very presence of an existing, huge, historic site between
Alpert Medical School and a major center for startups makes it likely that this stretch could see real further development. And with Brown staking claim to the &amp;#8220;mouth&amp;#8221; of Dyer Street, the makings of a Brown University &amp;#8220;West&amp;#8221; campus &lt;sup id="fnref:campuswest"&gt;&lt;a class="footnote-ref" href="#fn:campuswest" rel="footnote"&gt;4&lt;/a&gt;&lt;/sup&gt; is coming into&amp;nbsp;view.&lt;/p&gt;
&lt;p&gt;Expanding Riverwalk Park into the space between Dorrance and Ship Street as planned should be the final piece to the Dyer Street puzzle &lt;sup id="fnref:puzzle"&gt;&lt;a class="footnote-ref" href="#fn:puzzle" rel="footnote"&gt;5&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;It seems that turning Dyer Street into an &amp;#8220;A&amp;#8221; street filled with activity should be one of the easiest sells of all in the Jewelry District, given this is one of the few areas where actual purchases have taken place other than the land behind Johnson and&amp;nbsp;Wales.&lt;/p&gt;
&lt;p&gt;Luckily, as far as I can tell, Providence Planning&amp;#8217;s vision for the repairing of the street grid in this area is right on the mark, because while the land adjacent to Dyer Street from Friendship Street to Ship Street is some of the most &amp;#8220;shovel-ready&amp;#8221; land in the Jewelry District, this stretch also represents some of the most obviously damaged by the highway &lt;sup id="fnref:highway"&gt;&lt;a class="footnote-ref" href="#fn:highway" rel="footnote"&gt;6&lt;/a&gt;&lt;/sup&gt;. It is easily fixed. Dyer Street should be two ways all the way and not shift to a one-way at Peck Street. The remnants of an &amp;#8220;on&amp;#8221; ramp that serves as the northbound route connecting Ship Street and Peck Street should obviously be eliminated and subsumed in the expanded Riverwalk Park. An additional oddity left from another on ramp between Dorrance and Clifford Street should be removed, allowing the two-way Dyer to have a straighter path. Dyer should potentially be expanded to include bike lanes separated from traffic by trees on the eastern&amp;nbsp;side.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Chapinero, Bogotá Bike Path via Wikipedia" src="http://blog.jsonbecker.com/images/Chapinero_bike_path.jpg" title="Chapinero Bike Path" /&gt;&lt;/p&gt;
&lt;p&gt;Create a street like this. Encourage development on the west led by Brown University connecting Alpert Medical School to Brown Continuing Education. Bring in creative commercial development forming a continuous street wall of jobs from One Davol Square to the new, expanded park. Attach the proposed Greenway through the Jewelry District and the planned pedestrian bridge to Fox Point. Do all of this, and Dyer Street will become one of the most vibrant &lt;em&gt;places&lt;/em&gt; in&amp;nbsp;Providence.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:core"&gt;
&lt;p&gt;I am not being sarcastic here, even if I&amp;#8217;m generally dismissive and flippant about the wacky ideas that the &amp;#8220;elite&amp;#8221; in Providence and the state of Rhode Island have about this space&amp;#160;&lt;a class="footnote-backref" href="#fnref:core" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:busy"&gt;
&lt;p&gt;Okay, so here I&amp;#8217;m being sarcastic&amp;#160;&lt;a class="footnote-backref" href="#fnref:busy" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:dyertoeddy"&gt;
&lt;p&gt;Dyer turns into Eddy past Ship&amp;#160;&lt;a class="footnote-backref" href="#fnref:dyertoeddy" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:campuswest"&gt;
&lt;p&gt;I don&amp;#8217;t think they use this term&amp;#160;&lt;a class="footnote-backref" href="#fnref:campuswest" rev="footnote" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:puzzle"&gt;
&lt;p&gt;Although it appears the I-195 commission is getting cold feet on the expanse of this public space&amp;#160;&lt;a class="footnote-backref" href="#fnref:puzzle" rev="footnote" title="Jump back to footnote 5 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:highway"&gt;
&lt;p&gt;It will likely help to look at &lt;a href="https://maps.google.com/?ll=41.820716,-71.407483&amp;amp;spn=0.003274,0.006239&amp;amp;hnear=385+Westminster+St,+Providence,+Rhode+Island+02903&amp;amp;t=v&amp;amp;z=18"&gt;this view&lt;/a&gt; while reading this next section&amp;#160;&lt;a class="footnote-backref" href="#fnref:highway" rev="footnote" title="Jump back to footnote 6 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="dyer street"></category><category term="i195 land"></category><category term="jewelry district"></category><category term="knowledge district"></category><category term="providence"></category><category term="urban"></category></entry><entry><title>Downtown Improvement District</title><link href="http://blog.jsonbecker.com/2012/04/downtown-improvement-district.html" rel="alternate"></link><updated>2012-04-25T09:30:00-04:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-04-25:2012/04/downtown-improvement-district.html</id><summary type="html">&lt;p&gt;[&lt;img alt="DID taking care of Downcity planters" src="http://blog.jasonpbecker.com/wp-content/uploads/2012/04/did5.jpeg" title="DID Doing a Great Job" /&gt;][][/caption]&lt;/p&gt;
&lt;p&gt;I am a firm believer that some goods &lt;em&gt;should be&lt;/em&gt; &lt;a href="http://en.wikipedia.org/wiki/Public_goods"&gt;public&lt;/a&gt;. I do not believe that my tax dollars are about providing &lt;em&gt;direct&lt;/em&gt; personal benefit. I like redistributed tax policy. But it is hard to be a Rhode Islander, surrounded by government institutions &lt;a href="http://www.golocalprov.com/news/julia-steiny-woonsockets-nosedive-a-cautionary-tale/"&gt;that&lt;/a&gt; are
&lt;a href="http://www.golocalprov.com/news/procap/"&gt;failing&lt;/a&gt;, and feel good about the taxes I pay. Corruption and &lt;a href="http://www2.turnto10.com/news/2012/apr/06/former-uri-president-enters-sport-institute-scanda-ar-991425/"&gt;cronyism&lt;/a&gt; is a daily reality of government business. Some agencies have &lt;a href="http://www.ripec.org/pdfs/2009-AI-Study.pdf"&gt;tremendous waste and inefficiency&lt;/a&gt;. Worse, many public institutions that are failing their mission and wasting money are actually woefully underfunded. &lt;sup id="fnref:underfunded"&gt;&lt;a class="footnote-ref" href="#fn:underfunded" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;If more government institutions functioned like the Downtown Improvement District, there would be greater trust and support for government&amp;nbsp;services.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Some of the best money I spend each year is the approximately \$200-250 that I send to the &lt;a href="http://downtownprovidence.com/clean-safe/"&gt;Downtown Improvement District&lt;/a&gt; (&lt;span class="caps"&gt;DID&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;I live within a special assessment district in Providence that levies an additional property tax to pay for the ladies and gentlemen in bright yellow jackets that are a constant presence in my neighborhood. For a small tax each year, my neighborhood&amp;nbsp;gets:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;substantial cleanup /sanitation services that removes the mountains of trash that can pile up during a busy night where &lt;a href="http://jwu.edu/providence/"&gt;college students&lt;/a&gt;, &lt;a href="http://www.ppacri.org/"&gt;theater&lt;/a&gt; &lt;a href="http://www.trinityrep.com/"&gt;goers&lt;/a&gt;, &lt;a href="http://graciesprovidence.com/"&gt;restaurant patrons&lt;/a&gt;, nightclub patrons, &lt;a href="http://www.hotelprovidence.com/"&gt;tourists&lt;/a&gt;, and &lt;a href="http://www.waterfire.org/"&gt;Waterfire&lt;/a&gt; visitors all converge on&amp;nbsp;Downcity &lt;/li&gt;
&lt;li&gt;excellent landscaping including planting and pruning trees, maintaining flowerbeds, hanging flower pots on light posts,&amp;nbsp;etc. &lt;/li&gt;
&lt;li&gt;responsive care of public property including removing safety hazards, e.g. removing the cement, waist-high barrier that had fallen on the sidewalk by my building that was a major safety hazard for&amp;nbsp;pedestrians &lt;/li&gt;
&lt;li&gt;easily identifiable public presence in addition to cops that increases the safety and security of busy city&amp;nbsp;street &lt;/li&gt;
&lt;li&gt;much, much&amp;nbsp;more.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It may seem selfish, but honestly, this is the best government service I current receive. It is inexpensive. I am able to see a direct increase in my quality of life in Downcity. It clearly increases and protects my property investment. I get an annual budget that is fairly detailed
mailed annually that explains precisely what my dollars purchased and how they will be used in the coming&amp;nbsp;years.&lt;/p&gt;
&lt;p&gt;When the currently dormant&lt;a href="http://providencecoreconnector.com/"&gt;^0&lt;/a&gt;[] announced they would seek to use a special assessment district to fund operation expenses, &lt;a href="http://blog.jasonpbecker.com/2011/09/26/downcity-residents-should-support-the-core-connector-and-the-tax-makes-sense/"&gt;I was all for it&lt;/a&gt;. Sure, a
portion of my support came from the simple economics, but I would be lying if I did not admit that the wonderful relationship I have with the Downtown Improvement District was not a part of my consideration. The &lt;span class="caps"&gt;DID&lt;/span&gt; has provided an excellent model to Downcity residents demonstratingthe efficacy of using the greatest (but not sole) beneficiary of place-bound services as a revenue source. Does anyone really believe that Downtown would have doubled its residency from 2000-2010 &lt;sup id="fnref:census"&gt;&lt;a class="footnote-ref" href="#fn:census" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt; if the &lt;span class="caps"&gt;DID&lt;/span&gt; were not&amp;nbsp;around?&lt;/p&gt;
&lt;p&gt;[&lt;img alt="DID taking care of Downcity planters" src="http://blog.jasonpbecker.com/wp-content/uploads/2012/04/did5.jpeg" title="DID Doing a Great Job" /&gt;]:&amp;nbsp;http://www.providenceri.com/CityNews/newsletter2.php?id=290&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;&lt;a href="http://t.co/zmwvItBf"&gt;let&amp;#8217;s change that&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:underfunded"&gt;
&lt;p&gt;See Pawtucket and Woonsocket on &lt;a href="http://www.ride.ri.gov/Finance/funding/Uniform%20Chart%20of%20Accounts/2010/STATE/FY10%20Equalized%20Expenditures%20Report%20-%20Sorted.pdf"&gt;this chart&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:underfunded" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:census"&gt;
&lt;p&gt;&lt;span class="caps"&gt;US&lt;/span&gt; Census Bureau. Check out this &lt;a href="http://gis.providenceplanning.org/PVD_2010CensusViewer/"&gt;great resource&lt;/a&gt; that the &lt;a href="http://www.providenceri.com/planning/"&gt;Providence Planning Department&lt;/a&gt; put up&amp;#160;&lt;a class="footnote-backref" href="#fnref:census" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="core connector"></category><category term="department of planning and development"></category><category term="downcity"></category><category term="jewelry district"></category><category term="knowledge district"></category><category term="providence"></category><category term="public goods"></category><category term="rhode island"></category><category term="ri"></category><category term="streetcar"></category><category term="tax"></category><category term="urban development"></category><category term="westminster street"></category></entry><entry><title>Providence needs a little innovation</title><link href="http://blog.jsonbecker.com/2012/03/providence-needs-a-little-innovation.html" rel="alternate"></link><updated>2012-03-20T09:00:00-04:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-03-20:2012/03/providence-needs-a-little-innovation.html</id><summary type="html">&lt;p&gt;Have you ever tried to access public information about &lt;a href="http://www.providenceri.com"&gt;Providence&lt;/a&gt; on the web? Due to the recent, and new, requirement that residents reapply for their homestead tax exemption in Providence, I decided to poke around the Providence webpage to see what kind of &lt;a href="http://providence.ias-clt.com/parcel.list.php"&gt;public information on property was available online&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I was greeted with an &lt;span class="caps"&gt;IT&lt;/span&gt; nightmare&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;The system was clearly a third-party developed or purchased front end designed for searching public records on property and sold to municipalities throughout the country by winning contracts through the &lt;span class="caps"&gt;RFP&lt;/span&gt; process. It&amp;#8217;s also clearly no longer supported (or supported poorly), outdated, and running on hardware that&amp;#8217;s probably about as powerful as an 8-year-old desktop computer. The system crawls, when it&amp;#8217;s not completely still, and provides no means of easy export that I can&amp;nbsp;find.&lt;/p&gt;
&lt;p&gt;This was really disappointing to me. In an earlier post, I began to look at some simple data available on the Providence Journal&amp;#8217;s webpage about recent sales. I was hoping to use an &lt;span class="caps"&gt;API&lt;/span&gt; (and in the worst case, a massive data dump) to get access to information about the assessed value of recently sold properties and to play around a bit with various heat maps and see what patterns are revealed. Even if there were some way to get access to the data, the application is so poor I definitely do not have the&amp;nbsp;patience required.&lt;/p&gt;
&lt;p&gt;This is a real shame, because one of the great things about data on property is that it is all public information. This means that the data could be shared widely to creative policy wonks, data geeks, and &lt;span class="caps"&gt;CS&lt;/span&gt; nerds looking for a weekend project. There are now two cities&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;in the &lt;span class="caps"&gt;US&lt;/span&gt; that are employing a &lt;a href="http://www.theatlanticcities.com/technology/2012/03/dawn-muncipal-chief-innovation-officer/1516"&gt;new kind of &lt;span class="caps"&gt;CIO&lt;/span&gt;&lt;/a&gt;&amp;#8212; the Chief &lt;em&gt;Innovation&lt;/em&gt; Officer&amp;#8212; whose role is to connect government resources, be they employees, data, or infrastructure, with folks who can do something new, exciting, and useful for city&amp;nbsp;residents.&lt;/p&gt;
&lt;p&gt;Developers designed one application in San Francisco to reduce the &amp;#8220;notoriously cumbersome hurdles for starting a new business.&amp;#8221;&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;Does anyone happen to know of another city, perhaps without the rich, entrepreneurial technology and science economy it lusts for, that is not known as an easy place to set up shop? &lt;a href="http://www.providenceri.com"&gt;Hint&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;When Brown University has an excellent computer science department made up of undergrads who work on side projects like &lt;a href="http://brown.mochacourses.com"&gt;developing an online course catalog&lt;/a&gt; since the &lt;a href="http://www.browndailyherald.com/2.12225/ucs-criticizes-new-banner-course-catalog-1.1674252#.T2frNWJSRe8"&gt;Brown purchased system sucks&lt;/a&gt;, it&amp;#8217;s hard not to conclude that there are latent geek talents just waiting to be tapped. And it&amp;#8217;s not just Brown that could be engaged. What about &lt;a href="http://swipely.com/"&gt;Swipely&lt;/a&gt;, the newest tech startup from entrepreneur &lt;a href="http://angusdavis.com/"&gt;Angus Davis&lt;/a&gt;, a Rhode Island native who is very active in local government and developing Providence. An exciting. fledging technology company with young, smart folks who do application development with huge swaths of data every day is an excellent source of the kind of talent Providence needs. Why hasn&amp;#8217;t someone approached Swipely about a charity opportunity&amp;#8212; take all non-essential staff off their current projects, give them a break from the deadlines and typical day, and get them working furiously for a week on rolling out something awesome and useful for city residents. It would reinvigorate young coders and greatly benefit the&amp;nbsp;city.&lt;/p&gt;
&lt;p&gt;Heck, something as simple as getting in and teaching government employees how to spin up instances of &lt;a href="http://aws.amazon.com/"&gt;Amazon &lt;span class="caps"&gt;EC2&lt;/span&gt;&lt;/a&gt; &lt;sup id="fnref:4"&gt;&lt;a class="footnote-ref" href="#fn:4" rel="footnote"&gt;4&lt;/a&gt;&lt;/sup&gt; so they can migrate off self-managed, slow servers for non-secure information would be huge. Imagine this, plus rolling an &lt;span class="caps"&gt;API&lt;/span&gt; for critical municipal data sets. There would be a rich environment for hobbyists, students, and professionals alike to spark some creative ways to understand and interact with&amp;nbsp;Providence.&lt;/p&gt;
&lt;p&gt;Another example, assuming it&amp;#8217;s legal, how long do you think it would take a smart developer, dedicated solely to one task, to roll a system that would cross-reference Providence landowners with the &lt;span class="caps"&gt;DMV&lt;/span&gt; registration database so that myself and other residents didn&amp;#8217;t have to trek out documentation to City Hall to avoid a 50% tax&amp;nbsp;hike?&lt;/p&gt;
&lt;p&gt;Providence is not San Francisco, but there are many talented developers and data scientists who are passionate enough about the city to donate their time and expertise. Honestly, for many of these folks there are real personal benefits, even without appealing to some sentiment of civic duty. So let&amp;#8217;s open up our data, our infrastructure, and our employees. Let&amp;#8217;s encourage folks from outside of government to inject excitement and new skills for current government &lt;span class="caps"&gt;IT&lt;/span&gt; employees and&amp;nbsp;analysts.&lt;/p&gt;
&lt;p&gt;It&amp;#8217;s time for Providence&amp;#8217;s own &amp;#8220;Summer of&amp;nbsp;Code&amp;#8221;.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;To be fair, when I accessed the site today the site was substantially more functional than it was in two previous visits several weeks ago&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;San Francisco, unsurprisingly, and Philadelphia&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;From &lt;a href="http://www.theatlanticcities.com"&gt;The Atlantic Cities&lt;/a&gt; article linked above. &amp;#160;&lt;a class="footnote-backref" href="#fnref:3" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:4"&gt;
&lt;p&gt;&lt;a href="http://csrc.nist.gov/groups/SMA/fisma/index.html"&gt;&lt;span class="caps"&gt;FISMA&lt;/span&gt;&lt;/a&gt; compliant &amp;#160;&lt;a class="footnote-backref" href="#fnref:4" rev="footnote" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="brown university"></category><category term="charity"></category><category term="data"></category><category term="downcity"></category><category term="innovation"></category><category term="providence"></category><category term="public goods"></category><category term="rhode island"></category><category term="ri"></category><category term="technology"></category></entry><entry><title>Social Promotion, Tutoring, and Funding</title><link href="http://blog.jsonbecker.com/2012/02/social-promotion-tutoring-and-funding.html" rel="alternate"></link><updated>2012-02-15T09:30:00-05:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-02-15:2012/02/social-promotion-tutoring-and-funding.html</id><summary type="html">&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/Social_promotion"&gt;Social promotion&lt;/a&gt;, in education circles, refers to the practice of allowing students to move on to the next grade level or course even though they are unable to demonstrate they have mastered the skills and knowledge they were expected to learn. Ending or reducing social promotion has been a major theme in the standards-based education reform of the last 10-15 years. Ending social promotion feels like a sound, obvious consequence of standards-based education. Each year (or course) comes with set of standards that articulate what students must know and be able to do once complete. Since the standards of the following course will assume proficiency on previous standards, there is a fundamental common sense to prohibiting students to move to the next level before they have conquered all prior&amp;nbsp;levels.&lt;/p&gt;
&lt;p&gt;In reality, this is a gross oversimplification bordering on &lt;em&gt;reductio ad absurdum&lt;/em&gt;. Allow me to throw a few wrinkles into the carrion calls for social promotion&amp;#8217;s demise. First, some standards do not come packaged with lofty presumptions of prior knowledge or skills. For example, a student could be quite successful in a high school chemistry or physics course without being successful in biology. In fact many students take these three courses in a sequence which explicitly prevents taking advantage of the natural interrelatedness of these sciences&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;. For sure there are some skills that serve as critical gateways to future standards and expectations, but a student may fail a course while still having all of the core scaffolding in place for the next course level. Second, it is unclear that repeating a class (or entire grade-level) is an effective mechanism to successfully attain acceptable achievement. What proportion of content that will be repeated has a student already successfully learned without need for reinforcement? Are the strategies and pedagogy employed to teach students new material the same as those used to re-teach material? I&amp;#8217;m doubtful. Then there are behavioral and social concerns. What are the impacts on a student&amp;#8217;s self-esteem? What are the impacts, particularly in elementary schools, of mixing students at even greater age ranges? If students must relearn content, reread the same books, etc, what will happen to their level of engagement with the material? What is the impact of isolating students from their friends in a way that might feel like&amp;nbsp;punishment?&lt;/p&gt;
&lt;p&gt;There&amp;#8217;s research on both sides of this issue&amp;#8212; some that demonstrates that students who are held back &lt;a href="http://www.mitpressjournals.org/doi/pdf/10.1162/edfp.2007.2.4.319"&gt;do better academically&lt;/a&gt;&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;, and some that show outcomes are no better or worse. The impact on the socio-emotional side also seems mixed, although there is more consensus around negative consequences for being held back. That being said, much of the research I have read on social promotion looks at all students being held back in various contexts and not specifically examining long-term effects within a large-scale implementation that regularizes the process, which perhaps decreases the social stigma of being held back and increases the efficacy of teachers with held back students. I am having a hard time remembering at the moment, but I can&amp;#8217;t recall a large-scale study that used regression discontinuity (and instrumental variable) like the previously linked Jay P. Greene Florida study that took a robust look at socio-economic outcomes. Less rigorous methodologies may introduce substantial bias to results&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;That being said, I generally think that social promotion is not ideal. In a perfect world, principals and district leaders would have a better sense of how well teachers are able to differentiate instruction in their classrooms more precisely. This way, they could adequately determine when a student is so far behind expectations that it is unreasonable to expect teachers to deliver the necessary instruction in a mixed-ability classroom. When a student is that far behind at the end of the school year, targeted summer intervention would attempt to bring a student to within an acceptable range by the start of the next school year. If this fails, then, and only then, should a student be held&amp;nbsp;back.&lt;/p&gt;
&lt;p&gt;None of this is new. In fact, Wikipedia led me to an &lt;a href="http://www2.ed.gov/pubs/socialpromotion/intro.html"&gt;article about social promotion&lt;/a&gt; archived on the &lt;span class="caps"&gt;US&lt;/span&gt; Department of Education webpage from May 1999 that is strikingly similar to everything I wrote above&lt;sup id="fnref:4"&gt;&lt;a class="footnote-ref" href="#fn:4" rel="footnote"&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;Emily Richardson has a great post in &lt;a href="http://www.theatlantic.com/national/archive/2012/02/closing-the-literacy-gap-the-trouble-with-holding-back-students/253065/"&gt;The Atlantic&lt;/a&gt; &lt;sup id="fnref:5"&gt;&lt;a class="footnote-ref" href="#fn:5" rel="footnote"&gt;5&lt;/a&gt;&lt;/sup&gt;about an intriguing alternative. &lt;a href="https://webapp4.asu.edu/directory/person/28597"&gt;David Berliner&lt;/a&gt;, an Arizona State University professor of education,&amp;nbsp;says,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;Everybody supports the idea that if a student isn&amp;#8217;t reading well in
third grade that it&amp;#8217;s a signal that the child needs help. If you hold
them back, you&amp;#8217;re going to spend roughly another \$10,000 per child
for an extra year of schooling. If you spread out that \$10,000 over
the fourth and fifth grades for extra tutoring, in the long run you&amp;#8217;re
going to get a better&amp;nbsp;outcome.&amp;#8221;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;There has recently been an increase in &lt;a href="http://www.economics.harvard.edu/faculty/fryer/files/charter_school_strategies.pdf"&gt;evidence&lt;/a&gt; about the efficacy of intensive, very small group (like two-on-one) tutoring at raising academic achievement based on a &amp;#8220;successful replication&amp;#8221; of the &lt;a href="http://www.matchschool.org/"&gt;&lt;span class="caps"&gt;MATCH&lt;/span&gt; Charter School&amp;#8217;s&lt;/a&gt; tutoring program in the &lt;a href="http://www.houstonisd.org/"&gt;Houston Independent School District&amp;#8217;s&lt;/a&gt; &lt;a href="http://www.houstonisd.org/HISDConnectDS/v/index.jsp?vgnextoid=436bcd7298b69210VgnVCM10000028147fa6RCRD"&gt;Apollo 20&lt;/a&gt; Program&lt;sup id="fnref:6"&gt;&lt;a class="footnote-ref" href="#fn:6" rel="footnote"&gt;6&lt;/a&gt;&lt;/sup&gt;. Intensive one-on-one support has several key advantages that address some of my &amp;#8220;wrinkles&amp;#8221; about social promotion above. The instruction is specifically catered toward the exact standards that a student is weak on (and possibly on standards that are more foundational to future learning). The strategies and techniques used to teach a student may not be the same as whole-classroom, first-time exposure learning. The intervention strategy feels more like a surplus than deficit-driven policy, i.e. students are receiving &lt;em&gt;more&lt;/em&gt; because of their achievement not being &amp;#8220;punished&amp;#8221;. And that is not remotely an exhaustive&amp;nbsp;list.&lt;/p&gt;
&lt;p&gt;The problem is that education funding is not structured to spend the way that Berliner is recommending. Revenues are often raised or doled out on a per pupil basis so holding a student for an extra year will virtually automatically result in additional formula-driven dollars&lt;sup id="fnref:7"&gt;&lt;a class="footnote-ref" href="#fn:7" rel="footnote"&gt;7&lt;/a&gt;&lt;/sup&gt;. There is no way to flag a student as needing the &amp;#8220;5th-year high school&amp;#8221; funding now, in the form of two years of intensive, one-on-one tutoring in elementary or middle school. I am not sure I think that&amp;#8217;s a good thing, because I really do think that Berliner is on to something here. The cost-effectiveness of the total investment in any one student identified as being at risk of falling seriously behind is likely to be far higher providing a huge influx of resources to be used entirely on individualized intervention rather than offering an entire extra year of education overall and repeating a specific&amp;nbsp;grade.&lt;/p&gt;
&lt;p&gt;The logistics of supporting this kind of intervention with anything but local or private revenue is causing my brain to do mental gymnastics, but the complexity might really be worth the&amp;nbsp;benefits.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;An aside for another day. &amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;ending social promotion based on standardized assessments offers pretty much a textbook example of regression discontinuity studies, which I think is kind of cool&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;Although woefully outdated and using a source from 1986, the &lt;a href="http://en.wikipedia.org/wiki/Grade_retention#Research"&gt;research section of the Wikipedia page on grade retention&lt;/a&gt; outlines this in effective and simple language&amp;#160;&lt;a class="footnote-backref" href="#fnref:3" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:4"&gt;
&lt;p&gt;I did find the article after I wrote this post&amp;#160;&lt;a class="footnote-backref" href="#fnref:4" rev="footnote" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:5"&gt;
&lt;p&gt;And on her blog, The Educated Reporter&amp;#160;&lt;a class="footnote-backref" href="#fnref:5" rev="footnote" title="Jump back to footnote 5 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:6"&gt;
&lt;p&gt;Of course there is lot of past research to support this idea, but I do think that &lt;a href="http://www.economics.harvard.edu/faculty/fryer"&gt;Fryer&lt;/a&gt;&amp;#8216;s Apollo 20 evaluation has reinvigorated discussion around the effectiveness of this type of intervention in the past several months. &amp;#160;&lt;a class="footnote-backref" href="#fnref:6" rev="footnote" title="Jump back to footnote 6 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:7"&gt;
&lt;p&gt;In theory, at least. Of course many states are reducing their state aid formula in funky ways and there are loopholes in most maintenance of effort laws that are now being rigorously used to allow for per pupil decreases in local revenues&amp;#160;&lt;a class="footnote-backref" href="#fnref:7" rev="footnote" title="Jump back to footnote 7 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="cost-benefit analysis"></category><category term="edpolicy"></category><category term="education"></category><category term="education funding"></category><category term="efficiency"></category><category term="intervention"></category><category term="MATCH"></category><category term="social promotion"></category><category term="standards-based reform"></category><category term="tutoring"></category></entry><entry><title>Worth It: Five Stories from the Last Week</title><link href="http://blog.jsonbecker.com/2012/02/worth-it-five-stories-from-the-last-week.html" rel="alternate"></link><updated>2012-02-09T09:00:00-05:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-02-09:2012/02/worth-it-five-stories-from-the-last-week.html</id><summary type="html">&lt;p&gt;I read literally hundreds of posts from &lt;span class="caps"&gt;RSS&lt;/span&gt; feeds every day. I use &lt;a href="http://reader.google.com"&gt;Google Reader&lt;/a&gt; as an aggregator, &lt;a href="http://reederapp.com"&gt;Reeder&lt;/a&gt; to actually read through my feeds, and &lt;a href="http://www.pinboard.in/u:jasonpbecker"&gt;Pinboard&lt;/a&gt; for social bookmarking and posting&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;In order to capture just a small slice of the stories I really enjoyed, I&amp;#8217;ve decided to start a new feature called &amp;#8220;Worth It&amp;#8221;. I hope this will be between 3 and 5 stories each week with some quick commentary that I think are worth anyone&amp;#8217;s time to read. This week I&amp;#8217;ve thrown together five stories kind of haphazardly, but in the future I hope these posts will lean toward highlighting longer features or reports as opposed to more blog or typical article-length&amp;nbsp;pieces.&lt;/p&gt;
&lt;p&gt;Feel free to use the comment section to recommend some stories that were &amp;#8220;Worth It&amp;#8221; from the last week that I may have&amp;nbsp;missed.&lt;/p&gt;
&lt;h2&gt;&lt;a href="http://gothamschools.org/2012/02/07/from-school-facing-turnaround-a-tale-of-academic-perseverance/"&gt;From school facing turnaround, a tale of academic&amp;nbsp;perseverance&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The first &amp;#8220;Worth It&amp;#8221; piece is a great &lt;a href="http://www.gothamschools.org"&gt;Gotham Schools&lt;/a&gt; piece about a student who was nearly lost between the cracks in the New York City school system, doomed to a tough life by coincidence, mishap, and possibly negligence. Unlike most students faced with such abject systematic failure, Moustafa Elhanafi&amp;#8217;s story has a happy ending. Although he found himself illiterate and with no prospects at 18, he is now set on a course to graduate with his high school diploma ready for college by the time he is 21. Elhanafi was born in the United States but lived in Egypt with his mother from age 2 until age 8. At 8 years old, he moved back to New York City and lived with his father in Queens. When he was 11, the &lt;span class="caps"&gt;NYC&lt;/span&gt; had so totally failed him that they misdiagnosed him with mental retardation. The article hints at several reasons this calamity of errors may have occurred. Elhanafi was an English language learner, which can challenge the typical screening methods that trained social workers, psychologists, etc have at their disposable. He is described as shy and at times, withdrawn. It&amp;#8217;s quite possible that Elhanafi suffers from one or more learning disabilities and/or other unique psychosocial abnormalities, but it is also abundantly clear that being quarantined in programs designed for students with severe and profound special needs was no help. I strongly recommend you read this story and find out more about just what it takes to educate a student like Elhanafi. Without giving too much away, I&amp;#8217;ll just say that this is an uplifting story that shows how much compassion and dedication, from teachers, parents, and students can&amp;nbsp;accomplish.&lt;/p&gt;
&lt;h2&gt;&lt;a href="http://www.insidehighered.com/news/2012/02/07/rice-university-announces-open-source-textbooks"&gt;Why Pay for Intro&amp;nbsp;Textbooks?&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://www.rice.edu/"&gt;Rice University&lt;/a&gt; is admirably seeking to tackle the textbook publishing industry the right way&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;. Producing free, open source, traditional, peer-reviewed textbooks for the post-secondary market is well worth the investment. The internet may have democratized content creation, search may have increased the relevance of the sea of materials, and social media may have helped to curate quality out of the still massive relevant web. None of these are a substitute for true expertise subjected to a robust revision and editorial process on the road to peer expert approval. &lt;a href="http://en.wikipedia.org"&gt;Wikipedia&lt;/a&gt; is one of the few corners of the web to get quality right, but the mental model users have when in an encyclopedia is perusal; there is no way to clearly stake out a path through Wikipedia to thoroughly learn a set body of knowledge. Textbooks offer an organizational framework that brings clarity, context, and connectivity to the&amp;nbsp;information.&lt;/p&gt;
&lt;h2&gt;&lt;a href="http://blogs.edweek.org/edweek/campaign-k-12/2012/02/charter_advocates_say_federal.html"&gt;Charter Advocates Claim Rules in Works Would Affect&amp;nbsp;Pensions&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;This is a real wonky one. Essentially the &lt;span class="caps"&gt;IRS&lt;/span&gt; is tackling with how we define a government employee. The way some proposed rules are now written, it&amp;#8217;s possible that charter school teachers will not be considered &amp;#8220;government employees&amp;#8221;. As a result, their inclusion in government pension systems can jeopardize several special protections because the systems will no longer be considered public. Virtually all states allow charter school teachers to participate in state plans, and a few, including Rhode Island, require that all charter school teachers take part in the state operated teacher pension system. There are several excellent reasons for this policy, even if it costs charter schools more money than they might like. First, because pension benefits are a major form of compensation for teachers and they accrue with experience, participation in a state pension system serves to immobilize the teacher labor force. In fact, most states centrally operate their pension systems specifically to allow teachers to move across schools and districts without sacrificing their pensions. This is desirable if we want more efficient labor market sorting since optimal sorting requires minimal (and preferably negligent) transaction costs. Charter schools want the option to draw from current public school teachers and their ability to do so is greatly limited if benefits that have accrued over the course of a career are lost or severely diminished due to transitioning into a charter&amp;nbsp;school.&lt;/p&gt;
&lt;p&gt;I am not at all sympathetic to the notion that charter schools are not public schools. Although we might debate the extent to which they are democratic&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;, they are clearly public entities. They supply a public good entirely through taxpayer dollars with almost all the financial accountability (and sometimes more) requirements of traditional public schools. All federal public education laws and regulations apply to these schools as do the majority of state law and regulation (in most instances). Charter schools are public schools. But because charter school employees are technically directly accountable to a board that is typically not democratically elected, it is apparently debatable whether or not they are government employees. This seems odd to me. I work for the Rhode Island Department of Education and I am clearly considered a state employee. Yet my employer is a Commissioner of Education who is hired by the Board of Regents. The Board of Regents is an appointed body, not democratically elected. So while they may, in so ways, be directly accountable to elected officials, it&amp;#8217;s a long way off to find direct democratic accountability for my position. In many ways, charter school employees have far fewer layers between them and the public, yet my government employee status would never come into&amp;nbsp;question.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;I use &lt;a href="http://www.ifttt.com"&gt;&lt;span class="caps"&gt;IFTTT&lt;/span&gt;&lt;/a&gt; triggers based on Pinboard tags to post to &lt;a href="http://www.twitter.com/jasonpbecker"&gt;Twitter&lt;/a&gt;, &lt;a href="http://tumblr.jasonpbecker.com"&gt;Tumblr&lt;/a&gt;, &lt;a href="http://www.facebook.com/jason.p.becker"&gt;Facebook&lt;/a&gt;, etc&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;Apple&amp;#8217;s iBooks Author is awful in comparison. Bringing what are essentially web page authoring tools to the masses and wrapping the materials in a proprietary shell is just awful on so many levels. This strategy just shifts the cost from individual books to the devices the books need to run on. These devices have a lifespan that&amp;#8217;s shorter than a typical textbook and are very expensive. &amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;using Sarah Goldrick-Rab&amp;#8217;s recently offered definition, which described democratic to me as the extent to which stakeholders directly participate in institutional governance and decision-making&amp;#160;&lt;a class="footnote-backref" href="#fnref:3" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="charters"></category><category term="education"></category><category term="highered"></category><category term="news"></category><category term="open source"></category><category term="textbooks"></category><category term="worth it"></category></entry><entry><title>Bank of America will leave 111 Westminster</title><link href="http://blog.jsonbecker.com/2012/01/bank-of-america-will-leave-111-westminster.html" rel="alternate"></link><updated>2012-01-31T20:55:00-05:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-01-31:2012/01/bank-of-america-will-leave-111-westminster.html</id><summary type="html">&lt;p&gt;&lt;a href="http://www.flickr.com/photos/34463371@N08/"&gt;&lt;img alt="111 Westminster lit at night by Flickr user kehuston" src="http://blog.jsonbecker.com/images/111west.jpg" /&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;I was pretty disappointed, but not surprised, that Bank of America &lt;a href="http://www.pbn.com/Bank-of-America-to-vacate-Superman-building-,64983"&gt;has chosen to leave&lt;/a&gt; 111 Westminster Street. The building is an iconic anchor to downtown Providence. Unfortunately, this space has not been properly refurbished to more modern standards. The entire building has a single, antiquated utilities system&amp;#8212; heating, cooling, electricity, etc are all setup for a single tenant. Weighing in at 350,000 square feet, there is simply no one in Providence who needs an old, out of date workspace of that size. Renovations, at this point, are likely to be very expensive, although &lt;a href="http://www.theatlanticcities.com/housing/2012/01/why-most-environmental-building-building-weve-already-built/1016/"&gt;environmental advocates&lt;/a&gt; and &lt;a href="http://chronicle.com/blogs/buildings/costume-jewelry-factory-will-become-browns-medical-school-saving-35-million/26293"&gt;businessmen&lt;/a&gt; alike should unite around refurbishing over &lt;a href="http://news.providencejournal.com/breaking-news/2011/11/21/195_redevelopment.JPG"&gt;new construction&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Downtown Providence &lt;sup id="fnref:downcity"&gt;&lt;a class="footnote-ref" href="#fn:downcity" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; has no shortage of &lt;a href="http://www.pbn.com/2011-turning-point-for-commercial-real-estate,63603?category_id=79&amp;amp;sub_type=stories,packages"&gt;vacant space&lt;/a&gt;. Saving 111 Westminster is going to take creative thinking and substantial investment. Fortunately, there is no better time since the &lt;a href="http://www.gcpvd.org/2012/01/20/the-arcade-are-you-kidding-me-with-this/"&gt;Arcade is undergoing some exciting changes&lt;/a&gt;. &lt;sup id="fnref:arcade"&gt;&lt;a class="footnote-ref" href="#fn:arcade" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;Because of the near perfect alignment of 111 Westminster and the Arcade,
I&amp;#8217;d love to see some true, deep collaboration that rethinks the area on
Westminster Street between Exchange and Dorrance Streets &lt;sup id="fnref:dorrance"&gt;&lt;a class="footnote-ref" href="#fn:dorrance" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;. Activating this space at the street level will be a huge boon to the Arcade, 111 Westminster, and the success of Downtown as a whole. I&amp;#8217;ve got a handful of ideas, but I lack the skills to make beautiful pictures to make my visions&amp;nbsp;tangible.&lt;/p&gt;
&lt;p&gt;So I&amp;#8217;m going to just have to hope that &lt;a href="http://www.gcpvd.org"&gt;Greater City: Providence&lt;/a&gt; recognizes this as the opportunity for a new &lt;a href="http://www.gcpvd.org/category/features/reboot/"&gt;Reboot&lt;/a&gt;, my personal favorite work on the site. In their&amp;nbsp;words,&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;&lt;span class="caps"&gt;REBOOT&lt;/span&gt;&lt;/strong&gt; is an occasional series of posts on &lt;em&gt;Greater City:
Providence&lt;/em&gt; where we identify areas of the city that display poor
urbanism and propose ways to improve them. Our interventions may be
simple and quite easily realized, or they may at times be grand and
possibly take years or decades to complete. Either way, we hope they
generate interest and&amp;nbsp;discussion.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Past Reboot&amp;#8217;s have featured the &lt;a href="http://www.gcpvd.org/2011/06/08/reboot-providence-train-station/"&gt;Providence Train Station&lt;/a&gt; and &lt;a href="http://www.gcpvd.org/2010/08/17/reboot-olneyville-square/"&gt;Olneyville Square&lt;/a&gt;, among others. Let&amp;#8217;s Reboot 111 Westminster and the Arcade, and the whole area east of Dorrance &lt;sup id="fnref:110west"&gt;&lt;a class="footnote-ref" href="#fn:110west" rel="footnote"&gt;4&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The original title of this post was unintentionally, overly similar to &lt;span class="caps"&gt;GCPVD&lt;/span&gt;&amp;#8217;s post on this issue. I recognized this oversight independently and have edited the&amp;nbsp;title.&lt;/em&gt;&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:downcity"&gt;
&lt;p&gt;I am desperately trying to drop &amp;#8220;Downcity&amp;#8221; in favor of &amp;#8220;Downtown&amp;#8221; after training myself to say Downcity.&amp;#160;&lt;a class="footnote-backref" href="#fnref:downcity" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:arcade"&gt;
&lt;p&gt;I know I&amp;#8217;ve been cranky about the Arcade plans, but I think that&amp;#8217;s more about my general mood than the merits of the redevelopment. It could work, and if it does, it will be very exciting for Downtown.&amp;#160;&lt;a class="footnote-backref" href="#fnref:arcade" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:dorrance"&gt;
&lt;p&gt;I&amp;#8217;d love to see traffic closed along both Weybosset and Westminster from Memorial Boulevard down to Dorrance.&amp;#160;&lt;a class="footnote-backref" href="#fnref:dorrance" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:110west"&gt;
&lt;p&gt;And 110 Westminster, while we&amp;#8217;re at it, the massive condo tower-turned parking lot&amp;#160;&lt;a class="footnote-backref" href="#fnref:110west" rev="footnote" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="110 westminster"></category><category term="arcade"></category><category term="downcity"></category><category term="land use"></category><category term="providence"></category><category term="ri"></category><category term="urban development"></category><category term="westminster street"></category><category term="superman"></category></entry><entry><title>Providence Pensions— Let’s Call a Spade a Spade (or the COLA a Raise)</title><link href="http://blog.jsonbecker.com/2012/01/providence-pensions-lets-call-a-spade-a-spade-or-the-cola-a-raise.html" rel="alternate"></link><updated>2012-01-25T20:25:00-05:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-01-25:2012/01/providence-pensions-lets-call-a-spade-a-spade-or-the-cola-a-raise.html</id><summary type="html">&lt;p&gt;&lt;a href="https://twitter.com/#!/tednesi"&gt;Ted Nesi&lt;/a&gt; has done a pretty solid job tracing the &lt;a href="http://www.wpri.com/dpp/news/local_news/providence/prov-pensions-hit-by-comedy-of-errors?2"&gt;history&lt;/a&gt; of some awful decisions made by union-dominated boards that resulted in a significant number of retirees in the early-90s receiving 5% or 6% annually compounded interest on their retirement income. These are often called COLAs, or &lt;a href="http://en.wikipedia.org/wiki/Cost-of-living_adjustment"&gt;cost-of-living adjustments&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Today, I am inspired by Nesi&amp;#8217;s &lt;a href="http://blogs.wpri.com/2012/01/25/chart-the-decline-and-fall-of-the-providence-pension-system/"&gt;post&lt;/a&gt; on the rapid decline of the Providence municipal pension fund health that occurred since 6% &amp;#8220;&lt;span class="caps"&gt;COLA&lt;/span&gt;&amp;#8221; was introduced in 1989 through today. You see, something has really been bugging me about the conversation on municipal pensions in Rhode Island. A true &lt;span class="caps"&gt;COLA&lt;/span&gt; is key to ensuring that purchasing power is maintained throughout retirement. Essentially, quality of life and ability to buy required goods should be consistent from the day you retire until the day you die. This is a goal that makes a lot of sense. But the cost of goods has not increased 5% or 6% year-over-year ever in the past twenty years &lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;So I chose a key moment in the history of Providence municipal pensions&amp;#8212; a 1991 consent decree &lt;sup id="fnref:decree"&gt;&lt;a class="footnote-ref" href="#fn:decree" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; that then Mayor Buddy Cianci signed, solidifying and legitimizing the extremely high &amp;#8220;&lt;span class="caps"&gt;COLA&lt;/span&gt;&amp;#8221; for workers. I wanted to know, &amp;#8220;What would a worker retiring in the following year (1992) be making today if they retired with a \$25,000 annual pension and had a 6% &amp;#8216;&lt;span class="caps"&gt;COLA&lt;/span&gt;&amp;#8217;, 5% &amp;#8216;&lt;span class="caps"&gt;COLA&lt;/span&gt;&amp;#8217;, or a &lt;span class="caps"&gt;COLA&lt;/span&gt; based on the Northeast &lt;span class="caps"&gt;CPI&lt;/span&gt;-U?&amp;#8221; Not wanting to make a key mistake and &lt;a href="http://en.wikipedia.org/wiki/Cost-of-living_adjustment#CPI_is_not_a_COLA"&gt;equate a &lt;span class="caps"&gt;CPI&lt;/span&gt; with a &lt;span class="caps"&gt;COLA&lt;/span&gt;&lt;/a&gt;, I increased the &lt;span class="caps"&gt;CPI&lt;/span&gt;-U for each year by 25%, figuring that this is a reasonable approximation of the marginal taxes that would be paid on additional income by these&amp;nbsp;retirees.&lt;/p&gt;
&lt;p&gt;I suspected that 5% and 6% do not really result in a cost-of-living adjustment, but rather a clear wage increase for retired workers. I have no problem maintaining parity or near-parity with retirement level income, but there&amp;#8217;s absolute no reason someone who retired should receive a wage. My support for a true &lt;span class="caps"&gt;COLA&lt;/span&gt; is so strong that I made the adjustment for taxes on&amp;nbsp;income!&lt;/p&gt;
&lt;p&gt;What were the&amp;nbsp;results?&lt;/p&gt;
&lt;p&gt;&lt;img alt="Amazing what compound interest does" src="http://blog.jsonbecker.com/images/inflation1.png" title="Comparing COLA to CPI-U" /&gt;&lt;/p&gt;
&lt;p&gt;A Providence employee who retired in 1992 with a \$25,000 pension would be receiving \$46,132 in 2011 if their retirement was increased by inflation + the marginal tax rate (assumed here as 25%). But a Providence employee who retired with the same pension in 1992 under the conditions in Providence could expect \$63,174 at 5% or \$75,640 at the 5% and 6% rates, respectively. This is a &lt;span class="caps"&gt;MASSIVE&lt;/span&gt; difference which cannot constitute a&amp;nbsp;&amp;#8220;&lt;span class="caps"&gt;COLA&lt;/span&gt;&amp;#8221;.&lt;/p&gt;
&lt;p&gt;So I move that we stop referring to these particular pensions as having a &amp;#8220;&lt;span class="caps"&gt;COLA&lt;/span&gt;&amp;#8221;, because what really happened was a fixed raise was created to last for the rest of retirees&amp;#8217;&amp;nbsp;lives.&lt;/p&gt;
&lt;p&gt;Some additional neat&amp;nbsp;facts:&lt;/p&gt;
&lt;p&gt;Over 20 years, an individual who has a 6% raise per year will have collected \$228,672 more than someone who had a &lt;span class="caps"&gt;COLA&lt;/span&gt;. An individual with a 5% raise per year will have collected \$135,681.10 over the same 20 year&amp;nbsp;period.&lt;/p&gt;
&lt;p&gt;And of course, here&amp;#8217;s the code I used to produce the graph above in R&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;compound &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;start&lt;span class="p"&gt;,&lt;/span&gt;rate&lt;span class="p"&gt;,&lt;/span&gt;timespan&lt;span class="p"&gt;){&lt;/span&gt;
  x &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; vector&lt;span class="p"&gt;(&lt;/span&gt;mode &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;numeric&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; length &lt;span class="o"&gt;=&lt;/span&gt; timespan&lt;span class="p"&gt;)&lt;/span&gt;
  &lt;span class="kr"&gt;for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;i &lt;span class="kr"&gt;in&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;timespan&lt;span class="p"&gt;){&lt;/span&gt;
    &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;i &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
      x&lt;span class="p"&gt;[&lt;/span&gt;i&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; start
    &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="kr"&gt;else&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
      x&lt;span class="p"&gt;[&lt;/span&gt;i&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; x&lt;span class="p"&gt;[&lt;/span&gt;i&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;rate&lt;span class="p"&gt;)&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="kr"&gt;return&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

inflate &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;start&lt;span class="p"&gt;,&lt;/span&gt; inflation&lt;span class="p"&gt;){&lt;/span&gt;
  x &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; vector&lt;span class="p"&gt;(&lt;/span&gt;mode&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;numeric&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; length&lt;span class="o"&gt;=&lt;/span&gt;dim&lt;span class="p"&gt;(&lt;/span&gt;inflation&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
  &lt;span class="kr"&gt;for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;i &lt;span class="kr"&gt;in&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;dim&lt;span class="p"&gt;(&lt;/span&gt;inflation&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]){&lt;/span&gt;
    &lt;span class="kr"&gt;if&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;i&lt;span class="o"&gt;==&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;){&lt;/span&gt;
      x&lt;span class="p"&gt;[&lt;/span&gt;i&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; start
    &lt;span class="p"&gt;}&lt;/span&gt;
    &lt;span class="kr"&gt;else&lt;/span&gt;&lt;span class="p"&gt;{&lt;/span&gt;
      x&lt;span class="p"&gt;[&lt;/span&gt;i&lt;span class="p"&gt;]&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; x&lt;span class="p"&gt;[&lt;/span&gt;i&lt;span class="m"&gt;-1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;+&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1.25&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;inflation&lt;span class="p"&gt;[&lt;/span&gt;i&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="m"&gt;100&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="kr"&gt;return&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

cpiu &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; cbind&lt;span class="p"&gt;(&lt;/span&gt;seq&lt;span class="p"&gt;(&lt;/span&gt;from&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1992&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;to&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2011&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;2.8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;2.4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;2.6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;2.8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;2.4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;1.4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                                        &lt;span class="m"&gt;2.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;3.4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;2.8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;2.1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;2.8&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;3.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;3.6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
                                        &lt;span class="m"&gt;3.6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;2.6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;4.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;0.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;2.0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;3.0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

inflation &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; data.frame&lt;span class="p"&gt;(&lt;/span&gt;cbind&lt;span class="p"&gt;(&lt;/span&gt;cpiu&lt;span class="p"&gt;[,&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; inflate&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;25000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; cpiu&lt;span class="p"&gt;),&lt;/span&gt; 
                              compound&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;25000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;.05&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; 
                              compound&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;25000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;.06&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;20&lt;/span&gt;&lt;span class="p"&gt;)))&lt;/span&gt;

names&lt;span class="p"&gt;(&lt;/span&gt;inflation&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;&lt;span class="caps"&gt;NECPI&lt;/span&gt;.U&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;FivePercent&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;SixPercent&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
png&lt;span class="p"&gt;(&lt;/span&gt;filename&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;inflation.png&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; height&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;640&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; width&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;800&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; bg&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;white&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
par&lt;span class="p"&gt;(&lt;/span&gt;mar&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;6&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
plot&lt;span class="p"&gt;(&lt;/span&gt;inflation&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="caps"&gt;NECPI&lt;/span&gt;.U&lt;span class="p"&gt;,&lt;/span&gt; type&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;o&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; col&lt;span class="o"&gt;=&lt;/span&gt;rgb&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; ylim&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;20000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;80000&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; 
     axes&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;&lt;span class="caps"&gt;FALSE&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; ann&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;&lt;span class="caps"&gt;FALSE&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; lwd&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
axis&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; at&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; lab&lt;span class="o"&gt;=&lt;/span&gt;inflation&lt;span class="o"&gt;$&lt;/span&gt;year&lt;span class="p"&gt;)&lt;/span&gt;
axis&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; las&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; at&lt;span class="o"&gt;=&lt;/span&gt;seq&lt;span class="p"&gt;(&lt;/span&gt;from&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;20000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; to&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;80000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; by&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;10000&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
lines&lt;span class="p"&gt;(&lt;/span&gt;inflation&lt;span class="o"&gt;$&lt;/span&gt;FivePercent&lt;span class="p"&gt;,&lt;/span&gt; type&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;o&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; pch&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;22&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; lty&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; col&lt;span class="o"&gt;=&lt;/span&gt;rgb&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; 
      lwd&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
lines&lt;span class="p"&gt;(&lt;/span&gt;inflation&lt;span class="o"&gt;$&lt;/span&gt;SixPercent&lt;span class="p"&gt;,&lt;/span&gt; type&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;o&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; pch&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;23&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; lty&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; col&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;red&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; lwd&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
title&lt;span class="p"&gt;(&lt;/span&gt;main&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;span class="caps"&gt;COLA&lt;/span&gt; or Raise?\n &lt;span class="caps"&gt;CPI&lt;/span&gt;-U v. Pension COLAs in Providence&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; col.    main&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;black&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
title&lt;span class="p"&gt;(&lt;/span&gt;xlab&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Year&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
title&lt;span class="p"&gt;(&lt;/span&gt;ylab&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Annual Pension in Dollars\n&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
legend&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;80000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;span class="caps"&gt;CPI&lt;/span&gt;-U &lt;span class="caps"&gt;NE&lt;/span&gt; + 25%&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Five Percent&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;Six Percent&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; col&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;   &lt;span class="s"&gt;&amp;#39;green&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;blue&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;red&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; pch&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;21&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;23&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; lty&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
text&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;25000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;25000&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; pos&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; col&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;black&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
text&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; max&lt;span class="p"&gt;(&lt;/span&gt;inflation&lt;span class="o"&gt;$&lt;/span&gt;SixPercent&lt;span class="p"&gt;),&lt;/span&gt; round&lt;span class="p"&gt;(&lt;/span&gt;max&lt;span class="p"&gt;(&lt;/span&gt;inflation&lt;span class="o"&gt;$&lt;/span&gt;SixPercent&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; pos&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;     col&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;red&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
text&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; max&lt;span class="p"&gt;(&lt;/span&gt;inflation&lt;span class="o"&gt;$&lt;/span&gt;FivePercent&lt;span class="p"&gt;),&lt;/span&gt; round&lt;span class="p"&gt;(&lt;/span&gt;max&lt;span class="p"&gt;(&lt;/span&gt;inflation&lt;span class="o"&gt;$&lt;/span&gt;FivePercent&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;   &lt;span class="p"&gt;,&lt;/span&gt;pos&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; col&lt;span class="o"&gt;=&lt;/span&gt;rgb&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
text&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;20&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; max&lt;span class="p"&gt;(&lt;/span&gt;inflation&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="caps"&gt;NECPI&lt;/span&gt;.U&lt;span class="p"&gt;),&lt;/span&gt; round&lt;span class="p"&gt;(&lt;/span&gt;max&lt;span class="p"&gt;(&lt;/span&gt;inflation&lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="caps"&gt;NECPI&lt;/span&gt;.U&lt;span class="p"&gt;),&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; pos&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;     col&lt;span class="o"&gt;=&lt;/span&gt;rgb&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
dev.off&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;em&gt;This post reflects my personal views and opinions. I am a member of
Local 2012 of the &lt;span class="caps"&gt;RIAFT&lt;/span&gt; and was a supporter of the statewide pension
reform in the Fall of 2011. I am also a resident of&amp;nbsp;Providence.&lt;/em&gt;&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:decree"&gt;
&lt;p&gt;See the first link in this post&amp;#160;&lt;a class="footnote-backref" href="#fnref:decree" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;&lt;a href="http://www.bls.gov/ro1/9140.htm"&gt;Consumer Price Index Northeast from the Bureau of Labor Statistics&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;Sorry this code is not well-commented, but I believe it&amp;#8217;s fairly straight forward&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="non-mers"></category><category term="pension"></category><category term="pension reform"></category><category term="politics"></category><category term="providence"></category><category term="public-sector unions"></category><category term="rhode island"></category><category term="ri"></category><category term="rstats"></category><category term="union"></category></entry><entry><title>Providence Real Estate Sales in R</title><link href="http://blog.jsonbecker.com/2012/01/providence-real-estate-sales-in-r.html" rel="alternate"></link><updated>2012-01-23T00:08:00-05:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-01-23:2012/01/providence-real-estate-sales-in-r.html</id><summary type="html">&lt;p&gt;The past few months I&amp;#8217;ve been learning how to use R. This morning, I decided to try out two first&amp;#8212; importing a table of data that is being read of the web and overlaying location data onto a&amp;nbsp;map.&lt;/p&gt;
&lt;p&gt;With a little bit of Google skills and just enough R know-how I was able to produce this&amp;nbsp;image:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Providence Home Sales 9-12-11 to 12-27-11" src="http://blog.jsonbecker.com/images/homesales.png" title="Providence Home Sales 9-12-11 to 12-27-11" /&gt;&lt;/p&gt;
&lt;p&gt;There were a few things that were kind of tricky for me. First, for sometime I couldn&amp;#8217;t get latitude and longitude components for the addresses. I figured there was something wrong with the way I was using the *apply class of functions in R. apply() (and the related class of functions lapply, sapply, etc.) are really handy if a bit tricky for beginning R users. This function permits quickly &amp;#8220;applying&amp;#8221; a function across multiple elements. Traditionally this is done with a loop, but the apply() functions &amp;#8220;vectorize&amp;#8221; this process (R folks always talk about making your code more vectorized which has something to do with the structure of objects in R but is beyond my computer science skills&amp;#8212; essentially, vectorized code runs much faster and more efficiency than loops because of some underlying feature of the language). After playing around with apply, lapply, and sapply, I decided to move back into my &amp;#8220;old&amp;#8221; way of thinking and just write a&amp;nbsp;loop:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;latlongroll &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;address&lt;span class="p"&gt;){&lt;/span&gt;
  lat &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; vector&lt;span class="p"&gt;(&lt;/span&gt;mode &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;numeric&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; length &lt;span class="o"&gt;=&lt;/span&gt; length&lt;span class="p"&gt;(&lt;/span&gt;address&lt;span class="p"&gt;))&lt;/span&gt;
  lng &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; vector&lt;span class="p"&gt;(&lt;/span&gt;mode &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;numeric&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; length &lt;span class="o"&gt;=&lt;/span&gt; length&lt;span class="p"&gt;(&lt;/span&gt;address&lt;span class="p"&gt;))&lt;/span&gt;
  &lt;span class="kr"&gt;for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;i &lt;span class="kr"&gt;in&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;length&lt;span class="p"&gt;(&lt;/span&gt;address&lt;span class="p"&gt;)){&lt;/span&gt;
    latlong &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; gGeoCode&lt;span class="p"&gt;(&lt;/span&gt;address&lt;span class="p"&gt;[&lt;/span&gt;i&lt;span class="p"&gt;])&lt;/span&gt;
    lat&lt;span class="p"&gt;[&lt;/span&gt;i&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;latlong&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
    lng&lt;span class="p"&gt;[&lt;/span&gt;i&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;latlong&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  &lt;span class="p"&gt;}&lt;/span&gt;
  &lt;span class="kr"&gt;return&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;cbind&lt;span class="p"&gt;(&lt;/span&gt;lat&lt;span class="p"&gt;,&lt;/span&gt;lng&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This still didn&amp;#8217;t work&amp;#8212; I kept on getting a strange out-of-bounds call. So I decided to go down the rabbit hole of regular expressions and try and see if I could clean up my addresses any further (I couldn&amp;#8217;t). So, now seemed as good a time as any to figure out how to print to the console while a loop is running to keep track of progress and where exactly my function was stopped. This turned out to be a bit tricky because I didn&amp;#8217;t know you had to include a tricky line, &lt;code&gt;r flush.console()&lt;/code&gt; in order to get the prints to work. When I figured this out I found out my loop was being caught on my 7th element, a perfectly well formed address. When I ran gGeoCode() on that address only it worked fine. So I thought, maybe Google is bouncing me out because I&amp;#8217;m hitting it too fast? And bingo, the final (working&amp;nbsp;version):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;latlongroll &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;address&lt;span class="p"&gt;){&lt;/span&gt;
 lat &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; vector&lt;span class="p"&gt;(&lt;/span&gt;mode &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;numeric&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; length &lt;span class="o"&gt;=&lt;/span&gt; length&lt;span class="p"&gt;(&lt;/span&gt;address&lt;span class="p"&gt;))&lt;/span&gt;
 lng &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; vector&lt;span class="p"&gt;(&lt;/span&gt;mode &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;numeric&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; length &lt;span class="o"&gt;=&lt;/span&gt; length&lt;span class="p"&gt;(&lt;/span&gt;address&lt;span class="p"&gt;))&lt;/span&gt;
 &lt;span class="kr"&gt;for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;i &lt;span class="kr"&gt;in&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;length&lt;span class="p"&gt;(&lt;/span&gt;address&lt;span class="p"&gt;)){&lt;/span&gt;
  print&lt;span class="p"&gt;(&lt;/span&gt;i&lt;span class="p"&gt;)&lt;/span&gt;
  flush.console&lt;span class="p"&gt;()&lt;/span&gt;
  latlong &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; gGeoCode&lt;span class="p"&gt;(&lt;/span&gt;address&lt;span class="p"&gt;[&lt;/span&gt;i&lt;span class="p"&gt;])&lt;/span&gt;
  lat&lt;span class="p"&gt;[&lt;/span&gt;i&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;latlong&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  lng&lt;span class="p"&gt;[&lt;/span&gt;i&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;latlong&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
  Sys.sleep&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
 &lt;span class="p"&gt;}&lt;/span&gt;
 &lt;span class="kr"&gt;return&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;cbind&lt;span class="p"&gt;(&lt;/span&gt;lat&lt;span class="p"&gt;,&lt;/span&gt;lng&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Other than that, the whole process was pretty straight forward. I have to thank Tony Breyal for &lt;a href="http://stackoverflow.com/questions/3257441/geocoding-in-r-with-google-maps"&gt;posting the functions I used&lt;/a&gt; to get latitude and longitude on &lt;a href="http://stackoverflow.com/"&gt;Stack Overflow&lt;/a&gt;. Also, I found the &lt;a href="http://cran.r-project.org/web/packages/RgoogleMaps/vignettes/RgoogleMaps-intro.pdf"&gt;RgoogleMaps vignette&lt;/a&gt; to be very helpful, although I wish it had slightly better explained what was going on in&amp;nbsp;qbbox().&lt;/p&gt;
&lt;p&gt;Finally, my full source for the&amp;nbsp;above:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c1"&gt;# Providence Real Estate Transactions over the last 40 days.&lt;/span&gt;
&lt;span class="c1"&gt;# Required Packages&lt;/span&gt;
require&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;span class="caps"&gt;XML&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
require&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;RCurl&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
require&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&lt;span class="caps"&gt;RJSONIO&lt;/span&gt;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
require&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;RgoogleMaps&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Functions&lt;/span&gt;
&lt;span class="c1"&gt;# Construct &lt;span class="caps"&gt;URL&lt;/span&gt; required to get the Lat and Long from Google Maps&lt;/span&gt;
construct.geocode.url &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;address&lt;span class="p"&gt;,&lt;/span&gt; return.call &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;json&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; sensor &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;false&amp;quot;&lt;/span&gt;   &lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
 root &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;http://maps.google.com/maps/api/geocode/&amp;quot;&lt;/span&gt;
 u &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; paste&lt;span class="p"&gt;(&lt;/span&gt;root&lt;span class="p"&gt;,&lt;/span&gt; return.call&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;?address=&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; address&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;amp;sensor=&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; sensor&lt;span class="p"&gt;,&lt;/span&gt; sep &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&amp;quot;&lt;/span&gt;   &lt;span class="p"&gt;)&lt;/span&gt;
 &lt;span class="kr"&gt;return&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;URLencode&lt;span class="p"&gt;(&lt;/span&gt;u&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="c1"&gt;# Now that we have the proper Google Maps address, get the resulting latitude     and longitude&lt;/span&gt;
gGeoCode &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;address&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
 u &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; construct.geocode.url&lt;span class="p"&gt;(&lt;/span&gt;address&lt;span class="p"&gt;)&lt;/span&gt;
 doc &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; getURL&lt;span class="p"&gt;(&lt;/span&gt;u&lt;span class="p"&gt;)&lt;/span&gt;
 x &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; fromJSON&lt;span class="p"&gt;(&lt;/span&gt;doc&lt;span class="p"&gt;,&lt;/span&gt;simplify &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="kc"&gt;&lt;span class="caps"&gt;FALSE&lt;/span&gt;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
 lat &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; x&lt;span class="o"&gt;$&lt;/span&gt;results&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;geometry&lt;span class="o"&gt;$&lt;/span&gt;location&lt;span class="o"&gt;$&lt;/span&gt;lat
 lng &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; x&lt;span class="o"&gt;$&lt;/span&gt;results&lt;span class="p"&gt;[[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]]&lt;/span&gt;&lt;span class="o"&gt;$&lt;/span&gt;geometry&lt;span class="o"&gt;$&lt;/span&gt;location&lt;span class="o"&gt;$&lt;/span&gt;lng
 &lt;span class="kr"&gt;return&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;lat&lt;span class="p"&gt;,&lt;/span&gt; lng&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="c1"&gt;# Roll through addresses to create lat long&lt;/span&gt;
latlongroll &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;address&lt;span class="p"&gt;){&lt;/span&gt;
&lt;span class="c1"&gt;# Initializing the length of a vector dramatically speeds up the code. Far &lt;/span&gt;
&lt;span class="c1"&gt;# better than reassigning and resizing each time in the loop.&lt;/span&gt;
 lat &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; vector&lt;span class="p"&gt;(&lt;/span&gt;mode &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;numeric&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; length &lt;span class="o"&gt;=&lt;/span&gt; length&lt;span class="p"&gt;(&lt;/span&gt;address&lt;span class="p"&gt;))&lt;/span&gt;
 lng &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; vector&lt;span class="p"&gt;(&lt;/span&gt;mode &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;numeric&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; length &lt;span class="o"&gt;=&lt;/span&gt; length&lt;span class="p"&gt;(&lt;/span&gt;address&lt;span class="p"&gt;))&lt;/span&gt;
 &lt;span class="kr"&gt;for&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;i &lt;span class="kr"&gt;in&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt;length&lt;span class="p"&gt;(&lt;/span&gt;address&lt;span class="p"&gt;)){&lt;/span&gt;
&lt;span class="c1"&gt;# I kept the print in because this function takes a long time to run so I &lt;/span&gt;
&lt;span class="c1"&gt;# like  to watch its progress.&lt;/span&gt;
 print&lt;span class="p"&gt;(&lt;/span&gt;i&lt;span class="p"&gt;)&lt;/span&gt;
 flush.console&lt;span class="p"&gt;()&lt;/span&gt;
&lt;span class="c1"&gt;# To reduce the calls, I chose to store lat and long locally before &lt;/span&gt;
&lt;span class="c1"&gt;# separating the two whereas initially I hit Google for each separately&lt;/span&gt;
 latlong &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; gGeoCode&lt;span class="p"&gt;(&lt;/span&gt;address&lt;span class="p"&gt;[&lt;/span&gt;i&lt;span class="p"&gt;])&lt;/span&gt;
 lat&lt;span class="p"&gt;[&lt;/span&gt;i&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;latlong&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
 lng&lt;span class="p"&gt;[&lt;/span&gt;i&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;latlong&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;
&lt;span class="c1"&gt;# I&amp;#39;ll have to experiment with the sleep time. I&amp;#39;m certain 0.5 seconds is &lt;/span&gt;
&lt;span class="c1"&gt;# too long (and this is the bulk of the time spent on the whole code).&lt;/span&gt;
 Sys.sleep&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0.5&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
 &lt;span class="p"&gt;}&lt;/span&gt;
 &lt;span class="kr"&gt;return&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;cbind&lt;span class="p"&gt;(&lt;/span&gt;lat&lt;span class="p"&gt;,&lt;/span&gt;lng&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;

&lt;span class="c1"&gt;# Open to the most recent real estate transactions for Providence on the &lt;/span&gt;
&lt;span class="c1"&gt;# Projo&lt;/span&gt;
site &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;http://www.providencejournal.com/homes/real-estate-transactions/assets/pages/real-estate-transactions-providence.htm&amp;#39;&lt;/span&gt;
&lt;span class="c1"&gt;# Read in the table with the header as variable names.&lt;/span&gt;
realestate.table&lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;readHTMLTable&lt;span class="p"&gt;(&lt;/span&gt;site&lt;span class="p"&gt;,&lt;/span&gt;header&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k-Variable"&gt;T&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;which&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;stringsAsFactors&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="k-Variable"&gt;F&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Remove the $ sign before the price&lt;/span&gt;
realestate.table&lt;span class="o"&gt;$&lt;/span&gt;Price &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; gsub&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;([$]{1})([0-9]+)&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;\\2&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
                               realestate.table&lt;span class="o"&gt;$&lt;/span&gt;Price&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Cast price character as numeric&lt;/span&gt;
realestate.table&lt;span class="o"&gt;$&lt;/span&gt;Price&lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;as.numeric&lt;span class="p"&gt;(&lt;/span&gt;realestate.table&lt;span class="o"&gt;$&lt;/span&gt;Price&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Cast date string as date type (lowercase %y means 2-digit year, &lt;/span&gt;
&lt;span class="c1"&gt;# uppercase is 4 digit)&lt;/span&gt;
realestate.table&lt;span class="o"&gt;$&lt;/span&gt;Date &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; as.Date&lt;span class="p"&gt;(&lt;/span&gt;realestate.table&lt;span class="o"&gt;$&lt;/span&gt;Date&lt;span class="p"&gt;,&lt;/span&gt;format&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;%m/%d/%y&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Dummy transactions or title changes have a price of $1, removing those &lt;/span&gt;
&lt;span class="c1"&gt;# from data set&lt;/span&gt;
providence &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; subset&lt;span class="p"&gt;(&lt;/span&gt;realestate.table&lt;span class="p"&gt;,&lt;/span&gt;Price&lt;span class="o"&gt;&amp;gt;&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Removing properties that do not have an address that start with a street &lt;/span&gt;
&lt;span class="c1"&gt;# number&lt;/span&gt;
providence &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; subset&lt;span class="p"&gt;(&lt;/span&gt;providence&lt;span class="p"&gt;,&lt;/span&gt; grepl&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;^[0-9]+&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; providence&lt;span class="o"&gt;$&lt;/span&gt;Address&lt;span class="p"&gt;))&lt;/span&gt;
&lt;span class="c1"&gt;# Add lat and lng coordinates to each address&lt;/span&gt;
providence&lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;cbind&lt;span class="p"&gt;(&lt;/span&gt;providence&lt;span class="p"&gt;,&lt;/span&gt; latlongroll&lt;span class="p"&gt;(&lt;/span&gt;providence&lt;span class="p"&gt;[,&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;]))&lt;/span&gt;
&lt;span class="c1"&gt;# Calculate boundary lat and long for map&lt;/span&gt;
bb &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; qbbox&lt;span class="p"&gt;(&lt;/span&gt;providence&lt;span class="o"&gt;$&lt;/span&gt;lat&lt;span class="p"&gt;,&lt;/span&gt; providence&lt;span class="o"&gt;$&lt;/span&gt;lng&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# Gets a map from Google Maps&lt;/span&gt;
map &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; GetMap.bbox&lt;span class="p"&gt;(&lt;/span&gt;bb&lt;span class="o"&gt;$&lt;/span&gt;lonR&lt;span class="p"&gt;,&lt;/span&gt; bb&lt;span class="o"&gt;$&lt;/span&gt;latR&lt;span class="p"&gt;,&lt;/span&gt; zoom&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;12&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; maptype&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;mobile&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="c1"&gt;# plot the points&lt;/span&gt;
PlotOnStaticMap&lt;span class="p"&gt;(&lt;/span&gt;map&lt;span class="p"&gt;,&lt;/span&gt;lon&lt;span class="o"&gt;=&lt;/span&gt;providence&lt;span class="o"&gt;$&lt;/span&gt;lng&lt;span class="p"&gt;,&lt;/span&gt;lat&lt;span class="o"&gt;=&lt;/span&gt;providence&lt;span class="o"&gt;$&lt;/span&gt;lat&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="google maps"></category><category term="providence"></category><category term="real estate"></category><category term="rhode island"></category><category term="rstats"></category></entry><entry><title>What if the technology revolution in schools is really about the simple stuff?</title><link href="http://blog.jsonbecker.com/2012/01/what-if-the-technology-revolution-in-schools-is-really-about-the-simple-stuff.html" rel="alternate"></link><updated>2012-01-18T22:23:00-05:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-01-18:2012/01/what-if-the-technology-revolution-in-schools-is-really-about-the-simple-stuff.html</id><summary type="html">&lt;p&gt;The complicated school day is essentially designed so the minimum number of staff are away from kids at any given time. Some folks are trying to combat this with &lt;a href="http://www.allthingsplc.info/pdf/articles/make_time_for_collaboration.pdf"&gt;common planning time&lt;/a&gt; and other &lt;a href="http://www.erstools.org/Dream/district_es_a.cfm"&gt;scheduling gymnastics&lt;/a&gt;. These attempts are up against a strong opposing priority&amp;#8212; students must be with an adult essentially 100% of the time. Not only that, but the middle of a hectic day focused on teaching is not really conducive to reflection, strategizing, and deep planning on a tight schedule. The temptation to use this precious time to put out the days (or weeks) fires instead of the kind of collaboration and professional learning desired is just too&amp;nbsp;strong.&lt;/p&gt;
&lt;p&gt;And quite honestly, I think teachers should get space in the day to vent, grade papers, setup their classroom, call parents, and do all the normal &amp;#8220;maintenance&amp;#8221; required to keep their classes running. The question then remains, how do we create this dynamic space for professional learning, coordination of services, collaboration on lesson delivery, creative thinking about school structures,&amp;nbsp;etc?&lt;/p&gt;
&lt;p&gt;I really think that &lt;a href="http://www.storiesfromschool.org/travis.html"&gt;Travis&lt;/a&gt; on &lt;a href="http://www.storiesfromschool.org/"&gt;Stories from School&lt;/a&gt; has it right: &lt;a href="http://www.storiesfromschool.rg/2012/01/not-meeting.html"&gt;use technology to make it easy for teachers, administrators, and other staff to communicate and coordinate&lt;/a&gt;. There is no shortage of snake oil peddled to &amp;#8220;solve&amp;#8221; education in America and one of the most persistent memes is the technological revolution will alter classrooms forever. Technology&amp;#8217;s real promise is in &lt;em&gt;schools&lt;/em&gt; and not &lt;em&gt;classrooms&lt;/em&gt;&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;. Sharing assessment results and lesson plans, coordinating with interventions being offered to a student, talking to other teachers who have or have had the same student, and more can all be made much easier with technology. Rather than finding the time to meet face-to-face, faculty members can put energy into building relationships around teaching and learning when they have the time. The opportunity to breakaway the time constraints typically placed on synchronous conversation is huge. The opportunity for rich asynchronous sharing is virtually brand new.&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;I do not want this to sound like pushing for &amp;#8220;social media&amp;#8221; for teachers, mostly because the technological innovations involved are not a part of the current flavor of Web 2.0 networking. Even the old tools like email, instant messaging, and perhaps the oldest social tool of all, discussion boards, could be extremely helpful for&amp;nbsp;folks.&lt;/p&gt;
&lt;p&gt;None of this is new, most of this has been said, yet it seems like too few schools have found a way to leverage existing and inexpensive technology to implement this kind of communication as an essential part of work culture. That seems like a massive missed opportunity that should not be lost while district officials are distracted by quick-and-dirty 4 week online courses for credit&amp;nbsp;recovery.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;There are several reasons I&amp;#8217;m not optimistic on technology revolutionizing the classroom. My preferred explanation is that the &lt;em&gt;technology of learning has not changed, &lt;/em&gt;not to be confused with the technology of human machines, but instead the technology of &lt;em&gt;the&lt;/em&gt; human machine. Human learning is no different from it was in the past so our technology can only promise new delivery mechanisms for the same thousands of years old approach to teaching and learning. Education can gain efficiencies in delivery that are not to be underestimated. But I think of a revolution as changing a process so dramatically that an observer would barely recognize the process a decade later. The computers and the internet have certainly done that in some fields, but I don&amp;#8217;t see this happening in schools.&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;Ok, so I guess teachers could leave a flyer in mailboxes in the past, but come on&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="cpt"></category><category term="edtech"></category><category term="education"></category></entry><entry><title>Value-Added on Core Knowledge Blog— some thoughts on Chetty, Friedman, and Rockoff</title><link href="http://blog.jsonbecker.com/2012/01/value-added-on-core-knowledge-blog-some-thoughts-on-chetty-friedman-and-rockoff.html" rel="alternate"></link><updated>2012-01-13T00:08:00-05:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-01-13:2012/01/value-added-on-core-knowledge-blog-some-thoughts-on-chetty-friedman-and-rockoff.html</id><summary type="html">&lt;p&gt;Jessica Lahey wrote an &lt;a href="http://blog.coreknowledge.org/2012/01/12/what-is-the-value-in-a-high-value-added-teacher/"&gt;interesting post&lt;/a&gt; over on &lt;a href="http://blog.coreknowledge.org/"&gt;Core Knowledge Blog&lt;/a&gt; that I decided to comment&amp;nbsp;on.&lt;/p&gt;
&lt;p&gt;After I read back my comment, I realized it would be worth copying over here as it&amp;#8217;s own blog&amp;nbsp;post.&lt;/p&gt;
&lt;p&gt;The most interesting part of the &lt;a href="http://www.economics.harvard.edu/faculty/chetty"&gt;Chetty&lt;/a&gt;, &lt;a href="http://www.hks.harvard.edu/fs/jfriedm/"&gt;Friedman&lt;/a&gt;, and &lt;a href="http://www0.gsb.columbia.edu/faculty/jrockoff/"&gt;Rockoff&lt;/a&gt; &lt;a href="http://nber.org/papers/w17699"&gt;study&lt;/a&gt; is precisely the most banal- teachers who improve heir students learning as measured by increased achievement on tandardized tests also improve other more distant and relevant factors n children’s lives &lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;This seems obvious to anyone who isn’t vehemently anti-testing. For a large group of the anti-testing regime, there is considerable skepticism that the standardized testing intruments being used by states is a valid instrument for the “real” purposes of education. In fact, the line of thinking in this post is a close relative to this critique. Essentially, what is mathematically reliable is not necessarily valid for drawing&amp;nbsp;conclusions.&lt;/p&gt;
&lt;p&gt;&lt;span class="caps"&gt;CFR&lt;/span&gt; in a massive study essentially: 1) Added to a large research base that suggests that teachers can in fact have an impact on standardized test scores; 2) Demonstrate that the impact on standardized test scores are associated with broader, more distant, and, arguably, more important education outcomes; 3) These impacts are persistent throughout the lifetime of&amp;nbsp;students.&lt;/p&gt;
&lt;p&gt;While it does &lt;span class="caps"&gt;NOT&lt;/span&gt; make a great case for teacher dismissal based solely on &lt;span class="caps"&gt;VAM&lt;/span&gt;, like the authors are essentially claiming in popular coverage, it does continue to strengthen the case that standardized tests are relevant, reliable, and meaningful indicators of a successful education system. The impacts on social outcomes (teen pregnancy) and economic outcomes (later earnings) show a broad range of important outcomes we expect from schools are strongly associated with&amp;nbsp;VAMs.&lt;/p&gt;
&lt;p&gt;A good measure does not have to perfectly describe the intracacies of reality, it just has to give a rough, reasonable, and valid facsimile. &lt;span class="caps"&gt;CFR&lt;/span&gt; is just part of a growing tradition that shows there’s a good case for VAMs to be a part of that&amp;nbsp;image.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Actually, I think that &lt;a href="http://schoolfinance101.wordpress.com/2012/01/07/fire-first-ask-questions-later-comments-on-recent-teacher-effectiveness-studies/"&gt;Baker&lt;/a&gt;, &lt;a href="http://shankerblog.org/?p=4708"&gt;Di Carlo&lt;/a&gt;, nd &lt;a href="http://shermandorn.com/wordpress/?p=4390"&gt;Dorn&lt;/a&gt; are all probably right that the tests for biasness in VAMs or teachers are the most interesting part, but that&amp;#8217;s purely from a geeky researcher perspective. I doubt that&amp;#8217;ll have as much impact as ther portions of the paper, and probably rightfully so&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="Core Knowledge Blog"></category><category term="education"></category><category term="standardized tests"></category><category term="teacher evaluation"></category><category term="value-added measures"></category><category term="VAM"></category></entry><entry><title>Associated Press: Israeli schools not looking so good against OECD peers.</title><link href="http://blog.jsonbecker.com/2012/01/associated-press-israeli-schools-not-looking-so-good-against-oecd-peers.html" rel="alternate"></link><updated>2012-01-07T10:10:00-05:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2012-01-07:2012/01/associated-press-israeli-schools-not-looking-so-good-against-oecd-peers.html</id><summary type="html">&lt;p&gt;I read an interesting &lt;a href="http://goo.gl/SSY83"&gt;article&lt;/a&gt; this morning on Israeli
schools. Facing extreme poverty among Arab-Israeli&amp;#8217;s and the
ultra-orthodox, Israel struggles to maintain three separate school
systems and succeed. It reminded me of some interesting centralized
policy reforms in Israel that have led to great natural experiments. For
example, so-called Maimonides Laws which capped class sizes at 40,
allowed for some really interesting regression-discontinuity studies on
the impact of class size &lt;sup id="fnref:classsize"&gt;&lt;a class="footnote-ref" href="#fn:classsize" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;.&lt;/p&gt;
&lt;p&gt;What I found most interesting in this article, however, was the point
made by Jon&amp;nbsp;Medved:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;While agreeing Israeli schools need to raise their standards,
technology entrepreneur Jon Medved doesn&amp;#8217;t think Israel&amp;#8217;s test scores
tell the whole story. He says informal education, through the
military, youth movements, and extracurricular activities, builds
skills. He also praised programs for gifted&amp;nbsp;children.&lt;/p&gt;
&lt;p&gt;Consequently, Medved says he isn&amp;#8217;t worried that Israel&amp;#8217;s tech-driven
economy will slide because of deficiencies in the school&amp;nbsp;system.&lt;/p&gt;
&lt;p&gt;&lt;span class="dquo"&gt;&amp;#8220;&lt;/span&gt;While I think it&amp;#8217;s important to sound alarm signals, I haven&amp;#8217;t heard
from tech companies &amp;#8230; &amp;#8216;the employees we&amp;#8217;re getting are not
educated,&amp;#8217;&amp;#8221; Medved&amp;nbsp;said.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Two thoughts came to mind. First, we certainly are hearing in the United
States that employers are unhappy with the caliber of candidates for
open positions. It&amp;#8217;s unclear that in the &lt;span class="caps"&gt;US&lt;/span&gt; this is a result of low
aggregate skills or just tremendous mismatch between the skills that are
attained and the skills that are now valued in the marketplace. Second,
Israel&amp;#8217;s universal military service provides several additional years of
intense training and skill attainment even before college. Considering
the broad range of roles one can take on in the state military ((For
example, social workers in Israel are basically military trained, given
job experience, and then set out without a need for 5 years of
schooling, although I believe many do receive at least a bachelor&amp;#8217;s)),
it&amp;#8217;s hard not to see Israel&amp;#8217;s mandatory service as a massive vocational
educational&amp;nbsp;program.&lt;/p&gt;
&lt;p&gt;I don&amp;#8217;t have much analysis here, but mandatory public/civil service is
an interesting concept that this article will keep me thinking about
over the&amp;nbsp;weekend.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:classsize"&gt;
&lt;p&gt;http://www.economics.harvard.edu/faculty/staiger/files/AngristLavy%&lt;span class="caps"&gt;2BQJE&lt;/span&gt;%2B1999.pdf;
Angrist has also done several other studies in Israel with Lavy, a nice
little summary of which is available here http://www.nber.org/reporter/summer03/angrist.html&amp;#160;&lt;a class="footnote-backref" href="#fnref:classsize" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="Angrist"></category><category term="class_size_reduction"></category><category term="education"></category><category term="Israel"></category><category term="military"></category></entry><entry><title>GrapheR is an awesome GUI for R beginners</title><link href="http://blog.jsonbecker.com/2011/12/grapher-is-an-awesome-gui-for-r-beginners.html" rel="alternate"></link><updated>2011-12-19T09:28:00-05:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2011-12-19:2011/12/grapher-is-an-awesome-gui-for-r-beginners.html</id><summary type="html">&lt;p&gt;If you&amp;#8217;re just beginning to use R and want a quick and easy way to make some charts/graphs, etc, GrapheR is a great package to quickly produce high quality plots through a self-explanatory &lt;span class="caps"&gt;GUI&lt;/span&gt;. &lt;a href="http://journal.r-project.org/archive/2011-2/RJournal_2011-2_Herve.pdf"&gt;Here&lt;/a&gt;&amp;#8216;s an article
in The R Journal&amp;nbsp;today.&lt;/p&gt;
&lt;p&gt;My only complaint is that GrapheR does not appear to have a way to export the code that produced the graph, which would be a very helpful feature for a beginner who wants to learn the guts of producing publication quality charts in&amp;nbsp;R.&lt;/p&gt;
&lt;p&gt;To install and then&amp;nbsp;run&amp;#8230;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;install.packages&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;GrapheR&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
require&lt;span class="p"&gt;(&lt;/span&gt;GrapheR&lt;span class="p"&gt;)&lt;/span&gt;
run.GrapheR&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</summary><category term="GrapheR"></category><category term="rstats"></category></entry><entry><title>House wants unemployed to earn GEDs against all economic sense</title><link href="http://blog.jsonbecker.com/2011/12/house-wants-unemployed-to-earn-geds-against-all-economic-sense.html" rel="alternate"></link><updated>2011-12-14T17:58:00-05:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2011-12-14:2011/12/house-wants-unemployed-to-earn-geds-against-all-economic-sense.html</id><summary type="html">&lt;p&gt;Here is a&amp;nbsp;doozy.&lt;/p&gt;
&lt;p&gt;What is the purpose of the &lt;span class="caps"&gt;GED&lt;/span&gt;? Is it a &lt;a href="http://en.wikipedia.org/wiki/Signalling_(economics)"&gt;market signal&lt;/a&gt;, indicating your employability to hiring agents or does it follow a &lt;a href="http://en.wikipedia.org/wiki/Human_capital"&gt;human capital&lt;/a&gt; path wherein earning a &lt;span class="caps"&gt;GED&lt;/span&gt; is actually a process that increases your skill&amp;nbsp;set?&lt;/p&gt;
&lt;p&gt;The House wants all unemployed workers without a high school diploma &lt;a href="http://blogs.edweek.org/edweek/campaign-k-12/2011/12/bill_would_require_ged_to_tap.html"&gt;to earn their &lt;span class="caps"&gt;GED&lt;/span&gt;&lt;/a&gt;. Their explanation is assuming that the &lt;span class="caps"&gt;GED&lt;/span&gt; works purely through human capital theory, e.g. currently unemployed workers who don&amp;#8217;t have a high school diploma will earn more skills that make them increasingly employable by enrolling in and earning their &lt;span class="caps"&gt;GED&lt;/span&gt;. Is there any evidence for&amp;nbsp;this?&lt;/p&gt;
&lt;p&gt;If we look at what the &lt;a href="http://www.brown.edu/Departments/Education/resources/what_do_we_know.pdf"&gt;research says&lt;/a&gt; &lt;sup id="fnref:research"&gt;&lt;a class="footnote-ref" href="#fn:research" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;, we learn that the &lt;span class="caps"&gt;GED&lt;/span&gt; is only effective at boosting earnings of lower skilled recipients. Tyler suggests that this may indicate that the &lt;span class="caps"&gt;GED&lt;/span&gt; is acting as a labor market signal, demonstrating to future employers that they have the work ethic and extra motivation low-skilled high school drop-outs are believed to lack and are worth hiring. This is supported by the fact that not only are low skilled &lt;span class="caps"&gt;GED&lt;/span&gt; earners the only ones who see greater earnings and employability as a result of earning a &lt;span class="caps"&gt;GED&lt;/span&gt; but also by the fact that there is a lag to the &amp;#8220;&lt;span class="caps"&gt;GED&lt;/span&gt; impact&amp;#8221;. One possible mechanism for this lag indicates that the &lt;span class="caps"&gt;GED&lt;/span&gt; is a signal for unobserved characteristics that suggest an employee is ready to learn and earn those additional skills they do not current possess, and therefore, low-skilled workers who earn a &lt;span class="caps"&gt;GED&lt;/span&gt; are more likely to be placed in a position where they will have the opportunity to increase their human capital and future earnings. Since high skilled employees don&amp;#8217;t seem to gain any benefit from a &lt;span class="caps"&gt;GED&lt;/span&gt;, that suggests that their existing skill set already sufficiently operates as a signal of employability such that there is no need for an additional signal of initial readiness for hiring. Even if this were the case, if the &lt;span class="caps"&gt;GED&lt;/span&gt; was truly ruled by a human capital model, we would expect high skilled &lt;span class="caps"&gt;GED&lt;/span&gt; recipients to have become increasingly skilled through the &lt;span class="caps"&gt;GED&lt;/span&gt; process and, therefore, they should also benefit from increased earnings due to receiving a&amp;nbsp;&lt;span class="caps"&gt;GED&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;So what does this all mean? Let&amp;#8217;s remember that the unemployment benefits being offered only exist for 99 weeks now (and would be lowered to 59 weeks in the House proposal). This means that all the unemployed we&amp;#8217;re worried about were in fact employed within the last year and seven weeks. Do we believe that those who were employed as recently as one year ago, already deep into the economic downturn, who do not have a high school diploma fall into the low or high skilled group? It seems obvious to me that if you were employable 59 weeks ago you would almost certainly be in the upper half (if not higher) of the skills distribution among those who don&amp;#8217;t have high school diplomas. So the result of the &lt;span class="caps"&gt;GED&lt;/span&gt; policy is likely going to lead to no benefit for these workers and will probably even decrease their earnings since they will have some costs associated with earning the &lt;span class="caps"&gt;GED&lt;/span&gt;&amp;#8212; be it the fee for a course, the fee to take the test, the opportunity costs associated with spending time studying and working toward a credential that has no benefit,&amp;nbsp;etc.&lt;/p&gt;
&lt;p&gt;Worse, by dramatically changing the contexts where folks earn a &lt;span class="caps"&gt;GED&lt;/span&gt;, we&amp;#8217;re likely to completely change what signal the &lt;span class="caps"&gt;GED&lt;/span&gt; will send future employers. In essence, the impact is unpredictable, but it&amp;#8217;s hard to see a path whereby earning a &lt;span class="caps"&gt;GED&lt;/span&gt; increases in value as a result of policies that make certain that GEDs will be earned more broadly and under duress and not  by voluntary&amp;nbsp;action.&lt;/p&gt;
&lt;p&gt;So forget about all the other stuff you read on the &lt;span class="caps"&gt;GED&lt;/span&gt; requirement. We don&amp;#8217;t have to worry about fairness, discrimination, or just plain shitting on people when they&amp;#8217;re in some of the most dire straits they&amp;#8217;re likely to see by adding even more to their burdens. The &lt;span class="caps"&gt;GED&lt;/span&gt;-only policy on unemployment benefits is simply unlikely to do anything other than transfer resources from the unemployed to the &lt;a href="http://www.acenet.edu/AM/Template.cfm?Section=Home"&gt;American Council on Education&lt;/a&gt; and companies that have &lt;span class="caps"&gt;GED&lt;/span&gt; &lt;a href="http://www.kaptest.com/ged"&gt;prep&lt;/a&gt; &lt;a href="http://www.randomhouse.com/princetonreview/college/ged/"&gt;classes&lt;/a&gt;.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:research"&gt;
&lt;p&gt;John Tyler was a former professor of mine. If Brown had a PhD programming in education, I would go back in a heartbeat to work under him.&amp;#160;&lt;a class="footnote-backref" href="#fnref:research" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="brown university"></category><category term="economics"></category><category term="education"></category><category term="GED"></category><category term="human capital"></category><category term="john tyler"></category><category term="politics"></category><category term="signaling"></category><category term="unemployment"></category></entry><entry><title>Diane Ravitch, rebuttals.</title><link href="http://blog.jsonbecker.com/2011/12/diane-ravitch-rebuttals.html" rel="alternate"></link><updated>2011-12-12T15:23:00-05:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2011-12-12:2011/12/diane-ravitch-rebuttals.html</id><summary type="html">&lt;p&gt;So I wrote a &lt;a href="http://blog.jasonpbecker.com/2011/11/28/is-diane-ravitch-a-reliable-historian/"&gt;harsh post&lt;/a&gt; after reading a &lt;a href="http://www.tnr.com/print/article/politics/magazine/97765/diane-ravitch-education-reform"&gt;harsh article&lt;/a&gt; by Kevin Carey in &lt;a href="http://www.tnr.com/"&gt;The New Republic&lt;/a&gt; about &lt;a href="http://www.dianeravitch.com/"&gt;Diane Ravitch&lt;/a&gt;. I still standby what I said. Namely, I&amp;#8217;m very cautious about trusting Ravitch as a reliable narrator of history because&amp;nbsp;I&amp;#8217;m:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;unfamiliar with good historiography/methodology so it&amp;#8217;s hard for me to judge the quality of her work simply from the product&amp;nbsp;itself&lt;/li&gt;
&lt;li&gt;unaware of a rich discourse around education history in &lt;span class="caps"&gt;NYC&lt;/span&gt; and 20th century America in general that wrestles with, or even corroborates, Ravitch&amp;#8217;s&amp;nbsp;account&lt;/li&gt;
&lt;li&gt;certain that Ravitch&amp;#8217;s more recent writings often mischaracterizes the power and meaning behind quantitative research and exhibits selection bias to fit a particular&amp;nbsp;narrative&lt;/li&gt;
&lt;li&gt;generally distrustful of public academics, particularly when their writing is mainly outside of their primary&amp;nbsp;discipline.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;That being said, there have been several well-written critiques of Carey&amp;#8217;s piece and I thought it&amp;#8217;s only fair that I link to them to present a more complete picture of what many folks, some who agree and some who disagree with Ravitch&amp;#8217;s current ideology, think of Ravitch&amp;#8217;s&amp;nbsp;work.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.edexcellence.net/about-us/people/michael-j-petrilli.html"&gt;Mike Petrilli&lt;/a&gt; is certainly no fan of Ravitch&amp;#8217;s rebirth as the anti-choice, anti-accountability voice &lt;em&gt;du jour&lt;/em&gt;. But &lt;a href="http://www.educationgadfly.net/flypaper/2011/11/what-kevin-carey-didnt-say-about-diane-ravitch-but-should-have/"&gt;his piece&lt;/a&gt; in Flypaper in response to Carey is quite clear: the idea that Ravitch&amp;#8217;s personal life  had an impact on her criticism of then &lt;span class="caps"&gt;NYC&lt;/span&gt; Schools
Chancellor &lt;a href="http://en.wikipedia.org/wiki/Joel_Klein"&gt;Joel Klein&lt;/a&gt; is unfair and wrong. As someone who worked directly with Ravitch and who had, independently, overseen the awarding of a grant to &lt;a href="http://www.huffingtonpost.com/mary-butz"&gt;Mary Butz&lt;/a&gt;&amp;#8216;s leadership program, Petrilli sees a different line of thought. Ravitch, in his view, simply correctly pointed to the flaw in Klein&amp;#8217;s &amp;#8220;clear the field&amp;#8221; approach that tended to cut down successful or promising programs alongside the dead&amp;nbsp;weight.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.danagoldstein.net/dana_goldstein/about-dana.html"&gt;Dana Goldstein&lt;/a&gt;&amp;#8216;s &lt;a href="http://www.danagoldstein.net/dana_goldstein/2011/11/thoughts-on-kevin-careys-profile-of-diane-ravitch-history-and-ideology.html"&gt;response&lt;/a&gt; suggests that Kevin Carey ignored the context in which Ravitch wrote. Goldstein suggests that Ravitch had to fight against a sexist academy in a discipline that increasingly had taken on a polemicists tone, as a liberal who did not quite fit the mold
of her times. These factors combined to generate the type of histories and writing that Ravitch would produce and are critical in understanding, without undermining, her&amp;nbsp;work.&lt;/p&gt;
&lt;p&gt;Finally, &lt;a href="http://www.dianasenechal.com/bio.html"&gt;Diane Senechal&lt;/a&gt; writes in The New Republic &lt;a href="http://www.tnr.com/article/politics/98379/diane-ravitch-school-reform?page=0,0"&gt;today&lt;/a&gt; that Ravitch&amp;#8217;s history is a far more balanced critique than Carey would have you believe, very well documented, and self-consistent. She does concede that Ravitch writes with a fiery, decidedly non-academic tone that&amp;#8217;s
intended as a public intellectual. But here, Senechal views this as a strength, &amp;#8220;arous[ing] general interest in matters that might otherwise seem out of reach or obscure.&amp;#8221; Ultimately, Senechal&amp;#8217;s main point is that Ravitch&amp;#8217;s work is of very high quality and thorough and that her tone should not overshadow the accomplishment of her&amp;nbsp;scholarship.&lt;/p&gt;</summary><category term="dana goldstein"></category><category term="diane ravitch"></category><category term="edreform"></category><category term="education"></category><category term="education policy"></category><category term="education reform"></category><category term="history"></category><category term="kevin carey"></category><category term="mike petrilli"></category><category term="tnr"></category></entry><entry><title>How to use Picasa with iOS5</title><link href="http://blog.jsonbecker.com/2011/12/how-to-use-picasa-with-ios5.html" rel="alternate"></link><updated>2011-12-11T22:30:00-05:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2011-12-11:2011/12/how-to-use-picasa-with-ios5.html</id><summary type="html">&lt;p&gt;I&amp;#8217;m mostly writing this post because I had a fairly hard time finding a resolution to a real pesky error. For some reason, my &lt;a href="http://www.apple.com/iphone/"&gt;iPhone 4S&lt;/a&gt; was recognized by &lt;a href="http://picasa.google.com/"&gt;Picasa&lt;/a&gt; but always failed to import photos. Whenever I tried, the Picasa was clearly scanning through the files and then presented this&amp;nbsp;error:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;An error has occurred while attempting to import. Either the source is
unavailable or the destination is full or read only&amp;nbsp;(1).&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The resolution was found on &lt;a href="http://www.google.com/support/forum/p/Picasa/thread?tid=36adf4b3d0209e55&amp;amp;hl=en"&gt;this page&lt;/a&gt; posted by &lt;a href="http://www.google.com/support/forum/p/Picasa/user?userid=14055753863597455136&amp;amp;hl=en"&gt;Tradeinstyle&lt;/a&gt;. A slightly more thorough explanation of the solution&amp;nbsp;below.&lt;/p&gt;
&lt;p&gt;If you are seeing this error, what appears to have happened is that several images are &amp;#8220;corrupted&amp;#8221; in some way on your iPhone. Unfortunately, this requires opening up &lt;a href="http://www.apple.com/ilife/iphoto/"&gt;iPhoto&lt;/a&gt;. Once in iPhoto, you should be at the import screen and see all the pictures available on your phone. Several of these pictures will have a thumbnail consisting only of a dotted-line forming a square&amp;#8212; a blank thumbnail. You&amp;#8217;ll want to import these photos and, after clicking import, be sure to select the option that removes them from your iPhone. Now move these imported photos from your newly create iPhoto library into your normal Pictures folder (or wherever you&amp;#8217;re watching for pictures in Picasa). They&amp;#8217;ll load just fine. Exit iPhoto, delete your iPhoto Library (probably located in \~/Pictures/iPhoto\ Library) to avoid duplicates and open Picasa. Because the &amp;#8220;offending&amp;#8221; pictures have now been removed, Picasa should be able to easily import your&amp;nbsp;photos.&lt;/p&gt;
&lt;p&gt;This problem does not appear to be specific to the iPhone 4s and is probably applicable to &lt;a href="http://www.apple.com/ipodtouch/"&gt;all&lt;/a&gt; &lt;a href="http://www.apple.com/ios/"&gt;iOS5&lt;/a&gt; &lt;a href="http://www.apple.com/ipad/"&gt;devices&lt;/a&gt;.&lt;/p&gt;</summary><category term="Apple"></category><category term="import photos"></category><category term="ios5"></category><category term="ipad"></category><category term="ipad 2"></category><category term="iphone"></category><category term="iphone 4s"></category><category term="iphone4s"></category><category term="iphoto"></category><category term="ipod touch"></category><category term="picasa"></category><category term="solved"></category></entry><entry><title>How Social Reading Should Work</title><link href="http://blog.jsonbecker.com/2011/12/how-social-reading-should-work.html" rel="alternate"></link><updated>2011-12-08T19:32:00-05:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2011-12-08:2011/12/how-social-reading-should-work.html</id><summary type="html">&lt;p&gt;I am becoming increasingly frustrated by the failure of all the major players to get social right. I have a very simple dream for how the social web should work and its baffling to me that many obvious use-cases have not been addressed at all by Facebook, Twitter, or&amp;nbsp;Google.&lt;/p&gt;
&lt;p&gt;This is the first of two posts that will describe what I view as a viable framework for a social web experience. The whole goal of social web, in my view, is to read, share, discover, and communicate about found content. This post will focus on finding and reading content. The second will focus on sharing and discussing that&amp;nbsp;content.&lt;/p&gt;
&lt;h2&gt;Properly Handle Content&amp;nbsp;Sources&lt;/h2&gt;
&lt;p&gt;One of the major shortcomings of Facebook, Twitter, and Google+ is source content. The backbone of the ideal social experience is not simply sharing inane details of your personal life. It&amp;#8217;s making the entire web a community activity. It&amp;#8217;s about making communication on the internet as rich and natural an experience as possible. The branded pages and official accounts simply do not substitute for an excellent content platform. The origin of this problem is simple&amp;#8212; the modern social network is entirely built upon connecting people, and content generators are just considered a hacked up special class of people. Reading (and generating) content is the ground floor of the social&amp;nbsp;experience.&lt;/p&gt;
&lt;p&gt;What&amp;#8217;s my evidence that this model is insufficient? The popularity of services like Google Reader, Flipboard, Feedly, etc. Need more? The three major social players are all introducing new ways to bring content sources into their services and keep my eyes within their system. Facebook has its Social Reader, which is just creepy to me because I can&amp;#8217;t share outside of Facebook and I don&amp;#8217;t want everything my eyes glaze over to be shared instantly with everyone. Twitter has its &amp;#8220;Discover&amp;#8221; tab that goes well beyond trending and tries to create a pre-curated reader experience. Google has Currents, a Flipboard clone that&amp;#8217;s based upon casual magazine style reading, complete with a whole new set of subscriptions, a good mobile experience, and easy sharing into Google&amp;nbsp;Plus.&lt;/p&gt;
&lt;p&gt;But none of these solutions recognize that there are at least three major domains of access&amp;nbsp;content.&lt;/p&gt;
&lt;h2&gt;Bookmarking&lt;/h2&gt;
&lt;p&gt;The first way people find content is from sources they want to read casually. These are the sites you check when you&amp;#8217;re bored or when there&amp;#8217;s a massive breaking story. This is your New York Times or &lt;span class="caps"&gt;CNN&lt;/span&gt;.com pushing out massive amounts of timely information that you just want to dip into time to time. This is one form of content that folks are just starting to get right. Flipboard/Google Currents successfully gives a gorgeous platform for casually reading across many sources. There&amp;#8217;s no need to keep track of every story or go through content methodically. This reading experience is quick and casual and all about stumbling across&amp;nbsp;something.&lt;/p&gt;
&lt;h2&gt;Collecting&lt;/h2&gt;
&lt;p&gt;This is the bread and butter for &lt;span class="caps"&gt;RSS&lt;/span&gt; subscribers and one of the major areas that most social players are ignoring. Collecting means you want to read everything someone or some site writes. You want to make sure to come back and glance over things you don&amp;#8217;t get a chance to see. Read/unread counts are a critical piece of making sure you read every piece of news that comes through. This is content reading you want to tag, save, easily search through, etc. Another way to think of collecting is the set of information you trust only yourself to sort through a curate. This isn&amp;#8217;t your list of pretty recipes that come streaming in quickly and are throw-aways. These are your trusted insider industry areas that get at the heart of your job or most important&amp;nbsp;hobbies.&lt;/p&gt;
&lt;h2&gt;Streaming&lt;/h2&gt;
&lt;p&gt;This is the traditional &amp;#8220;news feed&amp;#8221; of social reading. It&amp;#8217;s how you see what all your &amp;#8220;friends&amp;#8221; are sharing, doing, and saying. This is about finding the trends, the conversations that are blowing up, the short funny statements, etc. You almost definitely don&amp;#8217;t care if you miss something someone posts here, but you want to be able to see the cream that rises to the top. You want a way that conveniently allows you to enter someone else&amp;#8217;s workspace and interact with the content they&amp;#8217;ve shared with you. This is the other area that social has some models that work well and was the basis for all other activities on the social web. It&amp;#8217;s also one of the social webs major problems. The stream is massive and cannot be absorbed in whole. Most of the content is throwaway. But because almost all other social reading is based on the stream, all of our content, even what we collect and bookmark, becomes throwaway and short-lived, given the same priority as your long lost aunt in an old age home playing&amp;nbsp;Farmville.&lt;/p&gt;
&lt;p&gt;For me, the social web has to start with providing me with a single space that aggregates what I want to read on the web. If content is not easy for me to get access to, I&amp;#8217;m never going to even worry about being satisfied with my options for sharing. Social fails right now because they haven&amp;#8217;t gotten the reading paradigm right. It&amp;#8217;s nowhere close to handling the three major domains&amp;#8212;bookmarking, collecting, and streaming&amp;#8212; effectively under a single attractive interface. I think Google is the closest. If you combine some of the features in Currents, their new attractive mobile reader that works great for bookmarking, with some of the critical features in Google Reader, right now the best collector, then I&amp;#8217;m very close to an ideal reading experience. My hope is that someone will find a way to combine all three and then provide the robust sharing features I&amp;#8217;ll write about in my next&amp;nbsp;post.&lt;/p&gt;</summary><category term="curation"></category><category term="facebook"></category><category term="google plus"></category><category term="google reader"></category><category term="social"></category><category term="twitter"></category></entry><entry><title>Contracting Technology in Education</title><link href="http://blog.jsonbecker.com/2011/11/contracting-technology-in-education.html" rel="alternate"></link><updated>2011-11-29T22:40:00-05:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2011-11-29:2011/11/contracting-technology-in-education.html</id><summary type="html">&lt;p&gt;I am glad that &lt;a href="http://gothamschools.org/author/philissa-cramer/"&gt;Philissa Cramer&lt;/a&gt; is reporting on some of the deeper details of the Special Education Student Information System &lt;sup id="fnref:coverage"&gt;&lt;a class="footnote-ref" href="#fn:coverage" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; implementation at the &lt;a href="http://schools.nyc.gov/default.htm"&gt;New York City Department&lt;/a&gt; of Education &lt;a href="http://gothamschools.org/2011/11/29/report-links-sesis-struggles-and-does-contractinpractices/"&gt;here&lt;/a&gt;. Many people don&amp;#8217;t really understand the ins and outs of government contracting. Folks really think &lt;span class="caps"&gt;NASA&lt;/span&gt; designs and builds the lunar module, for example, instead of realizing that they issued an &lt;span class="caps"&gt;RFP&lt;/span&gt; and contracting with &lt;a href="http://www.northropgrumman.com/"&gt;Northrop Grumman&lt;/a&gt; to do that work for them. Similarly, in education, especially around complex technology projects, most districts and states purchase products or services through a bid product rather than develop solutions in&amp;nbsp;house.&lt;/p&gt;
&lt;p&gt;However, I am a bit disappointed in the angle that &lt;a href="http://www.citylimits.org"&gt;City Limits&lt;/a&gt;, (Ms. Cramer&amp;#8217;s &lt;a href="http://www.theinvestigativefund.org/investigations/politicsandgovernment/1581/beyond_citytime?page=1"&gt;source&lt;/a&gt;) took in their reporting. There are real problems with government contracting, but they really mischaracterize the story around &lt;span class="caps"&gt;SESIS&lt;/span&gt; in an attempt to simplify the issue for casual readers.
City Limits acts as though it is surprising, or even deplorable, that an &lt;span class="caps"&gt;RFP&lt;/span&gt; was awarded to a company with a largely existing&amp;nbsp;product.&lt;/p&gt;
&lt;p&gt;They point to the fact that Maximus, the vendor for the &lt;span class="caps"&gt;SESIS&lt;/span&gt; contract, was modifying an existing product to meet the requirements outlined in &lt;span class="caps"&gt;NYC&lt;/span&gt; &lt;span class="caps"&gt;DOE&lt;/span&gt;&amp;#8217;s &lt;span class="caps"&gt;RFP&lt;/span&gt; as though this was clearly bad. City Limits uses words like &amp;#8220;revealed&amp;#8221; and &amp;#8220;simply&amp;#8221; to describe what Maximus was offering. This just ignores the reality of government contracting and shows disregard for risk mitigation. Almost all government agencies handsomely reward companies that can point to successes in developing and implementing solutions that can meet many of the requirements outlined in the issued &lt;span class="caps"&gt;RFP&lt;/span&gt;. The government wants to hire people it believes can do the job and do it well and often one of the best ways to make that determination is to see that someone has done it before. In almost all cases, this means selecting a vendor who has an existing product or process for meeting many of the requirements in the &lt;span class="caps"&gt;RFP&lt;/span&gt; that will be expanded upon or modified. But government purchasers don&amp;#8217;t just want experienced partners, they also want to leverage efficiencies by not paying for duplication. One of the major reasons for purchasing an existing product or contracting with a vendor is that school systems actually aren&amp;#8217;t that different from one another and the basic functionality and organizational structures required in an &lt;span class="caps"&gt;IT&lt;/span&gt; solution are shared across schools, districts, and states. Why pay substantially to build the same basic software infrastructure that already exists elsewhere? It&amp;#8217;s a waste of money most of the&amp;nbsp;time.&lt;/p&gt;
&lt;p&gt;City Limits then goes on to criticize the massive increases that can occur due to change orders. This is a serious problem with government contracting, but they fail to really explore why. A change order occurs when the client wants new or additional functionality that was not included in the initial contract. Their frequency and expense are not an example of why government agencies should not contract with outside vendors, rather, they demonstrate just how poorly bureaucracies are at managing large-scale complex projects. Change orders happen due to several failures, and almost all are the government agencies&amp;#8217; fault. In no particular order, the government&amp;nbsp;agency:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;failed to do proper discovery before issuing the &lt;span class="caps"&gt;RFP&lt;/span&gt; and, therefore, missed major functional requirements that are not identified until more intensive discovery occurs during development or initial&amp;nbsp;implementation;&lt;/li&gt;
&lt;li&gt;agreed to a contract that was far too specific and did not allow for the reality that requirements do evolve over time (though often not in ways which substantially change the nature or quantity of&amp;nbsp;work);&lt;/li&gt;
&lt;li&gt;agreed to a contract that was far too vague such that the vendor can claim to have delivered a product or service when they did not meet already identified functional requirements for the&amp;nbsp;system;&lt;/li&gt;
&lt;li&gt;did not take into account the preparation and costs required to sustain the product beyond the life of the initial engagement with the&amp;nbsp;vendor.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;These are the main things that lead to change orders. If the government agency is doing a top-notch job, they can all be avoided and the only occasion for a change order should be large external shocks that dramatically alter the functional requirements, intentional decisions to move away from the initial functional requirements that weighed the costs of altering the vendor contract, and a desire to extend and expand a relationship because of the success of the initial implementation resulting in a substantially more advanced or mature&amp;nbsp;product.&lt;/p&gt;
&lt;p&gt;It is really hard to manage vendor contracts right. It requires actually knowing what you want to buy before an &lt;span class="caps"&gt;RFP&lt;/span&gt; is issued (or recognizing what is and is not known and correctly assessing the scope of the impact future decisions on unknowns will have on the work). It requires a really good team of lawyers to fight outside forces that literally make their profits on carefully abdicating as much responsibility as possible at the contracting phase. It requires selecting good partners that are adequately willing and prepared to evolve and work with the agency as their needs and knowledge grow and mature. It requires an honest assessment of future resources that will be available to assure sustainability of large investments. And perhaps most difficult of all, it requires strong project management infrastructure throughout the entire agency to ensure alignment and consistency across multiple products produced internally and by multiple external&amp;nbsp;partners.&lt;/p&gt;
&lt;p&gt;The benefits of outsourcing products can be huge and are worth leveraging. Vendor contracts are difficult to manage, and bureaucracies are not always well-suited to managing these projects, but all government agencies struggle with getting this&amp;nbsp;right.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;One last parting&amp;nbsp;thought&amp;#8230;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In my view, the most challenging aspect of getting vendor contracting right for government agencies is spending ample upfront time, even before issuing an &lt;span class="caps"&gt;RFP&lt;/span&gt;, articulating the functional needs that a solution must meet in detail. I feel that often public sector employees are so
intimidated by the arduous process around issuing and awarding an &lt;span class="caps"&gt;RFP&lt;/span&gt; that they rush to get an &lt;span class="caps"&gt;RFP&lt;/span&gt; out there and worry about the details during contracting and product initiation. Whenever possible, resist this temptation at all costs. Whether custom designed internally or
provided by an external vendor, satisfaction is dependent upon clarity of the desired outcomes. This is particularly true with technology projects. Vendors will always produce &lt;em&gt;something&lt;/em&gt;, but whether the solution is any good is almost entirely up to good requirements&amp;nbsp;gathering.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:coverage"&gt;
&lt;p&gt;For pretty good coverage check out all of Gotham School&amp;#8217;s posts &lt;a href="http://gothamschools.org/tag/sesis/"&gt;http://gothamschools.org/tag/sesis/&lt;/a&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:coverage" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="bureaucracy"></category><category term="business analysis"></category><category term="City LImits"></category><category term="Gotham Schools"></category><category term="government"></category><category term="government contracting"></category><category term="information technology"></category><category term="NYC DOE"></category><category term="Philissa Cramer"></category><category term="politics"></category><category term="public goods"></category><category term="RFP"></category><category term="SESIS"></category><category term="vendor relationships"></category></entry><entry><title>Is Diane Ravitch a reliable historian?</title><link href="http://blog.jsonbecker.com/2011/11/is-diane-ravitch-a-reliable-historian.html" rel="alternate"></link><updated>2011-11-28T10:33:00-05:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2011-11-28:2011/11/is-diane-ravitch-a-reliable-historian.html</id><summary type="html">&lt;p&gt;&lt;em&gt;&lt;span class="caps"&gt;UPDATE&lt;/span&gt;: You should also read &lt;a href="http://blog.jasonpbecker.com/2011/12/12/diane-ravitch-rebuttals/"&gt;this page&lt;/a&gt; on jasonpbecker for some very strong and interesting rebuttals to Carey&amp;#8217;s article that I commented on&amp;nbsp;below.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Do read &lt;a href="http://www.tnr.com/print/article/politics/magazine/97765/diane-ravitch-education-reform"&gt;this article&lt;/a&gt; on Diane Ravitch. I personally have two major criticisms of Ravitch, both of which Carey exposes&amp;nbsp;eloquently.&lt;/p&gt;
&lt;p&gt;First, I believe that she leverages her respect and expertise as an historian and professor to present herself as an experts in areas of academic research and policy where she has little expertise. This is very common with public intellectuals, and I think it&amp;#8217;s deceiving and&amp;nbsp;deplorable.&lt;/p&gt;
&lt;p&gt;Second, I am unsure about whether she is a reliable narrator of history because my impression is that she&amp;#8217;s the &amp;#8220;best in the game&amp;#8221; at least in part because so few are playing. I don&amp;#8217;t personally have the skill to judge her histories and given her blatant academic dishonesty in so many other areas where I have some ability to judge quality, I find it hard to view her as an honest&amp;nbsp;operator.&lt;/p&gt;
&lt;p&gt;What is somewhat new in Carey&amp;#8217;s take on Ravitch, and what I think most here on Plus will find interesting, are two revelations. First, one I was somewhat acquainted with, it seems possible that some of Ravitch&amp;#8217;s shift to rhetorical vitriol against someone who seemed a natural ally (Joel Klein) may be partially attributable to a personal dispute involving Ravitch&amp;#8217;s &amp;#8220;partner&amp;#8221; (this and other articles seem to be intentionally ambiguous about the nature of this relationship). Second, and most interesting to me, it appears that Ravitch doesn&amp;#8217;t have the typical academic acumen of an acclaimed scholar in her field. In fact, it appears that Ravitch has produced almost exclusively popular history throughout her career. This detail in particular plays into some of my very concerns about the reliability of her historical&amp;nbsp;narratives.&lt;/p&gt;
&lt;p&gt;On a side note, I think if I could be one person in education policy today it&amp;#8217;d be Kevin Carey. He&amp;#8217;s smart as hell and an excellent writer, even if I disagree with him on higher education&amp;nbsp;issues.&lt;/p&gt;</summary><category term="carey"></category><category term="education"></category><category term="ravitch"></category></entry><entry><title>Why isn’t the Core Connector using Westminster with full RoW?</title><link href="http://blog.jsonbecker.com/2011/11/why-isnt-the-core-connector-using-westminster-with-full-row.html" rel="alternate"></link><updated>2011-11-06T10:16:00-05:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2011-11-06:2011/11/why-isnt-the-core-connector-using-westminster-with-full-row.html</id><summary type="html">&lt;p&gt;I love that Providence is pursuing a streetcar. There are really just
two things I don&amp;#8217;t understand about the &lt;a href="http://providencecoreconnector.com/"&gt;Core Connector&lt;/a&gt;&amp;#8216;s proposal.
I&amp;#8217;m going to tackle one in this&amp;nbsp;post.&lt;/p&gt;
&lt;p&gt;Why is the entire streetcar route shared with general traffic with no
dedicated right-of-way? Truthfully, this isn&amp;#8217;t a massive issue except in
the core part of Downcity where there is substantial traffic during rush
hours along the street car route. But this makes the plan even more
perplexing because it&amp;#8217;s precisely this portion of the route where an
obvious solution for dedicated light rail &lt;span class="caps"&gt;ROW&lt;/span&gt; exists- Westminster&amp;nbsp;Street.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Quick and dirty Core Connector modification" src="http://blog.jsonbecker.com/images/Route-November-3.png" title="CoreConnectorRouteModified" /&gt;&lt;/p&gt;
&lt;p&gt;The red route above represents the proposed streetcar line. The green
line represents Westminster Street, a narrow, single lane, one-way
street that cuts through Downcity and in front of &lt;a href="http://suraprovidence.com/"&gt;restaurants&lt;/a&gt;,
&lt;a href="http://www.queenofheartsandmodernlove.com/"&gt;boutique&lt;/a&gt; &lt;a href="http://www.shopwarf.com"&gt;shopping&lt;/a&gt;, &lt;a href="http://www.uri.edu/prov/"&gt;&lt;span class="caps"&gt;URI&lt;/span&gt;&lt;/a&gt;, etc. It brings the streetcar line
slightly closer to Johnson and Wales and slightly further from the
Dunkin Donuts Arena and Rhode Island Convention Center. While there is
real automobile traffic, this is almost entirely for two reasons. First,
Westminster has substantial on-street metered parking. Second,
Westminster is the East-&gt;West one-way to counter Weybosset&amp;#8217;s&amp;nbsp;West-East.&lt;/p&gt;
&lt;p&gt;Of course, the two major Downcity planning projects underway are
removing the stress that leads to both of these uses. The Downtown
Circulator project is nearly complete, converting Empire and Weybosset
to two-way streets. Automobile traffic will almost certainly take the
wider and faster Washington and Weybosset Streets, adjacent to
Westminster, unless the goal is to find on the street parking. The
second project is the Core Connector itself, which provides more options
to get into Downcity without a car, hopefully reducing the need for
parking. There are also substantial parking capacity that&amp;#8217;s
underutilized in the many surface lots and parking garages in the&amp;nbsp;area.&lt;/p&gt;
&lt;p&gt;&lt;img alt="A great shot from Flickr of Westminster at night" src="http://blog.jasonpbecker.com/wp-content/uploads/2011/11/4256071978_aaf18cb143_z.jpg" title="Westminster at Night" /&gt; &lt;sup id="fnref:sourceone"&gt;&lt;a class="footnote-ref" href="#fn:sourceone" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;&lt;/p&gt;
&lt;p&gt;As far as I can tell, there is really no need for Westminster to have
street traffic. A dedicated &lt;span class="caps"&gt;ROW&lt;/span&gt; will increase the speed and
predictability of the streetcar. Additional pedestrian space along
Westminster could quickly be used by the cafes and restaurants and
street vendors that already are in the area. The only reason I could
come up with for not using Westminster as a dedicated right-of-way for
the streetcar is the need for a turn in or around Kennedy Plaza. There
are so many options for moving between Washington and Westminster that I
just can&amp;#8217;t buy this as an insurmountable&amp;nbsp;challenge.&lt;/p&gt;
&lt;p&gt;I was unable to make it to the three recent public meetings about the
proposed route. If I were there, this would certainly be my first&amp;nbsp;question.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:sourceone"&gt;
&lt;p&gt;Sourced from http://www.flickr.com/photos/ranjith-pix/&amp;#160;&lt;a class="footnote-backref" href="#fnref:sourceone" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="core connector"></category><category term="department of planning and development"></category><category term="downcity"></category><category term="providence"></category><category term="ri"></category><category term="streetcar"></category><category term="urban development"></category><category term="westminster street"></category></entry><entry><title>GoLocalProv — Bad at Math</title><link href="http://blog.jsonbecker.com/2011/10/golocalprov-bad-at-math.html" rel="alternate"></link><updated>2011-10-16T11:12:00-04:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2011-10-16:2011/10/golocalprov-bad-at-math.html</id><summary type="html">&lt;p&gt;There are lots of things that are misleading about &lt;a href="http://www.golocalprov.com/news/10820/"&gt;this story&lt;/a&gt; published on GoLocalProv. It is utterly ridiculous to report numbers like how many total tax dollars are being collected by different communities for the sake of comparison. You cannot compare a total number like this which is so dependent upon things like, I don&amp;#8217;t know, the &lt;strong&gt;dramatic difference in the size of these communities&lt;/strong&gt;?&lt;/p&gt;
&lt;p&gt;In the 2010 Census, Providence had a population of &lt;strong&gt;178,042&lt;/strong&gt;. New Shoreham had a population of &lt;strong&gt;1,051&lt;/strong&gt;. Is anyone surprised that one of these communities is on the top of the list and the other on the&amp;nbsp;bottom?&lt;/p&gt;
&lt;p&gt;There&amp;#8217;s more than size at play, but the least &lt;span class="caps"&gt;GLP&lt;/span&gt; could have done was to correct for population and present the per capita levy. All it takes is one quick Google search and we can get the 2010 Census numbers which are probably pretty damn close to the current population so we can get a decent, somewhat level playing field to compare cities and towns on. &lt;a href="http://www.dlt.ri.gov/lmi/census/pop/townpop.htm"&gt;Here&amp;#8217;s the 2010 Census numbers from the &lt;span class="caps"&gt;RI&lt;/span&gt; Department of Labor and Training&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;So with 5 minutes in Excel (thanks, &lt;span class="caps"&gt;GLP&lt;/span&gt;, for making your charts images instead of tables), here&amp;#8217;s a much more interesting&amp;nbsp;list:&lt;/p&gt;
&lt;table width="250" border="1" cellspacing="0" cellpadding="0"&gt;
  &lt;colgroup&gt; 
    &lt;col width="85" align="left"&gt;&lt;/col&gt;
    &lt;col width="69" align="right"&gt;&lt;/col&gt;
    &lt;col width="50" align="right"&gt;&lt;/col&gt;
    &lt;col width="55" align="right"&gt;&lt;/col&gt;
  &lt;/colgroup&gt;
  &lt;tbody style="background-color:white"&gt;
  &lt;tr&gt;
    &lt;td width="75" height="12" align="left"&gt;
      **Community**
    &lt;/td&gt;
    &lt;td width="70"&gt;
      **&lt;span class="caps"&gt;FY12&lt;/span&gt; Levy**
    &lt;/td&gt;
    &lt;td width="50"&gt;
      **2010 Pop**
    &lt;/td&gt;
    &lt;td width="55"&gt;
      **Per Capita**
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td height="12"&gt;
      New Shoreham
    &lt;/td&gt;
    &lt;td&gt;
      \$8,187,149
    &lt;/td&gt;
    &lt;td&gt;
      1,051
    &lt;/td&gt;
    &lt;td&gt;
      **\$7,790**
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td height="12"&gt;
      Jamestown
    &lt;/td&gt;
    &lt;td&gt;
      \$18,653,102
    &lt;/td&gt;
    &lt;td&gt;
      5,405
    &lt;/td&gt;
    &lt;td&gt;
      **\$3,451**
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td height="12"&gt;
      Barrington

    &lt;/td&gt;
    &lt;td&gt;
      \$55,162,905
    &lt;/td&gt;
    &lt;td&gt;
      16,310
    &lt;/td&gt;
    &lt;td&gt;
      **\$3,382**
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td height="12"&gt;
      East Greenwich
    &lt;/td&gt;
    &lt;td&gt;
      \$44,015,850
    &lt;/td&gt;
    &lt;td&gt;
     13,146
    &lt;/td&gt;
    &lt;td&gt;
      **\$3,348**
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td height="12"&gt;
      West Greenwich
    &lt;/td&gt;
    &lt;td&gt;
      \$17,703,664
    &lt;/td&gt;
    &lt;td&gt;
      6,135
    &lt;/td&gt;
    &lt;td&gt;
      **\$2,886**
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td height="12"&gt;
      Little Compton
    &lt;/td&gt;
    &lt;td&gt;
      \$10,004,530
    &lt;/td&gt;
    &lt;td&gt;
      3,492
    &lt;/td&gt;
    &lt;td&gt;
      **\$2,865*&lt;/tr&gt;
  &lt;tr&gt;
    &lt;td height="12"&gt;
      Narragansett
    &lt;/td&gt;
    &lt;td&gt;
      \$44,732,180
    &lt;/td&gt;
    &lt;td&gt;
      15,868
    &lt;/td&gt;
    &lt;td&gt;
      **\$2,819**
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td height="12"&gt;
      Westerly
    &lt;/td&gt;
    &lt;td&gt;
      \$63,547,705

    &lt;/td&gt;
    &lt;td&gt;
      22,787
    &lt;/td&gt;
    &lt;td&gt;
    **\$2,789**
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td height="12"&gt;
      Charlestown

    &lt;/td&gt;
    &lt;td&gt;
      \$21,611,447

    &lt;/td&gt;
    &lt;td&gt;
      7,827
    &lt;/td&gt;
    &lt;td&gt;
      **\$2,761**
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td height="12"&gt;
      Portsmouth
    &lt;/td&gt;
    &lt;td&gt;
      \$45,807,376
    &lt;/td&gt;
    &lt;td&gt;
     17,389
    &lt;/td&gt;
    &lt;td&gt;
      **\$2,634**
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td height="12"&gt;
      Warwick
    &lt;/td&gt;
    &lt;td&gt;
      \$216,867,072
    &lt;/td&gt;
    &lt;td&gt;
      82,672
    &lt;/td&gt;
    &lt;td&gt;
      **\$2,623**
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td height="12"&gt;
      Middletown
    &lt;/td&gt;
    &lt;td&gt;
      \$41,588,607
    &lt;/td&gt;
    &lt;td&gt;
      16,150
    &lt;/td&gt;
    &lt;td&gt;
      **\$2,575**
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td height="12"&gt;
      Newport
    &lt;/td&gt;
    &lt;td align="right"&gt;
      \$63,519,526
    &lt;/td&gt;
    &lt;td align="right"&gt;
      24,672
    &lt;/td&gt;
    &lt;td align="right"&gt;
      **\$2,575**
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td height="12"&gt;
    North Kingstown
    &lt;/td&gt;
    &lt;td&gt;
    \$67,598,341
    &lt;/td&gt;
    &lt;td&gt;
     26,486
    &lt;/td&gt;
    &lt;td&gt;
    **\$2,552**
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td height="12"&gt;
      Scituate
    &lt;/td&gt;
    &lt;td align="right"&gt;
      \$25,492,269
    &lt;/td&gt;
    &lt;td align="right"&gt;
      10,329
    &lt;/td&gt;
    &lt;td align="right"&gt;
      **\$2,468**
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td height="12"&gt;
      Lincoln
    &lt;/td&gt;
    &lt;td align="right"&gt;
      \$51,960,896
    &lt;/td&gt;
    &lt;td align="right"&gt;
      21,105
    &lt;/td&gt;
    &lt;td align="right"&gt;
      **\$2,462**
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td height="12"&gt;
      Foster
    &lt;/td&gt;
    &lt;td&gt;
      \$11,221,591
    &lt;/td&gt;
    &lt;td&gt;
      4,606
    &lt;/td&gt;
    &lt;td&gt;
      **\$2,436**
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td height="12"&gt;
      Johnston
    &lt;/td&gt;
    &lt;td&gt;
      \$68,570,772
    &lt;/td&gt;
    &lt;td&gt;
     28,769
    &lt;/td&gt;
    &lt;td&gt;
      **\$2,383**

    &lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
    &lt;td height="12"&gt;
      North Smithfield
    &lt;/td&gt;
    &lt;td&gt;
      \$27,592,721
    &lt;/td&gt;
    &lt;td&gt;
     11,967
    &lt;/td&gt;
    &lt;td&gt;
      **\$2,306**
    &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
    &lt;td height="12"&gt;
      Smithfield
    &lt;td&gt;
      \$49,357,148
    &lt;/td&gt;
&lt;td&gt;
 21,430

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td&gt;
**\$2,303**

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;/tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td height="12"&gt;
Tiverton

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
\$35,771,014

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
 15,780

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
**\$2,267**

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;/tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td height="12"&gt;
Cranston

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
\$180,715,853

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
 80,387

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
**\$2,248**

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;/tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td height="12"&gt;
South Kingstown

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
\$66,120,832

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
 30,639

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
**\$2,158**

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;/tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td height="12"&gt;
Hopkinton

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
\$17,630,988

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
 8,188

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
**\$2,153**

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;/tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td height="12"&gt;
Glocester

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
\$20,971,276

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
 9,746

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
**\$2,152**

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;/tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td height="12"&gt;
North Providence

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
\$67,218,014

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
 32,078

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
**\$2,095**

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;/tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td height="12"&gt;
Warren

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
\$21,971,276

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
 10,611

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
**\$2,071**

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;/tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td height="12"&gt;
Richmond

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
\$15,705,615

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
 7,708

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
**\$2,038**

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;/tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td height="12"&gt;
Exeter

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
\$12,619,379

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
 6,425

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
**\$1,964**

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;/tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td height="12"&gt;
Providence

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
\$324,460,407

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
 178,042

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
**\$1,822**

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;/tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td height="12"&gt;
West Warwick

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
\$52,337,257

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
 29,191

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
**\$1,793**

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;/tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td height="12"&gt;
Coventry

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
\$61,860,355

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
 35,014

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td align="right"&gt;
**\$1,767**

&lt;/td&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;/tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;tr&gt;
&lt;/p&gt;
&lt;p&gt;
&lt;td height="12"&gt;
Cumberland

&lt;/td&gt;
&lt;td align="right"&gt;
\$57,890,766
&lt;/td&gt;
&lt;td align="right"&gt;
33,506
&lt;/td&gt;
&lt;td align="right"&gt;
**\$1,728**
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td height="12"&gt;
Burrillville
&lt;/td&gt;
&lt;td align="right"&gt;
\$26,687,010
&lt;/td&gt;
&lt;td align="right"&gt;
15,955
&lt;/td&gt;
&lt;td align="right"&gt;
**\$1,673**
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td height="12"&gt;
Bristol
&lt;/td&gt;
&lt;td align="right"&gt;
\$35,697,780
&lt;/td&gt;
&lt;td align="right"&gt;
22,954
&lt;/td&gt;
&lt;td align="right"&gt;
**\$1,555**
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td height="12"&gt;
Pawtucket
&lt;/td&gt;
&lt;td align="right"&gt;
\$96,340,757
&lt;/td&gt;
&lt;td align="right"&gt;
71,148
&lt;/td&gt;
&lt;td align="right"&gt;
**\$1,354**
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td height="12"&gt;
Woonsocket
&lt;/td&gt;
&lt;td align="right"&gt;
\$53,984,558
&lt;/td&gt;
&lt;td align="right"&gt;
41,186
&lt;/td&gt;
&lt;td align="right"&gt;
**\$1,311**
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td height="12"&gt;
Central Falls
&lt;/td&gt;
&lt;td align="right"&gt;
\$13,148,778
&lt;/td&gt;
&lt;td align="right"&gt;
 19,376
&lt;/td&gt;
&lt;td align="right"&gt;
**\$679**
&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;</summary><category term="2010 census"></category><category term="per capita"></category><category term="rhode island"></category><category term="tax"></category></entry><entry><title>TEA Party and Occupy Wall Street</title><link href="http://blog.jsonbecker.com/2011/10/tea-party-and-occupy-wall-street.html" rel="alternate"></link><updated>2011-10-15T19:20:00-04:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2011-10-15:2011/10/tea-party-and-occupy-wall-street.html</id><summary type="html">&lt;p&gt;I wondered to myself If I could explain these two movements in a few sentences. Is this&amp;nbsp;fair?&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The Taxed Enough Already (&lt;span class="caps"&gt;TEA&lt;/span&gt;) Party movement is a response to two
large government spending packages, the &amp;#8220;bailout&amp;#8221; and the &amp;#8220;stimulus&amp;#8221;
package. These people felt that it was inappropriate for the
government spend taxpayer money (and foreign debt) in an attempt to
prevent deeper economic damage from the collapse of the real estate&amp;nbsp;bubble.
&lt;/p&gt;
&lt;p&gt;The Occupy Wall Street movement is a response to the same two large
government spending packages as well as the subsequently ineffectual
American government during the first term of the Obama Presidency.
These people are skeptical that the &amp;#8220;bailout&amp;#8221; and &amp;#8220;stimulus&amp;#8221; package
addressed the challenges that the vast majority of Americans face
every day in favor of addressing the needs of an elite economic and
political&amp;nbsp;class.&lt;/p&gt;
&lt;/blockquote&gt;</summary><category term="occupy"></category><category term="occupy providence"></category></entry><entry><title>School facilities— anachronistic, expensive, isolating, and all around bad public spaces?</title><link href="http://blog.jsonbecker.com/2011/10/school-facilities-anachronistic-expensive-isolating-and-all-around-bad-public-spaces.html" rel="alternate"></link><updated>2011-10-06T00:01:00-04:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2011-10-06:2011/10/school-facilities-anachronistic-expensive-isolating-and-all-around-bad-public-spaces.html</id><summary type="html">&lt;p&gt;I wanted to write a lot more about this, but I just don&amp;#8217;t have the&amp;nbsp;time.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://gothamschools.org/2011/10/05/downtown-residents-disappointed-by-school-zones-proposal/"&gt;This story&lt;/a&gt;is about rezoning schools in downtown Manhattan which is struggling to meet the demands of emerging residential neighborhoods. Reading this story (and struggle) just brought up something I&amp;#8217;ve thought about for some time&amp;nbsp;now.&lt;/p&gt;
&lt;p&gt;The cost of school buildings is ridiculous. Schools are generally built for one purpose. They are generally built to last a very long time. They are generally built to a quality standard that suggests it will perennially be far too expensive to knock down and start over even if renovations are obscenely expensive and inadequate. In most areas (dense urban cities are probably the exception), we build schools on large plots of land with field/park space attached. This land is technically for public use, but in the name of safety for children, land uses are far more restrictive than most public&amp;nbsp;parks.&lt;/p&gt;
&lt;p&gt;It all just seems like an absurd setup that wastes countless public dollars. Why wouldn&amp;#8217;t we want to have smaller schools in mixed-use spaces that represent far less capital investment and introduce substantial budget flexibility as enrollment patterns change? Why would we want to build separate libraries from existing public resources? Why would we want separate fields rather than bringing students to truly public spaces during the&amp;nbsp;day?&lt;/p&gt;
&lt;p&gt;The school house as a public space that&amp;#8217;s isolated and locked away from the community that builds it, the school house that&amp;#8217;s on a 100-year bond designed in such a way that any conversion to other uses is very unlikely&amp;#8230; isn&amp;#8217;t that school house a bit&amp;nbsp;anachronistic?&lt;/p&gt;</summary><category term="education"></category><category term="land use"></category><category term="public goods"></category><category term="school facilities"></category><category term="urban development"></category></entry><entry><title>Downcity Residents Should Support the Core Connector and the Tax Makes Sense</title><link href="http://blog.jsonbecker.com/2011/09/downcity-residents-should-support-the-core-connector-and-the-tax-makes-sense.html" rel="alternate"></link><updated>2011-09-26T12:13:00-04:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2011-09-26:2011/09/downcity-residents-should-support-the-core-connector-and-the-tax-makes-sense.html</id><summary type="html">&lt;p&gt;As a resident of Downcity, I have been closely following the development of &lt;a href="http://providencecoreconnector.com/wp-content/uploads/2010/09/Final-Alternatives-Fact-Sheet.pdf"&gt;Providence&amp;#8217;s Core Connector Study&lt;/a&gt;. The official route and payment options have now been proposed, as reported in the &lt;a href="http://www.projo.com/news/content/STREETCAR_PLAN_09-26-11_UAQI5KV_v15.6c71c.html"&gt;Projo&lt;/a&gt;. &lt;/p&gt;
&lt;h2&gt;Route&lt;/h2&gt;
&lt;p&gt;I&amp;#8217;m pleased to see that they prioritized frequent service through the main ridership areas (College Hill to Jewelry District and hospital) were prioritized over service to the train station. Jef Nickerson says it best over at &lt;a href="http://www.gcpvd.org/2011/09/26/streetcars-the-train-station-is-out-but-thats-ok/"&gt;&lt;span class="caps"&gt;GCPVD&lt;/span&gt;&lt;/a&gt;&amp;#8212; the train station is out-of-the-way and would dramatically increase rider time while having unclear implications for ridership, and the station is already very well served (and could easily be better served) by existing bus routes. The streetcar is really about moving people within Providence and providing a permanency to the connectivity between the current (Brown and hospital) and hopefully future (Jewelry District) economic engines of the&amp;nbsp;city.&lt;/p&gt;
&lt;p&gt;The proposed route uses Washington and Empire Street&amp;#8212; both are wise choices. Washington Street adds the &lt;a href="http://www.providencebiltmore.com/"&gt;Biltmore&lt;/a&gt;, &lt;a href="http://www.lupos.com/"&gt;Lupos&lt;/a&gt;, &lt;a href="http://www.uri.edu/prov/"&gt;&lt;span class="caps"&gt;URI&lt;/span&gt;&lt;/a&gt;, and &lt;a href="http://www.as220.org/about/the-mercantile-block.html"&gt;&lt;span class="caps"&gt;AS220&lt;/span&gt;&lt;/a&gt; directly to the route while keeping the &lt;a href="http://www.riconvention.com/"&gt;Convention Center&lt;/a&gt; and the &lt;a href="http://www.dunkindonutscenter.com/"&gt;Dunk&lt;/a&gt; near by. Washington also has the advantage of a direct route over 95 for a possible South-Westward expansion in the future with limited cost and slow downs due to a lack of turns. Empire Street is also a great choice. The road is only about to undergo construction to be expanded for two-way traffic (one of the last legs of the Downtown Circulator project). The corner of Washington and Empire anchors the streetcar at the &lt;a href="http://www.provlib.org/"&gt;Providence Central Library&lt;/a&gt;, &lt;a href="http://www.trinityrep.com/"&gt;Trinity Rep&lt;/a&gt;, &lt;a href="http://www.as220.org"&gt;&lt;span class="caps"&gt;AS220&lt;/span&gt;&lt;/a&gt;, &lt;a href="http://38studios.com/"&gt;38 Studios&lt;/a&gt;, and &lt;a href="http://www.projo.com/economy/HASBRO_LASALLE_SQUARE_07-19-11_EMP8O4D_v19.42183.html"&gt;Hasbro&amp;#8217;s new Downcity location&lt;/a&gt;. Regency Plaza adds more residential ridership and the massive parking lot across from the Hilton suddenly looks more attractive for infill development. It doesn&amp;#8217;t hurt that I live at Westminster and Empire and would be excellently served by this location. Overall, I believe this path through Downcity is the easiest to manage while anchoring the streetcar near major hubs of activity. I only wish they could have found a way to bring the streetcar down Westminster and close the street to personal vehicle traffic, but that was never a likely&amp;nbsp;option.&lt;/p&gt;
&lt;p&gt;The Jewelry District part of the route never seemed as controversial to me because there were limited solutions that  were somewhat obvious. The decision to use Chestnut makes sense and solidifies the Westminster-Chestnut Street path as a strong North-South connector through the area. Not going all the way to Prairie Avenue is likely going to anger some Upper South Providence residents, but I&amp;#8217;m not convinced this is a bad thing. At the &lt;a href="http://blog.jasonpbecker.com/2011/09/08/community-voice-at-the-knowledge-district-development-framework-meeting/"&gt;Knowledge District Development Framework meeting&lt;/a&gt; it was clear that increasing paucity between the two sides of Prairie Avenue was a major goal of development in the hospital area. Forcing people to walk a bit on Dudley Street may generate the kind of foot traffic needed to make infill in that area with first floor retail a lot more&amp;nbsp;attractive.&lt;/p&gt;
&lt;h2&gt;The&amp;nbsp;Tax&lt;/h2&gt;
&lt;p&gt;I&amp;#8217;m in favor of it. This one is a no-brainer in my mind. Property values will certainly increase in the areas being served by the streetcar and therefore current owners stand to have some significant gains in equity if this project moves forward. The attractiveness of living where I am has increased tremendously for Brown faculty and staff, medical students, and some of the entrepreneurs and their employees if they ever materialize in the Jewelry District. That I should have to contribute some of this gained equity back to get the project built makes sense. The question is, will the requested tax be too high to be worth it? So let&amp;#8217;s do the math. The proposal will hit me with \$0.95 on every \$1,000 of property value. Let&amp;#8217;s assume that the homestead exemption will not be applied to this tax. Let&amp;#8217;s also assume that I&amp;#8217;m looking at a 15 year stay Downcity. This is reasonable because most of the properties around here are condos that are one or two bedroom and are not attractive to
folks with families&amp;#8212; we&amp;#8217;re filled with young folks and empty-nesters who aren&amp;#8217;t likely to be looking at this like a 30 year investment. Let&amp;#8217;s also assume that the economy will continue to stagnate over this period so we only see an inflation rate of, say, 2%. It&amp;#8217;s likely that this is an overly pessimistic estimate that will increase the cost. What I&amp;#8217;m interested in is the present discounted value, or the cost to me due to this tax if I were to incur it all up front. The theory goes that money today is worth more than money tomorrow because money depreciates in value due to inflation and because money today can be invested and will grow over time. We calculate &lt;span class="caps"&gt;PDV&lt;/span&gt; much like you would calculate compound interest. The final piece of data to calculate the &lt;span class="caps"&gt;PDV&lt;/span&gt; needed is my home value. Let&amp;#8217;s assume it hasn&amp;#8217;t moved at all since I purchased about a year ago, which would peg my condo at \$168,000. Now I want to know if
the &lt;span class="caps"&gt;PDV&lt;/span&gt; of the tax will exceed what I believe is a reasonable estimate for the increase in equity I will realize because of the project. 
And the &lt;span class="caps"&gt;PDV&lt;/span&gt;&amp;nbsp;is&amp;#8230;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;\$2,050.74&lt;/strong&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I think it would be hard to argue that my property value won&amp;#8217;t increase at least 1.2% because of this project. Adding the line, &amp;#8220;Steps to the Providence Streetcar that will take you to Brown&amp;#8217;s Medical School, through the Knowledge District, and to the Hospitals or through Downcity to &lt;span class="caps"&gt;RISD&lt;/span&gt; and Brown,&amp;#8221; is going to be worth more than that, period. I can&amp;#8217;t imagine the calculus is dramatically different for other Downcity property owners which means for us, this makes&amp;nbsp;&amp;#8220;cents&amp;#8221;.&lt;/p&gt;</summary><category term="brown university"></category><category term="core connector"></category><category term="department of planning and development"></category><category term="jewelry district"></category><category term="knowledge district"></category><category term="providence"></category><category term="ri"></category><category term="streetcar"></category><category term="urban development"></category></entry><entry><title>Justin Baeder asks the Wrong Question on Teacher Evaluation</title><link href="http://blog.jsonbecker.com/2011/09/justin-baeder-asks-the-wrong-question-on-teacher-evaluation.html" rel="alternate"></link><updated>2011-09-16T22:48:00-04:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2011-09-16:2011/09/justin-baeder-asks-the-wrong-question-on-teacher-evaluation.html</id><summary type="html">&lt;p&gt;If you&amp;#8217;re interested in education, I highly recommend Justin Baeder&amp;#8217;s&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; &amp;#8221;&lt;a href="http://blogs.edweek.org/edweek/on_performance/"&gt;On Performance&lt;/a&gt;&amp;#8221; blog hosted over on Education&amp;nbsp;Week.&lt;/p&gt;
&lt;p&gt;Today, he ended his &lt;a href="http://blogs.edweek.org/edweek/on_performance/2011/09/are_we_expecting_too_much_of_teacher_evaluation_systems.html"&gt;post&lt;/a&gt; with a question, &amp;#8220;I would be very interested to learn of any other sector that has achieved substantial performance gains by reforming its evaluation processes. We&amp;#8217;re putting a lot of eggs in the &amp;#8216;improve teacher evaluation to improve student learning&amp;#8217; basket, but no one even seems to be asking whether this strategy has any&amp;nbsp;merit.&amp;#8221;&lt;/p&gt;
&lt;p&gt;I think this is the write idea but the wrong question. What we should wonder is whether any other sector has achieved substantial performance gains by reforming its entire process for hiring, retaining, supporting, and terminating its employees when that sector started with an extremely rigid, non-differentiated structure. Teacher evaluation is about providing better professional growth opportunities targeted to an individual&amp;#8217;s needs. It&amp;#8217;s about rewarding folks who are doing a stellar job and making sure that you can reward mission-critical people who might otherwise leave for other opportunities. And, much to many union members&amp;#8217; chagrin, it&amp;#8217;s also about providing substantial a substantial and trusted evidence base that principals can turn to justify termination&amp;nbsp;decisions.&lt;/p&gt;
&lt;p&gt;Ask your favorite policy professional or administrator why they are pushing for centralized, mandatory, and prescriptive forms of teacher evaluation. I can guarantee they&amp;#8217;ll include the current lack of serious evaluation in schools. I would bet that most folks also are pushing for these policies as a proactive step to make sure they can win union-based challenges against performance-based terminations and reassignment. Because the teacher unions are so strong and are largely steadfast in their need to treat all teachers equally&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;, policymakers feel like they have to wrap evaluations in as much novel social science and standardization as possible so that they have even the tiniest chance in hell of holding up in court. To what extent can the lack of robust evaluation be connected to school leaders&amp;#8217; lack of self-efficacy for action on this&amp;nbsp;information?&lt;/p&gt;
&lt;p&gt;Teachers fear that a world without these protections would produce unfair evaluations and termination procedures that are subjective. Secretly, I bet that most policymakers would be totally comfortable not pushing hard for value-added models and overly specific observation rubrics. So long as they felt confident they could take action in response to the evaluations, the current evaluation hawks would instead be willing to leave much more to individual professional judgment&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;. If the primary relationship in a school building was professional, and not a unionized labor-management split, a lot of the current evaluation policy might not be necessary. In the very least, the policies could be less centralized. But ultimately, professionals are held accountable for their work quality by bosses that employees respect as&amp;nbsp;professionals.&lt;/p&gt;
&lt;p&gt;I&amp;#8217;ll end with one final thought: I wonder what the teacher evaluation narrative would be like in an alternative history where there was no split between the teacher unions and professional organizations of education administrators and&amp;nbsp;professors.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Important note: while I do work at a state department of education, I am not directly involved in nor am I intimately familiar with our teacher evaluation model or policies. As an employee of the Rhode Island Department of Education, I am also a member of the American Federation of Teachers Local 2012 union. The thoughts I&amp;#8217;ve expressed in this post are entirely my own and does not represent the &lt;span class="caps"&gt;AFT&lt;/span&gt; or &lt;span class="caps"&gt;RIDE&lt;/span&gt;&amp;#8217;s&amp;nbsp;position.&lt;/em&gt;&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Per his EdWeek Bio, &amp;#8220;Justin Baeder is a public school principal in Seattle and a doctoral student studying principal performance and productivity at the University of Washington. In this blog he aims to examine issues of performance, improvement, and the changing nature of the education profession.&amp;#8221; &amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;One day I&amp;#8217;ll write about the irony of equality of treatment for education professionals. It&amp;#8217;s strange that our thinking around funding has largely evolved from &amp;#8220;equality&amp;#8221; to &amp;#8220;adequacy&amp;#8221; but not our treatment of adults&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;Related important issue to solve&amp;#8212; low principal quality undermines this possibility. One day I&amp;#8217;ll write about my belief that the principal role is poorly designed and dooms most people to failure. Rethinking the building principal is a critical structural reform folks will be hearing more and more about&amp;#160;&lt;a class="footnote-backref" href="#fnref:3" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="education"></category><category term="evaluation"></category><category term="public-sector unions"></category><category term="teacher evaluation"></category><category term="union"></category></entry><entry><title>Libertarians and Charity</title><link href="http://blog.jsonbecker.com/2011/09/libertarians-and-charity.html" rel="alternate"></link><updated>2011-09-15T23:22:00-04:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2011-09-15:2011/09/libertarians-and-charity.html</id><summary type="html">&lt;p&gt;As an undergraduate I largely avoided political science because I couldn&amp;#8217;t imagine getting interested in reading The Republic, &lt;a href="http://www.coolstuffinc.com/images/Products/mtg%20art/Fourth/Leviathan.jpg"&gt;Leviathan&lt;/a&gt;, or Wealth of Nations. Political philosophy, and philosophy in general, just seemed like a horrible painful exercise, so I avoided it. Of course now that I&amp;#8217;m involved in &lt;a href="http://www.youtube.com/watch?v=mEJL2Uuv-oQ"&gt;public policy&lt;/a&gt; and not &lt;a href="http://io9.com/5840609/the-best-chemistry-geek-anthem-ever"&gt;organic chemistry&lt;/a&gt;, it feels as though I&amp;#8217;ve done a horrible disservice to myself by not going through and systematically exploring more fundamental questions about the role of the state, ethics and morality, justice,&amp;nbsp;etc.&lt;/p&gt;
&lt;p&gt;Part of my personal re-education in this area has been much easier by having access to a host of well-written blogs that host great conversations about these issues. These sources are smart, generally trustworthy, and are generally collegial. By reading actual academics apply their knowledge to current events, I am able to get access to a much more sophisticated conversation than is available in most popular&amp;nbsp;media.&lt;/p&gt;
&lt;p&gt;One of these sources is &lt;a href="http://bleedingheartlibertarians.com/"&gt;Bleeding Heart Libertarians&lt;/a&gt;, which seeks to explain how libertarians can have robust participation in social justice. This is a particularly interesting topic since, as I understand it, one of the major critiques of libertarianism is that it does not address social justice in a comprehensive and sufficient&amp;nbsp;way.&lt;/p&gt;
&lt;p&gt;Today, commenting on &lt;a href="https://twitter.com/#!/ronpaul"&gt;Ron Paul&lt;/a&gt;&amp;#8216;s response to &lt;a href="https://twitter.com/#!/wolfblitzercnn"&gt;Wolf Blitzer&lt;/a&gt;&amp;#8216;s baiting on healthcare&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;, &lt;span class="caps"&gt;BHL&lt;/span&gt; contributor &lt;a href="http://praxeology.net/"&gt;Professor Roderick Long&lt;/a&gt; brought up one of the libertarian arguments that most confounds me&amp;#8212; charity and mutual aid. Long writes that a libertarians second response to an individual&amp;#8217;s failure to use basic services ((Specifically, Blitzer presents the case of a healthy young man who foregoes health insurance. However, Professor Long&amp;#8217;s suggested response is sufficiently vague that I believe it is safe to say that he would apply the same three stages to any situation where an individual&amp;#8217;s circumstances or decisions have jeopardized their access to basic needs. This includes all social safety net programs.)) should be, &amp;#8220;talk about how charity and mutual aid are more efficient than government welfare, and how we therefore need to shift the venue of assistance from the latter to the&amp;nbsp;former.&amp;#8221;&lt;/p&gt;
&lt;p&gt;This argument had always felt extremely classist to me. It seems that those who are most vulnerable have never been the folks who have access to mutual aid or charity through local community organizations, family members, friends, and other contacts. General social capital aside, even people who have strong community ties who are most likely to need access to a social safety net live in communities that overwhelming don&amp;#8217;t have the collective resources to offer sufficient aid to promote the welfare of that community. The whole concept seems steeped in a highly culturally informed sense of reality that imagines a small town church community as opposed to the generationally impoverished&amp;#8217;s&amp;nbsp;reality.&lt;/p&gt;
&lt;p&gt;It&amp;#8217;s not that I&amp;#8217;m not sympathetic to the argument that it is possible that models of mutual aid and charity could ultimately private superior resource allocation, it&amp;#8217;s just that I don&amp;#8217;t think that aggregate efficiency is the goal here. I realize that this is a statement of prior moral conviction, but it seems to me that the ostensible purpose of safety nets is to make sure the most coverage against a failure to meet the basic needs of all people. Under this situation, efficiency is desirable but secondary, and I don&amp;#8217;t see how mutual aid and charity will provide sufficient coverage to meet the needs of the most important beneficiaries of these&amp;nbsp;policies.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;http://bleedingheartlibertarians.com/2011/09/the-libertarian-three-step-program&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="bhl"></category><category term="bleeding heart libertarians"></category><category term="charity"></category><category term="health insurance"></category><category term="libertarianism"></category><category term="political philosophy"></category><category term="politics"></category><category term="poverty"></category><category term="ron paul"></category><category term="social safety net"></category></entry><entry><title>Apple Migration Assistant</title><link href="http://blog.jsonbecker.com/2011/09/apple-migration-assistant.html" rel="alternate"></link><updated>2011-09-14T23:45:00-04:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2011-09-14:2011/09/apple-migration-assistant.html</id><summary type="html">&lt;p&gt;For several years I considered switching to Apple. I&amp;#8217;ve been a wannabe believer since &lt;span class="caps"&gt;OSX&lt;/span&gt;. I was using &lt;a href="http://images.memegenerator.net/instances/400x/6300003.jpg"&gt;Linux&lt;/a&gt;as my every day operating system. This was one part about learning, one part frustration with Windows perpetual funky instabilities, and part a growing appreciation for things like the command line interface and free and open source
software. &lt;span class="caps"&gt;OSX&lt;/span&gt; offered many things I liked&amp;#8212; &lt;a href="http://imgs.xkcd.com/comics/sandwich.png"&gt;a great &lt;span class="caps"&gt;CLI&lt;/span&gt;&lt;/a&gt; I was already getting intimately familiar with, &lt;a href="http://www.eatliver.com/img/2005/294.jpg"&gt;rock hard stability&lt;/a&gt;, beautiful graphic effects like those I enjoyed with Compiz, etc. More importantly, &lt;span class="caps"&gt;OSX&lt;/span&gt; could do all this while providing me with a decent experience on some of the software I&amp;#8217;d love to dump but simply could not like Microsoft Office. Additionally, I wouldn&amp;#8217;t have all kinds of problems on the web surfing pages that were supposedly platform neutral and using browsers that were supposedly cross-platform (Flash on Linux was a joke as recently as two years ago when I abandoned Linux as my every day operating system). Of course, perhaps first and foremost, I would never have to worry about whether an update will cause a conflict because I was forced to use a deprecated driver to get my hardware to work or that some of my hardware would be limited because there wasn&amp;#8217;t a fully functional driver available. But every time it came to a decision on purchasing a new machine, I could not bring myself to pay the &amp;#8220;&lt;a href="http://www.urbandictionary.com/define.php?term=Apple+Tax"&gt;Apple tax&lt;/a&gt;&amp;#8220;. I was a &lt;a href="http://hollywoodroaster.com/wp-content/uploads/2008/10/maruchan.jpg"&gt;student&lt;/a&gt;, and while I&amp;#8217;ve generally felt that the Macbook Pro/Powerbook have had reasonable economics and a physical
design well beyond their competitors, I just couldn&amp;#8217;t justify the price to power ratio. So I continued to build my own desktops and work on an &lt;span class="caps"&gt;IBM&lt;/span&gt; Thinkpad I would buy after finding a good&amp;nbsp;deal.&lt;/p&gt;
&lt;p&gt;A year ago that changed when I purchased a 13&amp;#8221; Macbook Pro. My laptop had totally crapped out on me and I needed a replacement fast. Combining the education discount (which I used a recently expired student &lt;span class="caps"&gt;ID&lt;/span&gt; for), a free printer and iPod, and tax-free weekend in Massachusetts meant I could buy a brand new &lt;span class="caps"&gt;MBP&lt;/span&gt; for around \$900. Nothing really could compete with this&amp;#8212; the price was right, the battery life, weight, size, and power were all right and I couldn&amp;#8217;t even
reach parody with another &lt;span class="caps"&gt;PC&lt;/span&gt;. So I purchased my Macbook&amp;nbsp;Pro.&lt;/p&gt;
&lt;p&gt;I was very happy with that laptop. A great keyboard is a must, and the Macbook Pro was the best I used other than my old Thinkpad T43. In addition to the keyboard, I also got a trackpad that was far superior to any I had used before that actually allowed me to ditch the mouse I normally carried with me everywhere I went. The battery life was a
ridiculous 8hrs&amp;#8212; my previous laptop got 2.5hrs at best and I used to think that was an accomplishment. Power wise I never ran into any hiccups. The stability was solid. &lt;span class="caps"&gt;OSX&lt;/span&gt; was easy to adopt to as a full-time &lt;span class="caps"&gt;OS&lt;/span&gt; and I was on my merry&amp;nbsp;way.&lt;/p&gt;
&lt;p&gt;Except one, tiny,&amp;nbsp;problem.&lt;/p&gt;
&lt;p&gt;I hate using a laptop if I don&amp;#8217;t have to. Whenever I was home I plugged right into a much bigger screen, an external keyboard, and mouse and sat a desk to use my computer. Call me old-fashioned, but I have never been as comfortable working on a laptop as I am using a separate keyboard, mouse, and monitor. And laptop speakers? Don&amp;#8217;t even get me&amp;nbsp;started.&lt;/p&gt;
&lt;p&gt;Now none of this would be a problem because I used my laptop on the go. At the time I purchased my machine, I was just coming off of five years of school, during which I constantly worked in libraries, coffee shops, friends houses, etc. I also had worked as a consultant at several places over the past year, so bringing my workstation with me on the go was a
necessity. One month after I got my laptop, I was working a normal desk job but was assigned a desktop from the stone age that was barely functional. I found myself doing a significant amount of my work on my personal laptop that I brought with me from home. But about six months ago, my job purchased me a new desktop that was blazing fast. I work with confidential data virtually all day long, which was a huge hassle when I used an old machine. I often performed various data management activities with no more than one application open on my work computer, prepare the data in non-confidential format, and ship it off to my laptop for more in-depth analysis. The workflow was atrocious. Having a
functional desktop made it pointless to bring my laptop to work&amp;#8212; most of what I do couldn&amp;#8217;t be done on a personal machine anyway. So while my workflow became much more efficient, my laptop lost utility. More and more I found myself simply leaving my laptop plugged in at my desk at home and operating it like a desktop. Fast forward to today and I fried
my battery, which now holds only 3-4 hours of charge and I haven&amp;#8217;t used my laptop as a portable computer in&amp;nbsp;months.&lt;/p&gt;
&lt;p&gt;I decided I should sell my laptop and replace it with a Mac Mini, which brings me to the title of this post. Perhaps the most pleasant experience I&amp;#8217;ve had on any computer since I first used a Gateway 2000 c. 1992 came from using Apple&amp;#8217;s Migration Assistant. Upon turning on my Mac Mini for the first time, the setup wizard offered  the opportunity to transfer files and settings from another computer. Now this is a feature that browsers and other software have offered for years and the experience has never been all that useful to me. But this time I decided
to try it and I plugged my laptop into my Mac Mini using an ethernet cable. Approximate 2 hours later my Mac Mini restarted and the experience was&amp;nbsp;breathtaking.&lt;/p&gt;
&lt;p&gt;Everything, and I mean everything, transferred over to my new computer. All my applications were installed. All of my settings, including those made by software like Onyx and Geek Tool, transferred over. All my documents were where I left them. The experience was indistinguishable from logging onto my&amp;nbsp;laptop.&lt;/p&gt;
&lt;p&gt;This is an astonishingly great and useful feature. It seems so simple in theory, but execution can easily be botched. Apple hit a home run with Migration Assistant, at least as of the version that comes standard in&amp;nbsp;Lion.&lt;/p&gt;
&lt;p&gt;Ultimately, my experience with Migration Assistant, along with the great resale value on my Macbook Pro, has pretty much ensured that my next computer will be&amp;nbsp;an Apple.&lt;/p&gt;</summary><category term="Apple"></category><category term="Linux"></category><category term="Mac Mini"></category><category term="Macbook Pro"></category><category term="Migration Assistant"></category><category term="OSX"></category><category term="OSX Lion"></category></entry><entry><title>Community Voice at the Knowledge District Development Framework Meeting</title><link href="http://blog.jsonbecker.com/2011/09/community-voice-at-the-knowledge-district-development-framework-meeting.html" rel="alternate"></link><updated>2011-09-08T03:50:00-04:00</updated><author><name>Jason</name></author><id>tag:blog.jsonbecker.com,2011-09-08:2011/09/community-voice-at-the-knowledge-district-development-framework-meeting.html</id><summary type="html">&lt;p&gt;Tonight, I went to a public meeting run by Providence&amp;#8217;s Department of Planning and Development. A few of upfront&amp;nbsp;observations:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The folks who work for the Department of Planning and Development (&lt;span class="caps"&gt;DPD&lt;/span&gt;) were professional, kind, and capable, as was the consultants who worked with them. They maintained decorum and a genuine sense of openness even though there was a clear tension in the room between some outspoken (and knowledgeable) community members and activists who had clearly participated in many past&amp;nbsp;meetings.&lt;/li&gt;
&lt;li&gt;The ideas presented for the Knowledge District demonstrated thoughtful, albeit top-down, considerations for the space that showed a remarkable respect for the complexity, size, and importance of the project. I also felt that the &lt;span class="caps"&gt;DPD&lt;/span&gt; and their consultants got all the big ideas right and that they were quite familiar with the community they were&amp;nbsp;re-imagining.&lt;/li&gt;
&lt;li&gt;Despite some great big ideas, there are really important details that are worth memorializing that the &lt;span class="caps"&gt;DPD&lt;/span&gt; is missing. In part, maybe this is because they&amp;#8217;re simply not at that deep a stage. I&amp;#8217;m hopeful that the purpose of the public meetings was not just to get
feedback on the big concepts (which seem largely unassailable), but to make sure they get the details right from the people who live and interact with these neighborhoods&amp;nbsp;daily.&lt;/li&gt;
&lt;li&gt;There are some clear areas of consensus among the engaged community, both positive and negative. At times, this consensus suggest that the state, city, and institutions (business, education, health, etc) have very different goals than the community.
∫
Here&amp;#8217;s my summary of what the community had to&amp;nbsp;say:&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Folks want to get rid of surface parking lots and move towards more parking structures. It&amp;#8217;s very clear that everyone feels these surface lots contribute to the desolate feel of the Jewelry District and hospital area, as well as acting as an extra barrier (beyond the highways) to connecting the Knowledge District to the rest of the city. People want to see mixed-use, with real action on the street level and residences and offices on higher floors. Everyone wants better sight lines to draw people into the Jewelry district and wants to see green space embraced, not solely through a park on the water but intimately placed directly on the streets as trees and other landscaping. People cited Chestnut and Richmond Street  several times as strong streets that acted as the main arteries by which Downcity and the Jewelry District connect. It seems that there is broad agreement that there a reason needs to exist to draw pedestrians into this neighborhood from Downcity, Fox Point, and Upper South Providence if we&amp;#8217;re going to have a vital, 24/7 community. There was also pretty broad acceptance of higher buildings being constructed along I-95 and keeping large footprint buildings out of the Jewelry&amp;nbsp;District.&lt;/p&gt;
&lt;p&gt;Most of the more negative tone of the evening came from two core issues&amp;#8212; the need for more residential development, something that&amp;#8217;s not seen as high priority or even on the radar of most public officials, and funding. I&amp;#8217;ll start with funding. There are serious concerns that even if the plans are perfect and great, a total lack of municipal, state, and federal funding for the foreseeable future places major risks on central aspects of the &lt;span class="caps"&gt;DPD&lt;/span&gt;&amp;#8217;s plans. How can we fund a large, sweeping greenway and inviting, beautiful streets? How can we fund restoring vital roadways absorbed by bad planning in the past? How can we upkeep the parks people crave or build vital family institutions like schools without any public funding? How will we repurpose landmark
buildings like the Dynamo House that has sat vacant even though it&amp;#8217;s so full of potential? There is a serious sense that all the projects that serve as good models for the Knowledge District required considerable public infrastructure investment that&amp;#8217;s just not available now. Sadly, to truly &amp;#8220;fix&amp;#8221; the Knowledge District will require not just one large project, but several major improvements. I saw little optimism for the proposed Streetcar/light rail system that &lt;span class="caps"&gt;RIPTA&lt;/span&gt; is championing. Some of that was disbelief that it could ever be funded, and some of that was disbelief the streetcar was a solution to a real problem. There&amp;#8217;s also little optimism that the proposed pedestrian bridge to connect Fox Point to the Jewelry District is going to happen. Everyone begrudged that &lt;span class="caps"&gt;DPD&lt;/span&gt; had little real authority to make anything happen. Zoning is an absolute disgrace in Providence, particularly this area. But even substantially improving the zoning and regulations around development won&amp;#8217;t actually make sure the projects are mindful of the projects wider goals. More to the point, it&amp;#8217;s still unclear how Providence can simply use the name &amp;#8220;Knowledge District&amp;#8221; to bring in the kind of development needed. There is serious consternation that the entire &amp;#8220;Knowledge District&amp;#8221; concept is selling something that doesn&amp;#8217;t exist and won&amp;#8217;t have the infrastructure to attract folks. Without the promise of big public infrastructure improvements, developers are going to play the &amp;#8220;wait and see&amp;#8221;&amp;nbsp;game.&lt;/p&gt;
&lt;p&gt;Residential development is another important aspect of what the community members craved. It was immediately clear that the desire of folks at this meeting was to have a 24/7 neighborhood with mixed-uses, including several calls (from residents, no less) to include low-income and affordable housing. There is strong dislike of the name &amp;#8220;Knowledge District&amp;#8221;, especially if it supplants the Jewelry District (which is a subset of the area in question). No one feels that this name captures what they want to use the space for, and no one felt the name had any
real meaning. Folks believed that &amp;#8220;Knowledge District&amp;#8221; was as empty marketing that would have no real longterm staying power. But really, this goes beyond a bad name. The members of the community who met with &lt;span class="caps"&gt;DPD&lt;/span&gt; tonight clearly believe that residential development has taken a
major backseat to institutional expansion and large business development. My interpretation was that the community felt that lawmakers were simply hoping that big groups like the hospitals, Brown University, Johnson and Wales, and some yet-to-be-named mid-sized businesses would snap up parcels and build massive buildings that would fill with jobs. First, they believed this vision was largely a fiction (again, see the hesitation folks had that businesses of any remarkable
size would take on the development costs and move to Providence without the public infrastructure investments). Second, these kinds of buildings were not what the community envisioned, particularly for the Jewelry District area that already has much smaller plot sizes and lower building heights. What I heard, rather clearly, was that the sea of parking lots around the hospital and the area with raised highway along I-95 was fair game for the behemoth buildings most lawmakers are picturing for the entire project. But the interior of the Knowledge
District has to be filled in with a place that people want to live, play and work in (in that&amp;nbsp;order).&lt;/p&gt;
&lt;p&gt;I hope to write some more on my thoughts on developing this area in the future. I generally agree with the comments from the community above, but I have a bit more optimism and a bit more faith. Overall, I was really happy with how &lt;span class="caps"&gt;DPD&lt;/span&gt; is framing this project. They are very consciously thinking about distinct portions of the Knowledge District and respecting their differences while simultaneously ensuring cohesion and setting strong, wider&amp;nbsp;goals.&lt;/p&gt;
&lt;p&gt;I just hope we get a damn grocery store and dramatically cut down on surface lots. More on that&amp;nbsp;later.&lt;/p&gt;</summary><category term="brown university"></category><category term="department of planning and development"></category><category term="jewelry district"></category><category term="knowledge district"></category><category term="land use"></category><category term="providence"></category><category term="ri"></category><category term="urban development"></category></entry></feed>